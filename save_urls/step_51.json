"[{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"document\", \"Document\"], \"kwargs\": {\"metadata\": {\"source\": \"https://dealii.org/current/doxygen/deal.II/step_51.html\", \"content_type\": \"text/html\", \"title\": \"The deal.II Library: The step-51 tutorial program\", \"language\": \"en-US\"}, \"page_content\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\nThe deal.II Library: The step-51 tutorial program\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\u00a0Reference documentation for deal.II version 9.6.0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\\(\\\\newcommand{\\\\dealvcentcolon}{\\\\mathrel{\\\\mathop{:}}}\\\\)\\n\\\\(\\\\newcommand{\\\\dealcoloneq}{\\\\dealvcentcolon\\\\mathrel{\\\\mkern-1.2mu}=}\\\\)\\n\\\\(\\\\newcommand{\\\\jump}[1]{\\\\left[\\\\!\\\\left[ #1 \\\\right]\\\\!\\\\right]}\\\\)\\n\\\\(\\\\newcommand{\\\\average}[1]{\\\\left\\\\{\\\\!\\\\left\\\\{ #1 \\\\right\\\\}\\\\!\\\\right\\\\}}\\\\)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLoading...\\nSearching...\\nNo Matches\\n\\n\\n\\n\\n\\n\\n\\nThe step-51 tutorial program\\n\\n\\nThis tutorial depends on step-7, step-9.\\n\\n\\nTable of contents\\n\\n\\n Introduction\\n\\n Hybridizable discontinuous Galerkin methods \\n\\n Reducing the size of the linear system \\n Relation with Static Condensation \\n Solution quality and rates of convergence\\n Alternative approaches \\n\\n HDG applied to the convection-diffusion problem \\n\\n Post-processing and super-convergence \\n\\n Problem specific data \\n Implementation \\n\\n The commented program\\n\\nInclude files\\nEquation data\\nThe HDG solver class\\nThe HDG class implementation\\n\\nConstructor\\nHDG::setup_system\\nHDG::PerTaskData\\nHDG::ScratchData\\nHDG::PostProcessScratchData\\nHDG::assemble_system\\nHDG::assemble_system_one_cell\\nHDG::copy_local_to_global\\nHDG::solve\\nHDG::postprocess\\nHDG::postprocess_one_cell\\nHDG::output_results\\nHDG::refine_grid\\nHDG::run\\n\\n\\n\\n Results\\n\\nProgram output\\n\\nConvergence tables\\n\\nComparison with continuous finite elements\\n\\nResults for 2D\\nResults for 3D\\n\\nPossibilities for improvements\\n\\n The plain program\\n   \\n\\n\\n This program was contributed by Martin Kronbichler and Scott Miller. \\n Introduction\\nThis tutorial program presents the implementation of a hybridizable discontinuous Galkerin method for the convection-diffusion equation.\\nHybridizable discontinuous Galerkin methods \\nOne common argument against the use of discontinuous Galerkin elements is the large number of globally coupled degrees of freedom that one must solve in an implicit system. This is because, unlike continuous finite elements, in typical discontinuous elements there is one degree of freedom at each vertex for each of the adjacent elements, rather than just one, and similarly for edges and faces. As an example of how fast the number of unknowns grows, consider the FE_DGPMonomial basis: each scalar solution component is represented by polynomials of degree \\\\(p\\\\) with \\\\((1/\\\\text{dim}!) \\\\prod_{i=1}^{\\\\text{dim}}(p+i)\\\\) degrees of freedom per element. Typically, all degrees of freedom in an element are coupled to all of the degrees of freedom in the adjacent elements. The resulting discrete equations yield very large linear systems very quickly, especially for systems of equations in 2 or 3 dimensions.\\nReducing the size of the linear system \\nTo alleviate the computational cost of solving such large linear systems, the hybridizable discontinuous Galerkin (HDG) methodology was introduced by Cockburn and co-workers (see the references in the recent HDG overview article by Nguyen and Peraire [162]).\\nThe HDG method achieves this goal by formulating the mathematical problem using Dirichlet-to-Neumann mappings. The partial differential equations are first written as a first order system, and each field is then discretized via a DG method. At this point, the single-valued \\\"trace\\\" values on the skeleton of the mesh, i.e., element faces, are taken to be independent unknown quantities. This yields unknowns in the discrete formulation that fall into two categories:\\nFace unknowns that only couple with the cell unknowns from both sides of the face;\\nCell unknowns that only couple with the cell and face unknowns defined within the same cell. Crucially, no cell interior degree of freedom on one cell ever couples to any interior cell degree of freedom of a different cell.\\n\\nThe Dirichlet-to-Neumann map concept then permits the following solution procedure: \\n\\nUse local element interior data to enforce a Neumann condition on the skeleton of the triangulation. The global problem is then to solve for the trace values, which are the only globally coupled unknowns. \\n\\nUse the known skeleton values as Dirichlet data for solving local element-level solutions. This is known as the 'local solver', and is an embarrassingly parallel element-by-element solution process. \\n\\nRelation with Static Condensation \\nThe above procedure also has a linear algebra interpretation\\u2014referred to as static condensation\\u2014that was exploited to reduce the size of the global linear system by Guyan in the context of continuous Finite Elements [108], and by Fraeijs de Veubeke for mixed methods [72]. In the latter case (mixed formulation), the system reduction was achieved through the use of discontinuous fluxes combined with the introduction of an additional auxiliary hybrid variable that approximates the trace of the unknown at the boundary of every element. This procedure became known as hybridization and\\u2014by analogy\\u2014is the reason why the local discontinuous Galerkin method introduced by Cockburn, Gopalakrishnan, and Lazarov in 2009 [62], and subsequently developed by their collaborators, eventually came to be known as the hybridizable discontinuous Galerkin (HDG) method.\\nLet us write the complete linear system associated to the HDG problem as a block system with the discrete DG (cell interior) variables \\\\(U\\\\) as first block and the skeleton (face) variables \\\\(\\\\Lambda\\\\) as the second block:      \\n\\\\begin{eqnarray*}\\n\\\\begin{pmatrix} A & B \\\\\\\\ C & D \\\\end{pmatrix}\\n\\\\begin{pmatrix} U \\\\\\\\ \\\\Lambda \\\\end{pmatrix}\\n=\\n\\\\begin{pmatrix} F \\\\\\\\ G \\\\end{pmatrix}.\\n\\\\end{eqnarray*}\\n\\n Our aim is now to eliminate the \\\\(U\\\\) block with a Schur complement approach similar to step-20, which results in the following two steps:    \\n\\\\begin{eqnarray*}\\n(D - C A^{-1} B) \\\\Lambda &=& G - C A^{-1} F, \\\\\\\\\\nA U &=& F - B \\\\Lambda.\\n\\\\end{eqnarray*}\\n\\n The point is that the presence of \\\\(A^{-1}\\\\) is not a problem because \\\\(A\\\\) is a block diagonal matrix where each block corresponds to one cell and is therefore easy enough to invert. The coupling to other cells is introduced by the matrices \\\\(B\\\\) and \\\\(C\\\\) over the skeleton variable. The block-diagonality of \\\\(A\\\\) and the structure in \\\\(B\\\\) and \\\\(C\\\\) allow us to invert the matrix \\\\(A\\\\) element by element (the local solution of the Dirichlet problem) and subtract \\\\(CA^{-1}B\\\\) from \\\\(D\\\\). The steps in the Dirichlet-to-Neumann map concept hence correspond to \\n\\nconstructing the Schur complement matrix \\\\(D-C A^{-1} B\\\\) and right hand side \\\\(G - C A^{-1} F\\\\) locally on each cell and inserting the contribution into the global trace matrix in the usual way, \\n\\nsolving the Schur complement system for \\\\(\\\\Lambda\\\\), and \\n\\nsolving for \\\\(U\\\\) using the second equation, given \\\\(\\\\Lambda\\\\). \\n\\nSolution quality and rates of convergence\\nAnother criticism of traditional DG methods is that the approximate fluxes converge suboptimally. The local HDG solutions can be shown to converge as \\\\(\\\\mathcal{O}(h^{p+1})\\\\), i.e., at optimal order. Additionally, a super-convergence property can be used to post-process a new approximate solution that converges at the rate \\\\(\\\\mathcal{O}(h^{p+2})\\\\).\\nAlternative approaches \\nThe hybridizable discontinuous Galerkin method is only one way in which the problems of the discontinuous Galerkin method can be addressed. Another idea is what is called the \\\"weak Galerkin\\\" method. It is explored in step-61.\\nHDG applied to the convection-diffusion problem \\nThe HDG formulation used for this example is taken from \\n N.C. Nguyen, J. Peraire, B. Cockburn: An implicit high-order hybridizable discontinuous Galerkin method for linear convection\\u2013diffusion equations, Journal of Computational Physics, 2009, 228:9, 3232-3254. [DOI] \\nWe consider the convection-diffusion equation over the domain \\\\(\\\\Omega\\\\) with Dirichlet boundary \\\\(\\\\partial \\\\Omega_D\\\\) and Neumann boundary \\\\(\\\\partial \\\\Omega_N\\\\):       \\n\\\\begin{eqnarray*}\\n        \\\\nabla \\\\cdot (\\\\mathbf{c} u) - \\\\nabla \\\\cdot (\\\\kappa \\\\nabla u) &=& f,\\n        \\\\quad \\\\text{ in } \\\\Omega, \\\\\\\\\\n        u &=& g_D, \\\\quad \\\\text{ on } \\\\partial \\\\Omega_D, \\\\\\\\\\n        (\\\\mathbf{c} u - \\\\kappa \\\\nabla u)\\\\cdot \\\\mathbf{n} &=& g_N,\\n        \\\\quad \\\\text{ on }  \\\\partial \\\\Omega_N.\\n\\\\end{eqnarray*}\\n\\nIntroduce the auxiliary variable \\\\(\\\\mathbf{q}=-\\\\kappa \\\\nabla u\\\\) and rewrite the above equation as the first order system:       \\n\\\\begin{eqnarray*}\\n  \\\\mathbf{q} + \\\\kappa \\\\nabla u &=& 0, \\\\quad \\\\text{ in } \\\\Omega, \\\\\\\\\\n  \\\\nabla \\\\cdot (\\\\mathbf{c} u + \\\\mathbf{q}) &=& f, \\\\quad \\\\text{ in } \\\\Omega, \\\\\\\\\\n  u &=& g_D, \\\\quad \\\\text{ on } \\\\partial \\\\Omega_D, \\\\\\\\\\n  (\\\\mathbf{q} + \\\\mathbf{c}u)\\\\cdot\\\\mathbf{n}  &=& g_N,\\n        \\\\quad \\\\text{ on }  \\\\partial \\\\Omega_N.\\n\\\\end{eqnarray*}\\n\\nWe multiply these equations by the weight functions \\\\(\\\\mathbf{v}, w\\\\) and integrate by parts over every element \\\\(K\\\\) to obtain:       \\n\\\\begin{eqnarray*}\\n  (\\\\mathbf{v}, \\\\kappa^{-1} \\\\mathbf{q})_K - (\\\\nabla\\\\cdot\\\\mathbf{v}, u)_K\\n    + \\\\left<\\\\mathbf{v}\\\\cdot\\\\mathbf{n}, {\\\\hat{u}}\\\\right>_{\\\\partial K} &=& 0, \\\\\\\\\\n  - (\\\\nabla w, \\\\mathbf{c} u + \\\\mathbf{q})_K\\n    + \\\\left<w, (\\\\widehat{\\\\mathbf{c} u}+{\\\\hat{\\\\mathbf{q}}})\\\\cdot\\\\mathbf{n}\\\\right>_{\\\\partial K}\\n    &=& (w,f)_K.\\n\\\\end{eqnarray*}\\n\\nThe terms decorated with a hat denote the numerical traces (also commonly referred to as numerical fluxes). They are approximations to the interior values on the boundary of the element. To ensure conservation, these terms must be single-valued on any given element edge \\\\(\\\\partial K\\\\) even though, with discontinuous shape functions, there may of course be multiple values coming from the cells adjacent to an interface. We eliminate the numerical trace \\\\(\\\\hat{\\\\mathbf{q}}\\\\) by using traces of the form:    \\n\\\\begin{eqnarray*}\\n  \\\\widehat{\\\\mathbf{c} u}+\\\\hat{\\\\mathbf{q}} = \\\\mathbf{c}\\\\hat{u} + \\\\mathbf{q}\\n  + \\\\tau(u - \\\\hat{u})\\\\mathbf{n} \\\\quad \\\\text{ on } \\\\partial K.\\n\\\\end{eqnarray*}\\n\\nThe variable \\\\(\\\\hat {u}\\\\) is introduced as an additional independent variable and is the one for which we finally set up a globally coupled linear system. As mentioned above, it is defined on the element faces and discontinuous from one face to another wherever faces meet (at vertices in 2d, and at edges and vertices in 3d). Values for \\\\(u\\\\) and \\\\(\\\\mathbf{q}\\\\) appearing in the numerical trace function are taken to be the cell's interior solution restricted to the boundary \\\\(\\\\partial K\\\\).\\nThe local stabilization parameter \\\\(\\\\tau\\\\) has effects on stability and accuracy of HDG solutions; see the literature for a further discussion. A stabilization parameter of unity is reported to be the choice which gives best results. A stabilization parameter \\\\(\\\\tau\\\\) that tends to infinity prohibits jumps in the solution over the element boundaries, making the HDG solution approach the approximation with continuous finite elements. In the program below, we choose the stabilization parameter as   \\n\\\\begin{eqnarray*}\\n  \\\\tau = \\\\frac{\\\\kappa}{\\\\ell} + |\\\\mathbf{c} \\\\cdot \\\\mathbf{n}|\\n\\\\end{eqnarray*}\\n\\n where we set the diffusion \\\\(\\\\kappa=1\\\\) and the diffusion length scale to \\\\(\\\\ell = \\\\frac{1}{5}\\\\).\\nThe trace/skeleton variables in HDG methods are single-valued on element faces. As such, they must strongly represent the Dirichlet data on \\\\(\\\\partial\\\\Omega_D\\\\). This means that   \\n\\\\begin{equation*}\\n  \\\\hat{u}|_{\\\\partial \\\\Omega_D} = g_D,\\n\\\\end{equation*}\\n\\n where the equal sign actually means an \\\\(L_2\\\\) projection of the boundary function \\\\(g\\\\) onto the space of the face variables (e.g. linear functions on the faces). This constraint is then applied to the skeleton variable \\\\(\\\\hat{u}\\\\) using inhomogeneous constraints by the method VectorTools::project_boundary_values.\\nSumming the elemental contributions across all elements in the triangulation, enforcing the normal component of the numerical flux, and integrating by parts on the equation weighted by \\\\(w\\\\), we arrive at the final form of the problem: Find  \\\\((\\\\mathbf{q}_h, u_h, \\\\hat{u}_h) \\\\in\\n\\\\mathcal{V}_h^p \\\\times \\\\mathcal{W}_h^p \\\\times \\\\mathcal{M}_h^p\\\\) such that                      \\n\\\\begin{align*}\\n  (\\\\mathbf{v}, \\\\kappa^{-1} \\\\mathbf{q}_h)_{\\\\mathcal{T}}\\n    - ( \\\\nabla\\\\cdot\\\\mathbf{v}, u_h)_{\\\\mathcal{T}}\\n    + \\\\left<\\\\mathbf{v}\\\\cdot\\\\mathbf{n}, \\\\hat{u}_h\\\\right>_{\\\\partial\\\\mathcal{T}}\\n    &= 0,\\n    \\\\quad &&\\\\forall \\\\mathbf{v} \\\\in \\\\mathcal{V}_h^p,\\n\\\\\\\\\\n   - (\\\\nabla w, \\\\mathbf{c} u_h)_{\\\\mathcal{T}}\\n   + (w, \\\\nabla \\\\cdot \\\\mathbf{q}_h)_{\\\\mathcal{T}}\\n   + (w, (\\\\mathbf{c}\\\\cdot\\\\mathbf{n}) \\\\hat{u}_h)_{\\\\partial \\\\mathcal{T}}\\n    + \\\\left<w, \\\\tau (u_h - \\\\hat{u}_h)\\\\right>_{\\\\partial \\\\mathcal{T}}\\n    &=\\n    (w, f)_{\\\\mathcal{T}},\\n    \\\\quad &&\\\\forall w \\\\in \\\\mathcal{W}_h^p,\\n\\\\\\\\\\n  \\\\left< \\\\mu, \\\\hat{u}_h\\\\mathbf{c} \\\\cdot \\\\mathbf{n}\\n                + \\\\mathbf{q}_h\\\\cdot \\\\mathbf{n}\\n            + \\\\tau (u_h - \\\\hat{u}_h)\\\\right>_{\\\\partial \\\\mathcal{T}}\\n    &=\\n    \\\\left<\\\\mu, g_N\\\\right>_{\\\\partial\\\\Omega_N},\\n    \\\\quad &&\\\\forall \\\\mu \\\\in \\\\mathcal{M}_h^p.\\n\\\\end{align*}\\n\\nThe unknowns \\\\((\\\\mathbf{q}_h, u_h)\\\\) are referred to as local variables; they are represented as standard DG variables. The unknown \\\\(\\\\hat{u}_h\\\\) is the skeleton variable which has support on the codimension-1 surfaces (faces) of the mesh.\\nWe use the notation \\\\((\\\\cdot, \\\\cdot)_{\\\\mathcal{T}} = \\\\sum_K (\\\\cdot, \\\\cdot)_K\\\\) to denote the sum of integrals over all cells and   \\\\(\\\\left<\\\\cdot,\\n\\\\cdot\\\\right>_{\\\\partial \\\\mathcal{T}} = \\\\sum_K \\\\left<\\\\cdot,\\n\\\\cdot\\\\right>_{\\\\partial K}\\\\) to denote integration over all faces of all cells, i.e., interior faces are visited twice, once from each side and with the corresponding normal vectors. When combining the contribution from both elements sharing a face, the above equation yields terms familiar from the DG method, with jumps of the solution over the cell boundaries.\\nIn the equation above, the space \\\\(\\\\mathcal {W}_h^{p}\\\\) for the scalar variable \\\\(u_h\\\\) is defined as the space of functions that are tensor product polynomials of degree \\\\(p\\\\) on each cell and discontinuous over the element boundaries \\\\(\\\\mathcal Q_{-p}\\\\), i.e., the space described by FE_DGQ<dim>(p). The space for the gradient or flux variable \\\\(\\\\mathbf{q}_i\\\\) is a vector element space where each component is a locally polynomial and discontinuous \\\\(\\\\mathcal Q_{-p}\\\\). In the code below, we collect these two local parts together in one FESystem where the first dim components denote the gradient part and the last scalar component corresponds to the scalar variable. For the skeleton component \\\\(\\\\hat{u}_h\\\\), we define a space that consists of discontinuous tensor product polynomials that live on the element faces, which in deal.II is implemented by the class FE_FaceQ. This space is otherwise similar to FE_DGQ, i.e., the solution function is not continuous between two neighboring faces, see also the results section below for an illustration.\\nIn the weak form given above, we can note the following coupling patterns: \\n\\nThe matrix \\\\(A\\\\) consists of local-local coupling terms. These arise when the local weighting functions \\\\((\\\\mathbf{v}, w)\\\\) multiply the local solution terms \\\\((\\\\mathbf{q}_h, u_h)\\\\). Because the elements are discontinuous, \\\\(A\\\\) is block diagonal. \\n\\nThe matrix \\\\(B\\\\) represents the local-face coupling. These are the terms with weighting functions \\\\((\\\\mathbf{v}, w)\\\\) multiplying the skeleton variable \\\\(\\\\hat{u}_h\\\\). \\n\\nThe matrix \\\\(C\\\\) represents the face-local coupling, which involves the weighting function \\\\(\\\\mu\\\\) multiplying the local solutions \\\\((\\\\mathbf{q}_h, u_h)\\\\). \\n\\nThe matrix \\\\(D\\\\) is the face-face coupling; terms involve both \\\\(\\\\mu\\\\) and \\\\(\\\\hat{u}_h\\\\). \\n\\nPost-processing and super-convergence \\nOne special feature of the HDG methods is that they typically allow for constructing an enriched solution that gains accuracy. This post-processing takes the HDG solution in an element-by-element fashion and combines it such that one can get \\\\(\\\\mathcal O(h^{p+2})\\\\) order of accuracy when using polynomials of degree \\\\(p\\\\). For this to happen, there are two necessary ingredients: \\n\\nThe computed solution gradient \\\\(\\\\mathbf{q}_h\\\\) converges at optimal rate, i.e., \\\\(\\\\mathcal{O}(h^{p+1})\\\\). \\n\\nThe cell-wise average of the scalar part of the solution, \\\\(\\\\frac{(1,u_h)_K}{\\\\text{vol}(K)}\\\\), super-converges at rate \\\\(\\\\mathcal{O}(h^{p+2})\\\\). \\n\\nWe now introduce a new variable \\\\(u_h^* \\\\in \\\\mathcal{V}_h^{p+1}\\\\), which we find by minimizing the expression \\\\(|\\\\kappa \\\\nabla u_h^* + \\\\mathbf{q}_h|^2\\\\) over the cell \\\\(K\\\\) under the constraint  \\\\(\\\\left(1, u_h^*\\\\right)_K = \\\\left(1,\\nu_h\\\\right)_K\\\\). The constraint is necessary because the minimization functional does not determine the constant part of \\\\(u_h^*\\\\). This translates to the following system of equations:      \\n\\\\begin{eqnarray*}\\n\\\\left(1, u_h^*\\\\right)_K &=& \\\\left(1, u_h\\\\right)_K\\\\\\\\\\n\\\\left(\\\\nabla w_h^*, \\\\kappa \\\\nabla u_h^*\\\\right)_K &=&\\n-\\\\left(\\\\nabla w_h^*, \\\\mathbf{q}_h\\\\right)_K\\n\\\\quad \\\\text{for all } w_h^* \\\\in \\\\mathcal Q^{p+1}.\\n\\\\end{eqnarray*}\\n\\nSince we test by the whole set of basis functions in the space of tensor product polynomials of degree \\\\(p+1\\\\) in the second set of equations, this is an overdetermined system with one more equation than unknowns. We fix this in the code below by omitting one of these equations (since the rows in the Laplacian are linearly dependent when representing a constant function). As we will see below, this form of the post-processing gives the desired super-convergence result with rate \\\\(\\\\mathcal {O}(h^{p+2})\\\\). It should be noted that there is some freedom in constructing \\\\(u_h^*\\\\) and this minimization approach to extract the information from the gradient is not the only one. In particular, the post-processed solution defined here does not satisfy the convection-diffusion equation in any sense. As an alternative, the paper by Nguyen, Peraire and Cockburn cited above suggests another somewhat more involved formula for convection-diffusion that can also post-process the flux variable into an \\\\(H(\\\\Omega,\\\\mathrm{div})\\\\)-conforming variant and better represents the local convection-diffusion operator when the diffusion is small. We leave the implementation of a more sophisticated post-processing as a possible extension to the interested reader.\\nNote that for vector-valued problems, the post-processing works similarly. One simply sets the constraint for the mean value of each vector component separately and uses the gradient as the main source of information.\\nProblem specific data \\nFor this tutorial program, we consider almost the same test case as in step-7. The computational domain is \\\\(\\\\Omega \\\\dealcoloneq [-1,1]^d\\\\) and the exact solution corresponds to the one in step-7, except for a scaling. We use the following source centers \\\\(x_i\\\\) for the exponentials \\n\\n1D: \\\\(\\\\{x_i\\\\}^1 = \\\\{ -\\\\frac{1}{3}, 0, \\\\frac{1}{3} \\\\}\\\\), \\n\\n2D:    \\\\(\\\\{\\\\mathbf{x}_i\\\\}^2 = \\\\{ (-\\\\frac{1}{2},\\\\frac{1}{2}),\\n                                         (-\\\\frac{1}{2},-\\\\frac{1}{2}),\\n                                         (\\\\frac{1}{2},-\\\\frac{1}{2})\\n                                   \\\\}\\\\), \\n\\n3D:    \\\\(\\\\{\\\\mathbf{x}_i\\\\}^3 = \\\\{ (-\\\\frac{1}{2},\\\\frac{1}{2}, \\\\frac{1}{4}),\\n                                      (-\\\\frac{3}{5},-\\\\frac{1}{2}, -\\\\frac{1}{8}),\\n                                      (\\\\frac{1}{2},-\\\\frac{1}{2}, \\\\frac{1}{2})\\n                                   \\\\}\\\\). \\n\\nWith the exact solution given, we then choose the forcing on the right hand side and the Neumann boundary condition such that we obtain this solution (manufactured solution technique). In this example, we choose the diffusion equal to one and the convection as       \\n\\\\[\\n\\\\mathbf{c} = \\\\begin{cases}\\n1, & \\\\textrm{dim}=1 \\\\\\\\\\n(y, -x), & \\\\textrm{dim}=2 \\\\\\\\\\n(y, -x, 1), & \\\\textrm{dim}=3\\n\\\\end{cases}\\n\\\\]\\n\\n Note that the convection is divergence-free, \\\\(\\\\nabla \\\\cdot c = 0\\\\).\\nImplementation \\nBesides implementing the above equations, the implementation below provides the following features: \\n\\nWorkStream to parallelize local solvers. Workstream has been presented in detail in step-9. \\n\\nReconstruct the local DG solution from the trace. \\n\\nPost-processing the solution for superconvergence. \\n\\nDataOutFaces for direct output of the global skeleton solution. \\n\\n The commented program\\n Include files\\nMost of the deal.II include files have already been covered in previous examples and are not commented on.\\n\\u00a0 #include <deal.II/base/quadrature_lib.h>\\n\\u00a0 #include <deal.II/base/function.h>\\n\\u00a0 #include <deal.II/base/tensor_function.h>\\n\\u00a0 #include <deal.II/base/exceptions.h>\\n\\u00a0 #include <deal.II/base/work_stream.h>\\n\\u00a0 #include <deal.II/base/convergence_table.h>\\n\\u00a0 #include <deal.II/lac/vector.h>\\n\\u00a0 #include <deal.II/lac/affine_constraints.h>\\n\\u00a0 #include <deal.II/lac/full_matrix.h>\\n\\u00a0 #include <deal.II/lac/dynamic_sparsity_pattern.h>\\n\\u00a0 #include <deal.II/lac/solver_bicgstab.h>\\n\\u00a0 #include <deal.II/lac/precondition.h>\\n\\u00a0 #include <deal.II/grid/tria.h>\\n\\u00a0 #include <deal.II/grid/grid_generator.h>\\n\\u00a0 #include <deal.II/grid/grid_refinement.h>\\n\\u00a0 #include <deal.II/dofs/dof_handler.h>\\n\\u00a0 #include <deal.II/dofs/dof_renumbering.h>\\n\\u00a0 #include <deal.II/dofs/dof_tools.h>\\n\\u00a0 #include <deal.II/fe/fe_dgq.h>\\n\\u00a0 #include <deal.II/fe/fe_system.h>\\n\\u00a0 #include <deal.II/fe/fe_values.h>\\n\\u00a0 #include <deal.II/numerics/vector_tools.h>\\n\\u00a0 #include <deal.II/numerics/error_estimator.h>\\n\\u00a0 #include <deal.II/numerics/data_out.h>\\n\\u00a0 \\nHowever, we do have a few new includes for the example. The first one defines finite element spaces on the faces of the triangulation, which we refer to as the 'skeleton'. These finite elements do not have any support on the element interior, and they represent polynomials that have a single value on each codimension-1 surface, but admit discontinuities on codimension-2 surfaces.\\n\\u00a0 #include <deal.II/fe/fe_face.h>\\n\\u00a0 \\nThe second new file we include defines a new type of sparse matrix. The regular SparseMatrix type stores indices to all non-zero entries. The ChunkSparseMatrix takes advantage of the coupled nature of DG solutions. It stores an index to a matrix sub-block of a specified size. In the HDG context, this sub-block-size is actually the number of degrees of freedom per face defined by the skeleton solution field. This reduces the memory consumption of the matrix by up to one third and results in similar speedups when using the matrix in solvers.\\n\\u00a0 #include <deal.II/lac/chunk_sparse_matrix.h>\\n\\u00a0 \\nThe final new include for this example deals with data output. Since we have a finite element field defined on the skeleton of the mesh, we would like to visualize what that solution actually is. DataOutFaces does exactly this; the interface is the almost the same as the familiar DataOut, but the output only has codimension-1 data for the simulation.\\n\\u00a0 #include <deal.II/numerics/data_out_faces.h>\\n\\u00a0 \\n\\u00a0 #include <iostream>\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nWe start by putting all of our classes into their own namespace.\\n\\u00a0 namespace Step51\\n\\u00a0 {\\n\\u00a0   using namespace dealii;\\n\\u00a0 \\ndealiiDefinition namespace_dealii.h:25\\n Equation data\\nThe structure of the analytic solution is the same as in step-7. There are two exceptions. Firstly, we also create a solution for the 3d case, and secondly, we scale the solution so its norm is of order unity for all values of the solution width.\\n\\u00a0   template <int dim>\\n\\u00a0   class SolutionBase\\n\\u00a0   {\\n\\u00a0   protected:\\n\\u00a0     static const unsigned int n_source_centers = 3;\\n\\u00a0     static const Point<dim>   source_centers[n_source_centers];\\n\\u00a0     static const double       width;\\n\\u00a0   };\\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <>\\n\\u00a0   const Point<1>\\n\\u00a0     SolutionBase<1>::source_centers[SolutionBase<1>::n_source_centers] =\\n\\u00a0       {Point<1>(-1.0 / 3.0), Point<1>(0.0), Point<1>(+1.0 / 3.0)};\\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <>\\n\\u00a0   const Point<2>\\n\\u00a0     SolutionBase<2>::source_centers[SolutionBase<2>::n_source_centers] =\\n\\u00a0       {Point<2>(-0.5, +0.5), Point<2>(-0.5, -0.5), Point<2>(+0.5, -0.5)};\\n\\u00a0 \\n\\u00a0   template <>\\n\\u00a0   const Point<3>\\n\\u00a0     SolutionBase<3>::source_centers[SolutionBase<3>::n_source_centers] = {\\n\\u00a0       Point<3>(-0.5, +0.5, 0.25),\\n\\u00a0       Point<3>(-0.6, -0.5, -0.125),\\n\\u00a0       Point<3>(+0.5, -0.5, 0.5)};\\n\\u00a0 \\n\\u00a0   template <int dim>\\n\\u00a0   const double SolutionBase<dim>::width = 1. / 5.;\\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim>\\n\\u00a0   class Solution : public Function<dim>, protected SolutionBase<dim>\\n\\u00a0   {\\n\\u00a0   public:\\n\\u00a0     virtual double value(const Point<dim> &p,\\n\\u00a0                          const unsigned int /*component*/ = 0) const override\\n\\u00a0     {\\n\\u00a0       double sum = 0;\\n\\u00a0       for (unsigned int i = 0; i < this->n_source_centers; ++i)\\n\\u00a0         {\\n\\u00a0           const Tensor<1, dim> x_minus_xi = p - this->source_centers[i];\\n\\u00a0           sum +=\\n\\u00a0             std::exp(-x_minus_xi.norm_square() / (this->width * this->width));\\n\\u00a0         }\\n\\u00a0 \\n\\u00a0       return sum /\\n\\u00a0              std::pow(2. * numbers::PI * this->width * this->width, dim / 2.);\\n\\u00a0     }\\n\\u00a0 \\n\\u00a0     virtual Tensor<1, dim>\\n\\u00a0     gradient(const Point<dim> &p,\\n\\u00a0              const unsigned int /*component*/ = 0) const override\\n\\u00a0     {\\n\\u00a0       Tensor<1, dim> sum;\\n\\u00a0       for (unsigned int i = 0; i < this->n_source_centers; ++i)\\n\\u00a0         {\\n\\u00a0           const Tensor<1, dim> x_minus_xi = p - this->source_centers[i];\\n\\u00a0 \\n\\u00a0           sum +=\\n\\u00a0             (-2 / (this->width * this->width) *\\n\\u00a0              std::exp(-x_minus_xi.norm_square() / (this->width * this->width)) *\\n\\u00a0              x_minus_xi);\\n\\u00a0         }\\n\\u00a0 \\n\\u00a0       return sum /\\n\\u00a0              std::pow(2. * numbers::PI * this->width * this->width, dim / 2.);\\n\\u00a0     }\\n\\u00a0   };\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nFunctionDefinition function.h:152\\nFunction::gradientvirtual Tensor< 1, dim, RangeNumberType > gradient(const Point< dim > &p, const unsigned int component=0) const\\nFunction::valuevirtual RangeNumberType value(const Point< dim > &p, const unsigned int component=0) const\\nPointDefinition point.h:111\\nTensorDefinition tensor.h:471\\nUtilities::MPI::sumT sum(const T &t, const MPI_Comm mpi_communicator)\\nnumbers::PIstatic constexpr double PIDefinition numbers.h:259\\nstd::exp::VectorizedArray< Number, width > exp(const ::VectorizedArray< Number, width > &)Definition vectorization.h:6829\\nstd::pow::VectorizedArray< Number, width > pow(const ::VectorizedArray< Number, width > &, const Number p)Definition vectorization.h:6885\\nThis class implements a function where the scalar solution and its negative gradient are collected together. This function is used when computing the error of the HDG approximation and its implementation is to simply call value and gradient function of the Solution class.\\n\\u00a0   template <int dim>\\n\\u00a0   class SolutionAndGradient : public Function<dim>, protected SolutionBase<dim>\\n\\u00a0   {\\n\\u00a0   public:\\n\\u00a0     SolutionAndGradient()\\n\\u00a0       : Function<dim>(dim + 1)\\n\\u00a0     {}\\n\\u00a0 \\n\\u00a0     virtual void vector_value(const Point<dim> &p,\\n\\u00a0                               Vector<double>   &v) const override\\n\\u00a0     {\\n\\u00a0       AssertDimension(v.size(), dim + 1);\\n\\u00a0       Solution<dim>  solution;\\n\\u00a0       Tensor<1, dim> grad = solution.gradient(p);\\n\\u00a0       for (unsigned int d = 0; d < dim; ++d)\\n\\u00a0         v[d] = -grad[d];\\n\\u00a0       v[dim] = solution.value(p);\\n\\u00a0     }\\n\\u00a0   };\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nFunction::vector_valuevirtual void vector_value(const Point< dim > &p, Vector< RangeNumberType > &values) const\\nVectorDefinition vector.h:120\\nAssertDimension#define AssertDimension(dim1, dim2)Definition exceptions.h:1985\\nNext comes the implementation of the convection velocity. As described in the introduction, we choose a velocity field that is \\\\((y, -x)\\\\) in 2d and \\\\((y, -x, 1)\\\\) in 3d. This gives a divergence-free velocity field.\\n\\u00a0   template <int dim>\\n\\u00a0   class ConvectionVelocity : public TensorFunction<1, dim>\\n\\u00a0   {\\n\\u00a0   public:\\n\\u00a0     ConvectionVelocity()\\n\\u00a0       : TensorFunction<1, dim>()\\n\\u00a0     {}\\n\\u00a0 \\n\\u00a0     virtual Tensor<1, dim> value(const Point<dim> &p) const override\\n\\u00a0     {\\n\\u00a0       Tensor<1, dim> convection;\\n\\u00a0       switch (dim)\\n\\u00a0         {\\n\\u00a0           case 1:\\n\\u00a0             convection[0] = 1;\\n\\u00a0             break;\\n\\u00a0           case 2:\\n\\u00a0             convection[0] = p[1];\\n\\u00a0             convection[1] = -p[0];\\n\\u00a0             break;\\n\\u00a0           case 3:\\n\\u00a0             convection[0] = p[1];\\n\\u00a0             convection[1] = -p[0];\\n\\u00a0             convection[2] = 1;\\n\\u00a0             break;\\n\\u00a0           default:\\n\\u00a0             DEAL_II_NOT_IMPLEMENTED();\\n\\u00a0         }\\n\\u00a0       return convection;\\n\\u00a0     }\\n\\u00a0   };\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nTensorFunctionDefinition tensor_function.h:58\\nTensorFunction::valuevirtual value_type value(const Point< dim > &p) const\\nDEAL_II_NOT_IMPLEMENTED#define DEAL_II_NOT_IMPLEMENTED()Definition exceptions.h:1814\\nThe last function we implement is the right hand side for the manufactured solution. It is very similar to step-7, with the exception that we now have a convection term instead of the reaction term. Since the velocity field is incompressible, i.e.,  \\\\(\\\\nabla \\\\cdot \\\\mathbf{c} =\\n   0\\\\), the advection term simply reads \\\\(\\\\mathbf{c} \\\\nabla u\\\\).\\n\\u00a0   template <int dim>\\n\\u00a0   class RightHandSide : public Function<dim>, protected SolutionBase<dim>\\n\\u00a0   {\\n\\u00a0   public:\\n\\u00a0     virtual double value(const Point<dim> &p,\\n\\u00a0                          const unsigned int /*component*/ = 0) const override\\n\\u00a0     {\\n\\u00a0       ConvectionVelocity<dim> convection_velocity;\\n\\u00a0       Tensor<1, dim>          convection = convection_velocity.value(p);\\n\\u00a0       double                  sum        = 0;\\n\\u00a0       for (unsigned int i = 0; i < this->n_source_centers; ++i)\\n\\u00a0         {\\n\\u00a0           const Tensor<1, dim> x_minus_xi = p - this->source_centers[i];\\n\\u00a0 \\n\\u00a0           sum +=\\n\\u00a0             ((2 * dim - 2 * convection * x_minus_xi -\\n\\u00a0               4 * x_minus_xi.norm_square() / (this->width * this->width)) /\\n\\u00a0              (this->width * this->width) *\\n\\u00a0              std::exp(-x_minus_xi.norm_square() / (this->width * this->width)));\\n\\u00a0         }\\n\\u00a0 \\n\\u00a0       return sum /\\n\\u00a0              std::pow(2. * numbers::PI * this->width * this->width, dim / 2.);\\n\\u00a0     }\\n\\u00a0   };\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n The HDG solver class\\nThe HDG solution procedure follows closely that of step-7. The major difference is the use of three different sets of DoFHandler and FE objects, along with the ChunkSparseMatrix and the corresponding solutions vectors. We also use WorkStream to enable a multithreaded local solution process which exploits the embarrassingly parallel nature of the local solver. For WorkStream, we define the local operations on a cell and a copy function into the global matrix and vector. We do this both for the assembly (which is run twice, once when we generate the system matrix and once when we compute the element-interior solutions from the skeleton values) and for the postprocessing where we extract a solution that converges at higher order.\\n\\u00a0   template <int dim>\\n\\u00a0   class HDG\\n\\u00a0   {\\n\\u00a0   public:\\n\\u00a0     enum RefinementMode\\n\\u00a0     {\\n\\u00a0       global_refinement,\\n\\u00a0       adaptive_refinement\\n\\u00a0     };\\n\\u00a0 \\n\\u00a0     HDG(const unsigned int degree, const RefinementMode refinement_mode);\\n\\u00a0     void run();\\n\\u00a0 \\n\\u00a0   private:\\n\\u00a0     void setup_system();\\n\\u00a0     void assemble_system(const bool reconstruct_trace = false);\\n\\u00a0     void solve();\\n\\u00a0     void postprocess();\\n\\u00a0     void refine_grid(const unsigned int cycle);\\n\\u00a0     void output_results(const unsigned int cycle);\\n\\u00a0 \\nData for the assembly and solution of the primal variables.\\n\\u00a0     struct PerTaskData;\\n\\u00a0     struct ScratchData;\\n\\u00a0 \\nPost-processing the solution to obtain \\\\(u^*\\\\) is an element-by-element procedure; as such, we do not need to assemble any global data and do not declare any 'task data' for WorkStream to use.\\n\\u00a0     struct PostProcessScratchData;\\n\\u00a0 \\nThe following three functions are used by WorkStream to do the actual work of the program.\\n\\u00a0     void assemble_system_one_cell(\\n\\u00a0       const typename DoFHandler<dim>::active_cell_iterator &cell,\\n\\u00a0       ScratchData                                          &scratch,\\n\\u00a0       PerTaskData                                          &task_data);\\n\\u00a0 \\n\\u00a0     void copy_local_to_global(const PerTaskData &data);\\n\\u00a0 \\n\\u00a0     void postprocess_one_cell(\\n\\u00a0       const typename DoFHandler<dim>::active_cell_iterator &cell,\\n\\u00a0       PostProcessScratchData                               &scratch,\\n\\u00a0       unsigned int                                         &empty_data);\\n\\u00a0 \\n\\u00a0 \\n\\u00a0     Triangulation<dim> triangulation;\\n\\u00a0 \\nTriangulationDefinition tria.h:1323\\nDoFHandler::active_cell_iteratortypename ActiveSelector::active_cell_iterator active_cell_iteratorDefinition dof_handler.h:440\\ntriangulationconst ::parallel::distributed::Triangulation< dim, spacedim > * triangulationDefinition p4est_wrappers.cc:68\\nThe 'local' solutions are interior to each element. These represent the primal solution field \\\\(u\\\\) as well as the auxiliary field \\\\(\\\\mathbf{q}\\\\).\\n\\u00a0     const FESystem<dim> fe_local;\\n\\u00a0     DoFHandler<dim>     dof_handler_local;\\n\\u00a0     Vector<double>      solution_local;\\n\\u00a0 \\nDoFHandlerDefinition dof_handler.h:317\\nFESystemDefinition fe_system.h:208\\nThe new finite element type and corresponding DoFHandler are used for the global skeleton solution that couples the element-level local solutions.\\n\\u00a0     const FE_FaceQ<dim> fe;\\n\\u00a0     DoFHandler<dim>     dof_handler;\\n\\u00a0     Vector<double>      solution;\\n\\u00a0     Vector<double>      system_rhs;\\n\\u00a0 \\nFE_FaceQDefinition fe_face.h:56\\nAs stated in the introduction, HDG solutions can be post-processed to attain superconvergence rates of \\\\(\\\\mathcal{O}(h^{p+2})\\\\). The post-processed solution is a discontinuous finite element solution representing the primal variable on the interior of each cell. We define a FE type of degree \\\\(p+1\\\\) to represent this post-processed solution, which we only use for output after constructing it.\\n\\u00a0     const FE_DGQ<dim> fe_u_post;\\n\\u00a0     DoFHandler<dim>   dof_handler_u_post;\\n\\u00a0     Vector<double>    solution_u_post;\\n\\u00a0 \\nFE_DGQDefinition fe_dgq.h:112\\nThe degrees of freedom corresponding to the skeleton strongly enforce Dirichlet boundary conditions, just as in a continuous Galerkin finite element method. We can enforce the boundary conditions in an analogous manner via an AffineConstraints object. In addition, hanging nodes are handled in the same way as for continuous finite elements: For the face elements which only define degrees of freedom on the face, this process sets the solution on the refined side to coincide with the representation on the coarse side.\\nNote that for HDG, the elimination of hanging nodes is not the only possibility \\u2014 in terms of the HDG theory, one could also use the unknowns from the refined side and express the local solution on the coarse side through the trace values on the refined side. However, such a setup is not as easily implemented in terms of deal.II loops and not further analyzed.\\n\\u00a0     AffineConstraints<double> constraints;\\n\\u00a0 \\nAffineConstraintsDefinition affine_constraints.h:507\\nThe usage of the ChunkSparseMatrix class is similar to the usual sparse matrices: You need a sparsity pattern of type ChunkSparsityPattern and the actual matrix object. When creating the sparsity pattern, we just have to additionally pass the size of local blocks.\\n\\u00a0     ChunkSparsityPattern      sparsity_pattern;\\n\\u00a0     ChunkSparseMatrix<double> system_matrix;\\n\\u00a0 \\nChunkSparseMatrixDefinition chunk_sparse_matrix.h:449\\nChunkSparsityPatternDefinition chunk_sparsity_pattern.h:245\\nSame as step-7:\\n\\u00a0     const RefinementMode refinement_mode;\\n\\u00a0     ConvergenceTable     convergence_table;\\n\\u00a0   };\\n\\u00a0 \\nConvergenceTableDefinition convergence_table.h:64\\n The HDG class implementation\\n Constructor\\nThe constructor is similar to those in other examples, with the exception of handling multiple DoFHandler and FiniteElement objects. Note that we create a system of finite elements for the local DG part, including the gradient/flux part and the scalar part.\\n\\u00a0   template <int dim>\\n\\u00a0   HDG<dim>::HDG(const unsigned int degree, const RefinementMode refinement_mode)\\n\\u00a0     : fe_local(FE_DGQ<dim>(degree) ^ dim, FE_DGQ<dim>(degree))\\n\\u00a0     , dof_handler_local(triangulation)\\n\\u00a0     , fe(degree)\\n\\u00a0     , dof_handler(triangulation)\\n\\u00a0     , fe_u_post(degree + 1)\\n\\u00a0     , dof_handler_u_post(triangulation)\\n\\u00a0     , refinement_mode(refinement_mode)\\n\\u00a0   {}\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n HDG::setup_system\\nThe system for an HDG solution is setup in an analogous manner to most of the other tutorial programs. We are careful to distribute dofs with all of our DoFHandler objects. The solution and system_matrix objects go with the global skeleton solution.\\n\\u00a0   template <int dim>\\n\\u00a0   void HDG<dim>::setup_system()\\n\\u00a0   {\\n\\u00a0     dof_handler_local.distribute_dofs(fe_local);\\n\\u00a0     dof_handler.distribute_dofs(fe);\\n\\u00a0     dof_handler_u_post.distribute_dofs(fe_u_post);\\n\\u00a0 \\n\\u00a0     std::cout << \\\"   Number of degrees of freedom: \\\" << dof_handler.n_dofs()\\n\\u00a0               << std::endl;\\n\\u00a0 \\n\\u00a0     solution.reinit(dof_handler.n_dofs());\\n\\u00a0     system_rhs.reinit(dof_handler.n_dofs());\\n\\u00a0 \\n\\u00a0     solution_local.reinit(dof_handler_local.n_dofs());\\n\\u00a0     solution_u_post.reinit(dof_handler_u_post.n_dofs());\\n\\u00a0 \\n\\u00a0     constraints.clear();\\n\\u00a0     DoFTools::make_hanging_node_constraints(dof_handler, constraints);\\n\\u00a0     std::map<types::boundary_id, const Function<dim> *> boundary_functions;\\n\\u00a0     Solution<dim>                                       solution_function;\\n\\u00a0     boundary_functions[0] = &solution_function;\\n\\u00a0     VectorTools::project_boundary_values(dof_handler,\\n\\u00a0                                          boundary_functions,\\n\\u00a0                                          QGauss<dim - 1>(fe.degree + 1),\\n\\u00a0                                          constraints);\\n\\u00a0     constraints.close();\\n\\u00a0 \\nQGaussDefinition quadrature_lib.h:40\\nDoFTools::make_hanging_node_constraintsvoid make_hanging_node_constraints(const DoFHandler< dim, spacedim > &dof_handler, AffineConstraints< number > &constraints)Definition dof_tools_constraints.cc:3073\\nVectorTools::project_boundary_valuesvoid project_boundary_values(const Mapping< dim, spacedim > &mapping, const DoFHandler< dim, spacedim > &dof, const std::map< types::boundary_id, const Function< spacedim, number > * > &boundary_functions, const Quadrature< dim - 1 > &q, std::map< types::global_dof_index, number > &boundary_values, std::vector< unsigned int > component_mapping={})\\nWhen creating the chunk sparsity pattern, we first create the usual dynamic sparsity pattern and then set the chunk size, which is equal to the number of dofs on a face, when copying this into the final sparsity pattern.\\n\\u00a0     {\\n\\u00a0       DynamicSparsityPattern dsp(dof_handler.n_dofs());\\n\\u00a0       DoFTools::make_sparsity_pattern(dof_handler, dsp, constraints, false);\\n\\u00a0       sparsity_pattern.copy_from(dsp, fe.n_dofs_per_face());\\n\\u00a0     }\\n\\u00a0     system_matrix.reinit(sparsity_pattern);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nDynamicSparsityPatternDefinition dynamic_sparsity_pattern.h:322\\nDoFTools::make_sparsity_patternvoid make_sparsity_pattern(const DoFHandler< dim, spacedim > &dof_handler, SparsityPatternBase &sparsity_pattern, const AffineConstraints< number > &constraints={}, const bool keep_constrained_dofs=true, const types::subdomain_id subdomain_id=numbers::invalid_subdomain_id)Definition dof_tools_sparsity.cc:56\\n HDG::PerTaskData\\nNext comes the definition of the local data structures for the parallel assembly. The first structure PerTaskData contains the local vector and matrix that are written into the global matrix, whereas the ScratchData contains all data that we need for the local assembly. There is one variable worth noting here, namely the boolean variable trace_reconstruct. As mentioned in the introduction, we solve the HDG system in two steps. First, we create a linear system for the skeleton system where we condense the local part into it via the Schur complement \\\\(D-CA^{-1}B\\\\). Then, we solve for the local part using the skeleton solution. For these two steps, we need the same matrices on the elements twice, which we want to compute by two assembly steps. Since most of the code is similar, we do this with the same function but only switch between the two based on a flag that we set when starting the assembly. Since we need to pass this information on to the local worker routines, we store it once in the task data.\\n\\u00a0   template <int dim>\\n\\u00a0   struct HDG<dim>::PerTaskData\\n\\u00a0   {\\n\\u00a0     FullMatrix<double>                   cell_matrix;\\n\\u00a0     Vector<double>                       cell_vector;\\n\\u00a0     std::vector<types::global_dof_index> dof_indices;\\n\\u00a0 \\n\\u00a0     bool trace_reconstruct;\\n\\u00a0 \\n\\u00a0     PerTaskData(const unsigned int n_dofs, const bool trace_reconstruct)\\n\\u00a0       : cell_matrix(n_dofs, n_dofs)\\n\\u00a0       , cell_vector(n_dofs)\\n\\u00a0       , dof_indices(n_dofs)\\n\\u00a0       , trace_reconstruct(trace_reconstruct)\\n\\u00a0     {}\\n\\u00a0   };\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nFullMatrixDefinition full_matrix.h:79\\n HDG::ScratchData\\nScratchData contains persistent data for each thread within WorkStream. The FEValues, matrix, and vector objects should be familiar by now. There are two objects that need to be discussed: std::vector<std::vector<unsigned int> > fe_local_support_on_face and std::vector<std::vector<unsigned int> > fe_support_on_face. These are used to indicate whether or not the finite elements chosen have support (non-zero values) on a given face of the reference cell for the local part associated to fe_local and the skeleton part fe. We extract this information in the constructor and store it once for all cells that we work on. Had we not stored this information, we would be forced to assemble a large number of zero terms on each cell, which would significantly slow the program.\\n\\u00a0   template <int dim>\\n\\u00a0   struct HDG<dim>::ScratchData\\n\\u00a0   {\\n\\u00a0     FEValues<dim>     fe_values_local;\\n\\u00a0     FEFaceValues<dim> fe_face_values_local;\\n\\u00a0     FEFaceValues<dim> fe_face_values;\\n\\u00a0 \\n\\u00a0     FullMatrix<double> ll_matrix;\\n\\u00a0     FullMatrix<double> lf_matrix;\\n\\u00a0     FullMatrix<double> fl_matrix;\\n\\u00a0     FullMatrix<double> tmp_matrix;\\n\\u00a0     Vector<double>     l_rhs;\\n\\u00a0     Vector<double>     tmp_rhs;\\n\\u00a0 \\n\\u00a0     std::vector<Tensor<1, dim>> q_phi;\\n\\u00a0     std::vector<double>         q_phi_div;\\n\\u00a0     std::vector<double>         u_phi;\\n\\u00a0     std::vector<Tensor<1, dim>> u_phi_grad;\\n\\u00a0     std::vector<double>         tr_phi;\\n\\u00a0     std::vector<double>         trace_values;\\n\\u00a0 \\n\\u00a0     std::vector<std::vector<unsigned int>> fe_local_support_on_face;\\n\\u00a0     std::vector<std::vector<unsigned int>> fe_support_on_face;\\n\\u00a0 \\n\\u00a0     ConvectionVelocity<dim> convection_velocity;\\n\\u00a0     RightHandSide<dim>      right_hand_side;\\n\\u00a0     const Solution<dim>     exact_solution;\\n\\u00a0 \\n\\u00a0     ScratchData(const FiniteElement<dim> &fe,\\n\\u00a0                 const FiniteElement<dim> &fe_local,\\n\\u00a0                 const QGauss<dim>        &quadrature_formula,\\n\\u00a0                 const QGauss<dim - 1>    &face_quadrature_formula,\\n\\u00a0                 const UpdateFlags         local_flags,\\n\\u00a0                 const UpdateFlags         local_face_flags,\\n\\u00a0                 const UpdateFlags         flags)\\n\\u00a0       : fe_values_local(fe_local, quadrature_formula, local_flags)\\n\\u00a0       , fe_face_values_local(fe_local,\\n\\u00a0                              face_quadrature_formula,\\n\\u00a0                              local_face_flags)\\n\\u00a0       , fe_face_values(fe, face_quadrature_formula, flags)\\n\\u00a0       , ll_matrix(fe_local.n_dofs_per_cell(), fe_local.n_dofs_per_cell())\\n\\u00a0       , lf_matrix(fe_local.n_dofs_per_cell(), fe.n_dofs_per_cell())\\n\\u00a0       , fl_matrix(fe.n_dofs_per_cell(), fe_local.n_dofs_per_cell())\\n\\u00a0       , tmp_matrix(fe.n_dofs_per_cell(), fe_local.n_dofs_per_cell())\\n\\u00a0       , l_rhs(fe_local.n_dofs_per_cell())\\n\\u00a0       , tmp_rhs(fe_local.n_dofs_per_cell())\\n\\u00a0       , q_phi(fe_local.n_dofs_per_cell())\\n\\u00a0       , q_phi_div(fe_local.n_dofs_per_cell())\\n\\u00a0       , u_phi(fe_local.n_dofs_per_cell())\\n\\u00a0       , u_phi_grad(fe_local.n_dofs_per_cell())\\n\\u00a0       , tr_phi(fe.n_dofs_per_cell())\\n\\u00a0       , trace_values(face_quadrature_formula.size())\\n\\u00a0       , fe_local_support_on_face(GeometryInfo<dim>::faces_per_cell)\\n\\u00a0       , fe_support_on_face(GeometryInfo<dim>::faces_per_cell)\\n\\u00a0       , exact_solution()\\n\\u00a0     {\\n\\u00a0       for (const unsigned int face_no : GeometryInfo<dim>::face_indices())\\n\\u00a0         for (unsigned int i = 0; i < fe_local.n_dofs_per_cell(); ++i)\\n\\u00a0           {\\n\\u00a0             if (fe_local.has_support_on_face(i, face_no))\\n\\u00a0               fe_local_support_on_face[face_no].push_back(i);\\n\\u00a0           }\\n\\u00a0 \\n\\u00a0       for (const unsigned int face_no : GeometryInfo<dim>::face_indices())\\n\\u00a0         for (unsigned int i = 0; i < fe.n_dofs_per_cell(); ++i)\\n\\u00a0           {\\n\\u00a0             if (fe.has_support_on_face(i, face_no))\\n\\u00a0               fe_support_on_face[face_no].push_back(i);\\n\\u00a0           }\\n\\u00a0     }\\n\\u00a0 \\n\\u00a0     ScratchData(const ScratchData &sd)\\n\\u00a0       : fe_values_local(sd.fe_values_local.get_fe(),\\n\\u00a0                         sd.fe_values_local.get_quadrature(),\\n\\u00a0                         sd.fe_values_local.get_update_flags())\\n\\u00a0       , fe_face_values_local(sd.fe_face_values_local.get_fe(),\\n\\u00a0                              sd.fe_face_values_local.get_quadrature(),\\n\\u00a0                              sd.fe_face_values_local.get_update_flags())\\n\\u00a0       , fe_face_values(sd.fe_face_values.get_fe(),\\n\\u00a0                        sd.fe_face_values.get_quadrature(),\\n\\u00a0                        sd.fe_face_values.get_update_flags())\\n\\u00a0       , ll_matrix(sd.ll_matrix)\\n\\u00a0       , lf_matrix(sd.lf_matrix)\\n\\u00a0       , fl_matrix(sd.fl_matrix)\\n\\u00a0       , tmp_matrix(sd.tmp_matrix)\\n\\u00a0       , l_rhs(sd.l_rhs)\\n\\u00a0       , tmp_rhs(sd.tmp_rhs)\\n\\u00a0       , q_phi(sd.q_phi)\\n\\u00a0       , q_phi_div(sd.q_phi_div)\\n\\u00a0       , u_phi(sd.u_phi)\\n\\u00a0       , u_phi_grad(sd.u_phi_grad)\\n\\u00a0       , tr_phi(sd.tr_phi)\\n\\u00a0       , trace_values(sd.trace_values)\\n\\u00a0       , fe_local_support_on_face(sd.fe_local_support_on_face)\\n\\u00a0       , fe_support_on_face(sd.fe_support_on_face)\\n\\u00a0       , exact_solution()\\n\\u00a0     {}\\n\\u00a0   };\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nFEFaceValuesDefinition fe_values.h:322\\nFEValuesDefinition fe_values.h:63\\nFiniteElementData::n_dofs_per_cellunsigned int n_dofs_per_cell() const\\nFiniteElementDefinition fe.h:655\\nFiniteElement::has_support_on_facevirtual bool has_support_on_face(const unsigned int shape_index, const unsigned int face_index) const\\nint\\nUpdateFlagsUpdateFlagsDefinition fe_update_flags.h:64\\nGeometryInfoDefinition geometry_info.h:1964\\n HDG::PostProcessScratchData\\nPostProcessScratchData contains the data used by WorkStream when post-processing the local solution \\\\(u^*\\\\). It is similar, but much simpler, than ScratchData.\\n\\u00a0   template <int dim>\\n\\u00a0   struct HDG<dim>::PostProcessScratchData\\n\\u00a0   {\\n\\u00a0     FEValues<dim> fe_values_local;\\n\\u00a0     FEValues<dim> fe_values;\\n\\u00a0 \\n\\u00a0     std::vector<double>         u_values;\\n\\u00a0     std::vector<Tensor<1, dim>> u_gradients;\\n\\u00a0     FullMatrix<double>          cell_matrix;\\n\\u00a0 \\n\\u00a0     Vector<double> cell_rhs;\\n\\u00a0     Vector<double> cell_sol;\\n\\u00a0 \\n\\u00a0     PostProcessScratchData(const FiniteElement<dim> &fe,\\n\\u00a0                            const FiniteElement<dim> &fe_local,\\n\\u00a0                            const QGauss<dim>        &quadrature_formula,\\n\\u00a0                            const UpdateFlags         local_flags,\\n\\u00a0                            const UpdateFlags         flags)\\n\\u00a0       : fe_values_local(fe_local, quadrature_formula, local_flags)\\n\\u00a0       , fe_values(fe, quadrature_formula, flags)\\n\\u00a0       , u_values(quadrature_formula.size())\\n\\u00a0       , u_gradients(quadrature_formula.size())\\n\\u00a0       , cell_matrix(fe.n_dofs_per_cell(), fe.n_dofs_per_cell())\\n\\u00a0       , cell_rhs(fe.n_dofs_per_cell())\\n\\u00a0       , cell_sol(fe.n_dofs_per_cell())\\n\\u00a0     {}\\n\\u00a0 \\n\\u00a0     PostProcessScratchData(const PostProcessScratchData &sd)\\n\\u00a0       : fe_values_local(sd.fe_values_local.get_fe(),\\n\\u00a0                         sd.fe_values_local.get_quadrature(),\\n\\u00a0                         sd.fe_values_local.get_update_flags())\\n\\u00a0       , fe_values(sd.fe_values.get_fe(),\\n\\u00a0                   sd.fe_values.get_quadrature(),\\n\\u00a0                   sd.fe_values.get_update_flags())\\n\\u00a0       , u_values(sd.u_values)\\n\\u00a0       , u_gradients(sd.u_gradients)\\n\\u00a0       , cell_matrix(sd.cell_matrix)\\n\\u00a0       , cell_rhs(sd.cell_rhs)\\n\\u00a0       , cell_sol(sd.cell_sol)\\n\\u00a0     {}\\n\\u00a0   };\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n HDG::assemble_system\\nThe assemble_system function is similar to the one on step-32, where the quadrature formula and the update flags are set up, and then WorkStream is used to do the work in a multi-threaded manner. The trace_reconstruct input parameter is used to decide whether we are solving for the global skeleton solution (false) or the local solution (true).\\nOne thing worth noting for the multi-threaded execution of assembly is the fact that the local computations in assemble_system_one_cell() call into BLAS and LAPACK functions if those are available in deal.II. Thus, the underlying BLAS/LAPACK library must support calls from multiple threads at the same time. Most implementations do support this, but some libraries need to be built in a specific way to avoid problems. For example, OpenBLAS compiled without multithreading inside the BLAS/LAPACK calls needs to built with a flag called USE_LOCKING set to true.\\n\\u00a0   template <int dim>\\n\\u00a0   void HDG<dim>::assemble_system(const bool trace_reconstruct)\\n\\u00a0   {\\n\\u00a0     const QGauss<dim>     quadrature_formula(fe.degree + 1);\\n\\u00a0     const QGauss<dim - 1> face_quadrature_formula(fe.degree + 1);\\n\\u00a0 \\n\\u00a0     const UpdateFlags local_flags(update_values | update_gradients |\\n\\u00a0                                   update_JxW_values | update_quadrature_points);\\n\\u00a0 \\n\\u00a0     const UpdateFlags local_face_flags(update_values);\\n\\u00a0 \\n\\u00a0     const UpdateFlags flags(update_values | update_normal_vectors |\\n\\u00a0                             update_quadrature_points | update_JxW_values);\\n\\u00a0 \\n\\u00a0     PerTaskData task_data(fe.n_dofs_per_cell(), trace_reconstruct);\\n\\u00a0     ScratchData scratch(fe,\\n\\u00a0                         fe_local,\\n\\u00a0                         quadrature_formula,\\n\\u00a0                         face_quadrature_formula,\\n\\u00a0                         local_flags,\\n\\u00a0                         local_face_flags,\\n\\u00a0                         flags);\\n\\u00a0 \\n\\u00a0     WorkStream::run(dof_handler.begin_active(),\\n\\u00a0                     dof_handler.end(),\\n\\u00a0                     *this,\\n\\u00a0                     &HDG<dim>::assemble_system_one_cell,\\n\\u00a0                     &HDG<dim>::copy_local_to_global,\\n\\u00a0                     scratch,\\n\\u00a0                     task_data);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nFiniteElementData::degreeconst unsigned int degreeDefinition fe_data.h:452\\nupdate_values@ update_valuesShape function values.Definition fe_update_flags.h:75\\nupdate_normal_vectors@ update_normal_vectorsNormal vectors.Definition fe_update_flags.h:141\\nupdate_JxW_values@ update_JxW_valuesTransformed quadrature weights.Definition fe_update_flags.h:134\\nupdate_gradients@ update_gradientsShape function gradients.Definition fe_update_flags.h:81\\nupdate_quadrature_points@ update_quadrature_pointsTransformed quadrature points.Definition fe_update_flags.h:127\\nWorkStream::runvoid run(const std::vector< std::vector< Iterator > > &colored_iterators, Worker worker, Copier copier, const ScratchData &sample_scratch_data, const CopyData &sample_copy_data, const unsigned int queue_length=2 *MultithreadInfo::n_threads(), const unsigned int chunk_size=8)Definition work_stream.h:1272\\n HDG::assemble_system_one_cell\\nThe real work of the HDG program is done by assemble_system_one_cell. Assembling the local matrices \\\\(A, B, C\\\\) is done here, along with the local contributions of the global matrix \\\\(D\\\\).\\n\\u00a0   template <int dim>\\n\\u00a0   void HDG<dim>::assemble_system_one_cell(\\n\\u00a0     const typename DoFHandler<dim>::active_cell_iterator &cell,\\n\\u00a0     ScratchData                                          &scratch,\\n\\u00a0     PerTaskData                                          &task_data)\\n\\u00a0   {\\nConstruct iterator for dof_handler_local for FEValues reinit function.\\n\\u00a0     const typename DoFHandler<dim>::active_cell_iterator loc_cell =\\n\\u00a0       cell->as_dof_handler_iterator(dof_handler_local);\\n\\u00a0 \\n\\u00a0     const unsigned int n_q_points =\\n\\u00a0       scratch.fe_values_local.get_quadrature().size();\\n\\u00a0     const unsigned int n_face_q_points =\\n\\u00a0       scratch.fe_face_values_local.get_quadrature().size();\\n\\u00a0 \\n\\u00a0     const unsigned int loc_dofs_per_cell =\\n\\u00a0       scratch.fe_values_local.get_fe().n_dofs_per_cell();\\n\\u00a0 \\n\\u00a0     const FEValuesExtractors::Vector fluxes(0);\\n\\u00a0     const FEValuesExtractors::Scalar scalar(dim);\\n\\u00a0 \\n\\u00a0     scratch.ll_matrix = 0;\\n\\u00a0     scratch.l_rhs     = 0;\\n\\u00a0     if (!task_data.trace_reconstruct)\\n\\u00a0       {\\n\\u00a0         scratch.lf_matrix     = 0;\\n\\u00a0         scratch.fl_matrix     = 0;\\n\\u00a0         task_data.cell_matrix = 0;\\n\\u00a0         task_data.cell_vector = 0;\\n\\u00a0       }\\n\\u00a0     scratch.fe_values_local.reinit(loc_cell);\\n\\u00a0 \\nFEValuesExtractors::ScalarDefinition fe_values_extractors.h:95\\nFEValuesExtractors::VectorDefinition fe_values_extractors.h:150\\nWe first compute the cell-interior contribution to ll_matrix matrix (referred to as matrix \\\\(A\\\\) in the introduction) corresponding to local-local coupling, as well as the local right-hand-side vector. We store the values at each quadrature point for the basis functions, the right-hand-side value, and the convection velocity, in order to have quick access to these fields.\\n\\u00a0     for (unsigned int q = 0; q < n_q_points; ++q)\\n\\u00a0       {\\n\\u00a0         const double rhs_value = scratch.right_hand_side.value(\\n\\u00a0           scratch.fe_values_local.quadrature_point(q));\\n\\u00a0         const Tensor<1, dim> convection = scratch.convection_velocity.value(\\n\\u00a0           scratch.fe_values_local.quadrature_point(q));\\n\\u00a0         const double JxW = scratch.fe_values_local.JxW(q);\\n\\u00a0         for (unsigned int k = 0; k < loc_dofs_per_cell; ++k)\\n\\u00a0           {\\n\\u00a0             scratch.q_phi[k] = scratch.fe_values_local[fluxes].value(k, q);\\n\\u00a0             scratch.q_phi_div[k] =\\n\\u00a0               scratch.fe_values_local[fluxes].divergence(k, q);\\n\\u00a0             scratch.u_phi[k] = scratch.fe_values_local[scalar].value(k, q);\\n\\u00a0             scratch.u_phi_grad[k] =\\n\\u00a0               scratch.fe_values_local[scalar].gradient(k, q);\\n\\u00a0           }\\n\\u00a0         for (unsigned int i = 0; i < loc_dofs_per_cell; ++i)\\n\\u00a0           {\\n\\u00a0             for (unsigned int j = 0; j < loc_dofs_per_cell; ++j)\\n\\u00a0               scratch.ll_matrix(i, j) +=\\n\\u00a0                 (scratch.q_phi[i] * scratch.q_phi[j] -\\n\\u00a0                  scratch.q_phi_div[i] * scratch.u_phi[j] +\\n\\u00a0                  scratch.u_phi[i] * scratch.q_phi_div[j] -\\n\\u00a0                  (scratch.u_phi_grad[i] * convection) * scratch.u_phi[j]) *\\n\\u00a0                 JxW;\\n\\u00a0             scratch.l_rhs(i) += scratch.u_phi[i] * rhs_value * JxW;\\n\\u00a0           }\\n\\u00a0       }\\n\\u00a0 \\nFace terms are assembled on all faces of all elements. This is in contrast to more traditional DG methods, where each face is only visited once in the assembly procedure.\\n\\u00a0     for (const auto face_no : cell->face_indices())\\n\\u00a0       {\\n\\u00a0         scratch.fe_face_values_local.reinit(loc_cell, face_no);\\n\\u00a0         scratch.fe_face_values.reinit(cell, face_no);\\n\\u00a0 \\nThe already obtained \\\\(\\\\hat{u}\\\\) values are needed when solving for the local variables.\\n\\u00a0         if (task_data.trace_reconstruct)\\n\\u00a0           scratch.fe_face_values.get_function_values(solution,\\n\\u00a0                                                      scratch.trace_values);\\n\\u00a0 \\n\\u00a0         for (unsigned int q = 0; q < n_face_q_points; ++q)\\n\\u00a0           {\\n\\u00a0             const double     JxW = scratch.fe_face_values.JxW(q);\\n\\u00a0             const Point<dim> quadrature_point =\\n\\u00a0               scratch.fe_face_values.quadrature_point(q);\\n\\u00a0             const Tensor<1, dim> normal =\\n\\u00a0               scratch.fe_face_values.normal_vector(q);\\n\\u00a0             const Tensor<1, dim> convection =\\n\\u00a0               scratch.convection_velocity.value(quadrature_point);\\n\\u00a0 \\nHere we compute the stabilization parameter discussed in the introduction: since the diffusion is one and the diffusion length scale is set to 1/5, it simply results in a contribution of 5 for the diffusion part and the magnitude of convection through the element boundary in a centered scheme for the convection part.\\n\\u00a0             const double tau_stab = (5. + std::abs(convection * normal));\\n\\u00a0 \\nstd::abs::VectorizedArray< Number, width > abs(const ::VectorizedArray< Number, width > &)Definition vectorization.h:6927\\nWe store the non-zero flux and scalar values, making use of the support_on_face information we created in ScratchData.\\n\\u00a0             for (unsigned int k = 0;\\n\\u00a0                  k < scratch.fe_local_support_on_face[face_no].size();\\n\\u00a0                  ++k)\\n\\u00a0               {\\n\\u00a0                 const unsigned int kk =\\n\\u00a0                   scratch.fe_local_support_on_face[face_no][k];\\n\\u00a0                 scratch.q_phi[k] =\\n\\u00a0                   scratch.fe_face_values_local[fluxes].value(kk, q);\\n\\u00a0                 scratch.u_phi[k] =\\n\\u00a0                   scratch.fe_face_values_local[scalar].value(kk, q);\\n\\u00a0               }\\n\\u00a0 \\nWhen trace_reconstruct=false, we are preparing to assemble the system for the skeleton variable \\\\(\\\\hat{u}\\\\). If this is the case, we must assemble all local matrices associated with the problem: local-local, local-face, face-local, and face-face. The face-face matrix is stored as TaskData::cell_matrix, so that it can be assembled into the global system by copy_local_to_global.\\n\\u00a0             if (!task_data.trace_reconstruct)\\n\\u00a0               {\\n\\u00a0                 for (unsigned int k = 0;\\n\\u00a0                      k < scratch.fe_support_on_face[face_no].size();\\n\\u00a0                      ++k)\\n\\u00a0                   scratch.tr_phi[k] = scratch.fe_face_values.shape_value(\\n\\u00a0                     scratch.fe_support_on_face[face_no][k], q);\\n\\u00a0                 for (unsigned int i = 0;\\n\\u00a0                      i < scratch.fe_local_support_on_face[face_no].size();\\n\\u00a0                      ++i)\\n\\u00a0                   for (unsigned int j = 0;\\n\\u00a0                        j < scratch.fe_support_on_face[face_no].size();\\n\\u00a0                        ++j)\\n\\u00a0                     {\\n\\u00a0                       const unsigned int ii =\\n\\u00a0                         scratch.fe_local_support_on_face[face_no][i];\\n\\u00a0                       const unsigned int jj =\\n\\u00a0                         scratch.fe_support_on_face[face_no][j];\\n\\u00a0                       scratch.lf_matrix(ii, jj) +=\\n\\u00a0                         ((scratch.q_phi[i] * normal +\\n\\u00a0                           (convection * normal - tau_stab) * scratch.u_phi[i]) *\\n\\u00a0                          scratch.tr_phi[j]) *\\n\\u00a0                         JxW;\\n\\u00a0 \\nNote the sign of the face_no-local matrix. We negate the sign during assembly here so that we can use the FullMatrix::mmult with addition when computing the Schur complement.\\n\\u00a0                       scratch.fl_matrix(jj, ii) -=\\n\\u00a0                         ((scratch.q_phi[i] * normal +\\n\\u00a0                           tau_stab * scratch.u_phi[i]) *\\n\\u00a0                          scratch.tr_phi[j]) *\\n\\u00a0                         JxW;\\n\\u00a0                     }\\n\\u00a0 \\n\\u00a0                 for (unsigned int i = 0;\\n\\u00a0                      i < scratch.fe_support_on_face[face_no].size();\\n\\u00a0                      ++i)\\n\\u00a0                   for (unsigned int j = 0;\\n\\u00a0                        j < scratch.fe_support_on_face[face_no].size();\\n\\u00a0                        ++j)\\n\\u00a0                     {\\n\\u00a0                       const unsigned int ii =\\n\\u00a0                         scratch.fe_support_on_face[face_no][i];\\n\\u00a0                       const unsigned int jj =\\n\\u00a0                         scratch.fe_support_on_face[face_no][j];\\n\\u00a0                       task_data.cell_matrix(ii, jj) +=\\n\\u00a0                         ((convection * normal - tau_stab) * scratch.tr_phi[i] *\\n\\u00a0                          scratch.tr_phi[j]) *\\n\\u00a0                         JxW;\\n\\u00a0                     }\\n\\u00a0 \\n\\u00a0                 if (cell->face(face_no)->at_boundary() &&\\n\\u00a0                     (cell->face(face_no)->boundary_id() == 1))\\n\\u00a0                   {\\n\\u00a0                     const double neumann_value =\\n\\u00a0                       -scratch.exact_solution.gradient(quadrature_point) *\\n\\u00a0                         normal +\\n\\u00a0                       convection * normal *\\n\\u00a0                         scratch.exact_solution.value(quadrature_point);\\n\\u00a0                     for (unsigned int i = 0;\\n\\u00a0                          i < scratch.fe_support_on_face[face_no].size();\\n\\u00a0                          ++i)\\n\\u00a0                       {\\n\\u00a0                         const unsigned int ii =\\n\\u00a0                           scratch.fe_support_on_face[face_no][i];\\n\\u00a0                         task_data.cell_vector(ii) +=\\n\\u00a0                           scratch.tr_phi[i] * neumann_value * JxW;\\n\\u00a0                       }\\n\\u00a0                   }\\n\\u00a0               }\\n\\u00a0 \\nThis last term adds the contribution of the term  \\\\(\\\\left<w,\\\\tau\\n   u_h\\\\right>_{\\\\partial \\\\mathcal T}\\\\) to the local matrix. As opposed to the face matrices above, we need it in both assembly stages.\\n\\u00a0             for (unsigned int i = 0;\\n\\u00a0                  i < scratch.fe_local_support_on_face[face_no].size();\\n\\u00a0                  ++i)\\n\\u00a0               for (unsigned int j = 0;\\n\\u00a0                    j < scratch.fe_local_support_on_face[face_no].size();\\n\\u00a0                    ++j)\\n\\u00a0                 {\\n\\u00a0                   const unsigned int ii =\\n\\u00a0                     scratch.fe_local_support_on_face[face_no][i];\\n\\u00a0                   const unsigned int jj =\\n\\u00a0                     scratch.fe_local_support_on_face[face_no][j];\\n\\u00a0                   scratch.ll_matrix(ii, jj) +=\\n\\u00a0                     tau_stab * scratch.u_phi[i] * scratch.u_phi[j] * JxW;\\n\\u00a0                 }\\n\\u00a0 \\nWhen trace_reconstruct=true, we are solving for the local solutions on an element by element basis. The local right-hand-side is calculated by replacing the basis functions tr_phi in the lf_matrix computation by the computed values trace_values. Of course, the sign of the matrix is now minus since we have moved everything to the other side of the equation.\\n\\u00a0             if (task_data.trace_reconstruct)\\n\\u00a0               for (unsigned int i = 0;\\n\\u00a0                    i < scratch.fe_local_support_on_face[face_no].size();\\n\\u00a0                    ++i)\\n\\u00a0                 {\\n\\u00a0                   const unsigned int ii =\\n\\u00a0                     scratch.fe_local_support_on_face[face_no][i];\\n\\u00a0                   scratch.l_rhs(ii) -=\\n\\u00a0                     (scratch.q_phi[i] * normal +\\n\\u00a0                      scratch.u_phi[i] * (convection * normal - tau_stab)) *\\n\\u00a0                     scratch.trace_values[q] * JxW;\\n\\u00a0                 }\\n\\u00a0           }\\n\\u00a0       }\\n\\u00a0 \\nOnce assembly of all of the local contributions is complete, we must either: (1) assemble the global system, or (2) compute the local solution values and save them. In either case, the first step is to invert the local-local matrix.\\n\\u00a0     scratch.ll_matrix.gauss_jordan();\\n\\u00a0 \\nFor (1), we compute the Schur complement and add it to the cell_matrix, matrix \\\\(D\\\\) in the introduction.\\n\\u00a0     if (task_data.trace_reconstruct == false)\\n\\u00a0       {\\n\\u00a0         scratch.fl_matrix.mmult(scratch.tmp_matrix, scratch.ll_matrix);\\n\\u00a0         scratch.tmp_matrix.vmult_add(task_data.cell_vector, scratch.l_rhs);\\n\\u00a0         scratch.tmp_matrix.mmult(task_data.cell_matrix,\\n\\u00a0                                  scratch.lf_matrix,\\n\\u00a0                                  true);\\n\\u00a0         cell->get_dof_indices(task_data.dof_indices);\\n\\u00a0       }\\nFor (2), we are simply solving (ll_matrix).(solution_local) = (l_rhs). Hence, we multiply l_rhs by our already inverted local-local matrix and store the result using the set_dof_values function.\\n\\u00a0     else\\n\\u00a0       {\\n\\u00a0         scratch.ll_matrix.vmult(scratch.tmp_rhs, scratch.l_rhs);\\n\\u00a0         loc_cell->set_dof_values(scratch.tmp_rhs, solution_local);\\n\\u00a0       }\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n HDG::copy_local_to_global\\nIf we are in the first step of the solution, i.e. trace_reconstruct=false, then we assemble the local matrices into the global system.\\n\\u00a0   template <int dim>\\n\\u00a0   void HDG<dim>::copy_local_to_global(const PerTaskData &data)\\n\\u00a0   {\\n\\u00a0     if (data.trace_reconstruct == false)\\n\\u00a0       constraints.distribute_local_to_global(data.cell_matrix,\\n\\u00a0                                              data.cell_vector,\\n\\u00a0                                              data.dof_indices,\\n\\u00a0                                              system_matrix,\\n\\u00a0                                              system_rhs);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n HDG::solve\\nThe skeleton solution is solved for by using a BiCGStab solver with identity preconditioner.\\n\\u00a0   template <int dim>\\n\\u00a0   void HDG<dim>::solve()\\n\\u00a0   {\\n\\u00a0     SolverControl                  solver_control(system_matrix.m() * 10,\\n\\u00a0                                  1e-11 * system_rhs.l2_norm());\\n\\u00a0     SolverBicgstab<Vector<double>> solver(solver_control);\\n\\u00a0     solver.solve(system_matrix, solution, system_rhs, PreconditionIdentity());\\n\\u00a0 \\n\\u00a0     std::cout << \\\"   Number of BiCGStab iterations: \\\"\\n\\u00a0               << solver_control.last_step() << std::endl;\\n\\u00a0 \\n\\u00a0     system_matrix.clear();\\n\\u00a0     sparsity_pattern.reinit(0, 0, 0, 1);\\n\\u00a0 \\n\\u00a0     constraints.distribute(solution);\\n\\u00a0 \\nPreconditionIdentityDefinition precondition.h:220\\nSolverBicgstabDefinition solver_bicgstab.h:81\\nSolverControlDefinition solver_control.h:67\\nOnce we have solved for the skeleton solution, we can solve for the local solutions in an element-by-element fashion. We do this by re-using the same assemble_system function but switching trace_reconstruct to true.\\n\\u00a0     assemble_system(true);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n HDG::postprocess\\nThe postprocess method serves two purposes. First, we want to construct a post-processed scalar variables in the element space of degree \\\\(p+1\\\\) that we hope will converge at order \\\\(p+2\\\\). This is again an element-by-element process and only involves the scalar solution as well as the gradient on the local cell. To do this, we introduce the already defined scratch data together with some update flags and run the work stream to do this in parallel.\\nSecondly, we want to compute discretization errors just as we did in step-7. The overall procedure is similar with calls to VectorTools::integrate_difference. The difference is in how we compute the errors for the scalar variable and the gradient variable. In step-7, we did this by computing L2_norm or H1_seminorm contributions. Here, we have a DoFHandler with these two contributions computed and sorted by their vector component, [0, dim) for the gradient and dim for the scalar. To compute their value, we hence use a ComponentSelectFunction with either of them, together with the SolutionAndGradient class introduced above that contains the analytic parts of either of them. Eventually, we also compute the L2-error of the post-processed solution and add the results into the convergence table.\\n\\u00a0   template <int dim>\\n\\u00a0   void HDG<dim>::postprocess()\\n\\u00a0   {\\n\\u00a0     {\\n\\u00a0       const QGauss<dim> quadrature_formula(fe_u_post.degree + 1);\\n\\u00a0       const UpdateFlags local_flags(update_values);\\n\\u00a0       const UpdateFlags flags(update_values | update_gradients |\\n\\u00a0                               update_JxW_values);\\n\\u00a0 \\n\\u00a0       PostProcessScratchData scratch(\\n\\u00a0         fe_u_post, fe_local, quadrature_formula, local_flags, flags);\\n\\u00a0 \\n\\u00a0       WorkStream::run(\\n\\u00a0         dof_handler_u_post.begin_active(),\\n\\u00a0         dof_handler_u_post.end(),\\n\\u00a0         [this](const typename DoFHandler<dim>::active_cell_iterator &cell,\\n\\u00a0                PostProcessScratchData                               &scratch,\\n\\u00a0                unsigned int                                         &data) {\\n\\u00a0           this->postprocess_one_cell(cell, scratch, data);\\n\\u00a0         },\\n\\u00a0         std::function<void(const unsigned int &)>(),\\n\\u00a0         scratch,\\n\\u00a0         0U);\\n\\u00a0     }\\n\\u00a0 \\n\\u00a0     Vector<float> difference_per_cell(triangulation.n_active_cells());\\n\\u00a0 \\n\\u00a0     ComponentSelectFunction<dim> value_select(dim, dim + 1);\\n\\u00a0     VectorTools::integrate_difference(dof_handler_local,\\n\\u00a0                                       solution_local,\\n\\u00a0                                       SolutionAndGradient<dim>(),\\n\\u00a0                                       difference_per_cell,\\n\\u00a0                                       QGauss<dim>(fe.degree + 2),\\n\\u00a0                                       VectorTools::L2_norm,\\n\\u00a0                                       &value_select);\\n\\u00a0     const double L2_error =\\n\\u00a0       VectorTools::compute_global_error(triangulation,\\n\\u00a0                                         difference_per_cell,\\n\\u00a0                                         VectorTools::L2_norm);\\n\\u00a0 \\n\\u00a0     ComponentSelectFunction<dim> gradient_select(\\n\\u00a0       std::pair<unsigned int, unsigned int>(0, dim), dim + 1);\\n\\u00a0     VectorTools::integrate_difference(dof_handler_local,\\n\\u00a0                                       solution_local,\\n\\u00a0                                       SolutionAndGradient<dim>(),\\n\\u00a0                                       difference_per_cell,\\n\\u00a0                                       QGauss<dim>(fe.degree + 2),\\n\\u00a0                                       VectorTools::L2_norm,\\n\\u00a0                                       &gradient_select);\\n\\u00a0     const double grad_error =\\n\\u00a0       VectorTools::compute_global_error(triangulation,\\n\\u00a0                                         difference_per_cell,\\n\\u00a0                                         VectorTools::L2_norm);\\n\\u00a0 \\n\\u00a0     VectorTools::integrate_difference(dof_handler_u_post,\\n\\u00a0                                       solution_u_post,\\n\\u00a0                                       Solution<dim>(),\\n\\u00a0                                       difference_per_cell,\\n\\u00a0                                       QGauss<dim>(fe.degree + 3),\\n\\u00a0                                       VectorTools::L2_norm);\\n\\u00a0     const double post_error =\\n\\u00a0       VectorTools::compute_global_error(triangulation,\\n\\u00a0                                         difference_per_cell,\\n\\u00a0                                         VectorTools::L2_norm);\\n\\u00a0 \\n\\u00a0     convergence_table.add_value(\\\"cells\\\", triangulation.n_active_cells());\\n\\u00a0     convergence_table.add_value(\\\"dofs\\\", dof_handler.n_dofs());\\n\\u00a0 \\n\\u00a0     convergence_table.add_value(\\\"val L2\\\", L2_error);\\n\\u00a0     convergence_table.set_scientific(\\\"val L2\\\", true);\\n\\u00a0     convergence_table.set_precision(\\\"val L2\\\", 3);\\n\\u00a0 \\n\\u00a0     convergence_table.add_value(\\\"grad L2\\\", grad_error);\\n\\u00a0     convergence_table.set_scientific(\\\"grad L2\\\", true);\\n\\u00a0     convergence_table.set_precision(\\\"grad L2\\\", 3);\\n\\u00a0 \\n\\u00a0     convergence_table.add_value(\\\"val L2-post\\\", post_error);\\n\\u00a0     convergence_table.set_scientific(\\\"val L2-post\\\", true);\\n\\u00a0     convergence_table.set_precision(\\\"val L2-post\\\", 3);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nComponentSelectFunctionDefinition function.h:582\\nTriangulation::n_active_cellsunsigned int n_active_cells() const\\nVectorTools::compute_global_errordouble compute_global_error(const Triangulation< dim, spacedim > &tria, const InVector &cellwise_error, const NormType &norm, const double exponent=2.)\\nVectorTools::L2_norm@ L2_normDefinition vector_tools_common.h:112\\nVectorTools::integrate_differencevoid integrate_difference(const Mapping< dim, spacedim > &mapping, const DoFHandler< dim, spacedim > &dof, const ReadVector< Number > &fe_function, const Function< spacedim, Number > &exact_solution, OutVector &difference, const Quadrature< dim > &q, const NormType &norm, const Function< spacedim, double > *weight=nullptr, const double exponent=2.)\\n HDG::postprocess_one_cell\\nThis is the actual work done for the postprocessing. According to the discussion in the introduction, we need to set up a system that projects the gradient part of the DG solution onto the gradient of the post-processed variable. Moreover, we need to set the average of the new post-processed variable to equal the average of the scalar DG solution on the cell.\\nMore technically speaking, the projection of the gradient is a system that would potentially fills our dofs_per_cell times dofs_per_cell matrix but is singular (the sum of all rows would be zero because the constant function has zero gradient). Therefore, we take one row away and use it for imposing the average of the scalar value. We pick the first row for the scalar part, even though we could pick any row for  \\\\(\\\\mathcal\\n   Q_{-p}\\\\) elements. However, had we used FE_DGP elements instead, the first row would correspond to the constant part already and deleting e.g. the last row would give us a singular system. This way, our program can also be used for those elements.\\n\\u00a0   template <int dim>\\n\\u00a0   void HDG<dim>::postprocess_one_cell(\\n\\u00a0     const typename DoFHandler<dim>::active_cell_iterator &cell,\\n\\u00a0     PostProcessScratchData                               &scratch,\\n\\u00a0     unsigned int &)\\n\\u00a0   {\\n\\u00a0     const typename DoFHandler<dim>::active_cell_iterator loc_cell =\\n\\u00a0       cell->as_dof_handler_iterator(dof_handler_local);\\n\\u00a0 \\n\\u00a0     scratch.fe_values_local.reinit(loc_cell);\\n\\u00a0     scratch.fe_values.reinit(cell);\\n\\u00a0 \\n\\u00a0     const FEValuesExtractors::Vector fluxes(0);\\n\\u00a0     const FEValuesExtractors::Scalar scalar(dim);\\n\\u00a0 \\n\\u00a0     const unsigned int n_q_points = scratch.fe_values.get_quadrature().size();\\n\\u00a0     const unsigned int dofs_per_cell = scratch.fe_values.dofs_per_cell;\\n\\u00a0 \\n\\u00a0     scratch.fe_values_local[scalar].get_function_values(solution_local,\\n\\u00a0                                                         scratch.u_values);\\n\\u00a0     scratch.fe_values_local[fluxes].get_function_values(solution_local,\\n\\u00a0                                                         scratch.u_gradients);\\n\\u00a0 \\n\\u00a0     double sum = 0;\\n\\u00a0     for (unsigned int i = 1; i < dofs_per_cell; ++i)\\n\\u00a0       {\\n\\u00a0         for (unsigned int j = 0; j < dofs_per_cell; ++j)\\n\\u00a0           {\\n\\u00a0             sum = 0;\\n\\u00a0             for (unsigned int q = 0; q < n_q_points; ++q)\\n\\u00a0               sum += (scratch.fe_values.shape_grad(i, q) *\\n\\u00a0                       scratch.fe_values.shape_grad(j, q)) *\\n\\u00a0                      scratch.fe_values.JxW(q);\\n\\u00a0             scratch.cell_matrix(i, j) = sum;\\n\\u00a0           }\\n\\u00a0 \\n\\u00a0         sum = 0;\\n\\u00a0         for (unsigned int q = 0; q < n_q_points; ++q)\\n\\u00a0           sum -= (scratch.fe_values.shape_grad(i, q) * scratch.u_gradients[q]) *\\n\\u00a0                  scratch.fe_values.JxW(q);\\n\\u00a0         scratch.cell_rhs(i) = sum;\\n\\u00a0       }\\n\\u00a0     for (unsigned int j = 0; j < dofs_per_cell; ++j)\\n\\u00a0       {\\n\\u00a0         sum = 0;\\n\\u00a0         for (unsigned int q = 0; q < n_q_points; ++q)\\n\\u00a0           sum += scratch.fe_values.shape_value(j, q) * scratch.fe_values.JxW(q);\\n\\u00a0         scratch.cell_matrix(0, j) = sum;\\n\\u00a0       }\\n\\u00a0     {\\n\\u00a0       sum = 0;\\n\\u00a0       for (unsigned int q = 0; q < n_q_points; ++q)\\n\\u00a0         sum += scratch.u_values[q] * scratch.fe_values.JxW(q);\\n\\u00a0       scratch.cell_rhs(0) = sum;\\n\\u00a0     }\\n\\u00a0 \\nHaving assembled all terms, we can again go on and solve the linear system. We invert the matrix and then multiply the inverse by the right hand side. An alternative (and more numerically stable) method would have been to only factorize the matrix and apply the factorization.\\n\\u00a0     scratch.cell_matrix.gauss_jordan();\\n\\u00a0     scratch.cell_matrix.vmult(scratch.cell_sol, scratch.cell_rhs);\\n\\u00a0     cell->distribute_local_to_global(scratch.cell_sol, solution_u_post);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n HDG::output_results\\nWe have 3 sets of results that we would like to output: the local solution, the post-processed local solution, and the skeleton solution. The former 2 both 'live' on element volumes, whereas the latter lives on codimension-1 surfaces of the triangulation. Our output_results function writes all local solutions to the same vtk file, even though they correspond to different DoFHandler objects. The graphical output for the skeleton variable is done through use of the DataOutFaces class.\\n\\u00a0   template <int dim>\\n\\u00a0   void HDG<dim>::output_results(const unsigned int cycle)\\n\\u00a0   {\\n\\u00a0     std::string filename;\\n\\u00a0     switch (refinement_mode)\\n\\u00a0       {\\n\\u00a0         case global_refinement:\\n\\u00a0           filename = \\\"solution-global\\\";\\n\\u00a0           break;\\n\\u00a0         case adaptive_refinement:\\n\\u00a0           filename = \\\"solution-adaptive\\\";\\n\\u00a0           break;\\n\\u00a0         default:\\n\\u00a0           DEAL_II_NOT_IMPLEMENTED();\\n\\u00a0       }\\n\\u00a0 \\n\\u00a0     std::string face_out(filename);\\n\\u00a0     face_out += \\\"-face\\\";\\n\\u00a0 \\n\\u00a0     filename += \\\"-q\\\" + Utilities::int_to_string(fe.degree, 1);\\n\\u00a0     filename += \\\"-\\\" + Utilities::int_to_string(cycle, 2);\\n\\u00a0     filename += \\\".vtk\\\";\\n\\u00a0     std::ofstream output(filename);\\n\\u00a0 \\n\\u00a0     DataOut<dim> data_out;\\n\\u00a0 \\nDataOutDefinition data_out.h:147\\nUtilities::int_to_stringstd::string int_to_string(const unsigned int value, const unsigned int digits=numbers::invalid_unsigned_int)Definition utilities.cc:470\\nWe first define the names and types of the local solution, and add the data to data_out.\\n\\u00a0     std::vector<std::string> names(dim, \\\"gradient\\\");\\n\\u00a0     names.emplace_back(\\\"solution\\\");\\n\\u00a0     std::vector<DataComponentInterpretation::DataComponentInterpretation>\\n\\u00a0       component_interpretation(\\n\\u00a0         dim + 1, DataComponentInterpretation::component_is_part_of_vector);\\n\\u00a0     component_interpretation[dim] =\\n\\u00a0       DataComponentInterpretation::component_is_scalar;\\n\\u00a0     data_out.add_data_vector(dof_handler_local,\\n\\u00a0                              solution_local,\\n\\u00a0                              names,\\n\\u00a0                              component_interpretation);\\n\\u00a0 \\nDataComponentInterpretation::component_is_scalar@ component_is_scalarDefinition data_component_interpretation.h:52\\nDataComponentInterpretation::component_is_part_of_vector@ component_is_part_of_vectorDefinition data_component_interpretation.h:58\\nThe second data item we add is the post-processed solution. In this case, it is a single scalar variable belonging to a different DoFHandler.\\n\\u00a0     std::vector<std::string> post_name(1, \\\"u_post\\\");\\n\\u00a0     std::vector<DataComponentInterpretation::DataComponentInterpretation>\\n\\u00a0       post_comp_type(1, DataComponentInterpretation::component_is_scalar);\\n\\u00a0     data_out.add_data_vector(dof_handler_u_post,\\n\\u00a0                              solution_u_post,\\n\\u00a0                              post_name,\\n\\u00a0                              post_comp_type);\\n\\u00a0 \\n\\u00a0     data_out.build_patches(fe.degree);\\n\\u00a0     data_out.write_vtk(output);\\n\\u00a0 \\n\\u00a0     face_out += \\\"-q\\\" + Utilities::int_to_string(fe.degree, 1);\\n\\u00a0     face_out += \\\"-\\\" + Utilities::int_to_string(cycle, 2);\\n\\u00a0     face_out += \\\".vtk\\\";\\n\\u00a0     std::ofstream face_output(face_out);\\n\\u00a0 \\nThe DataOutFaces class works analogously to the DataOut class when we have a DoFHandler that defines the solution on the skeleton of the triangulation. We treat it as such here, and the code is similar to that above.\\n\\u00a0     DataOutFaces<dim>        data_out_face(false);\\n\\u00a0     std::vector<std::string> face_name(1, \\\"u_hat\\\");\\n\\u00a0     std::vector<DataComponentInterpretation::DataComponentInterpretation>\\n\\u00a0       face_component_type(1, DataComponentInterpretation::component_is_scalar);\\n\\u00a0 \\n\\u00a0     data_out_face.add_data_vector(dof_handler,\\n\\u00a0                                   solution,\\n\\u00a0                                   face_name,\\n\\u00a0                                   face_component_type);\\n\\u00a0 \\n\\u00a0     data_out_face.build_patches(fe.degree);\\n\\u00a0     data_out_face.write_vtk(face_output);\\n\\u00a0   }\\n\\u00a0 \\nDataOutFacesDefinition data_out_faces.h:109\\n HDG::refine_grid\\nWe implement two different refinement cases for HDG, just as in step-7: adaptive_refinement and global_refinement. The global_refinement option recreates the entire triangulation every time. This is because we want to use a finer sequence of meshes than what we would get with one refinement step, namely 2, 3, 4, 6, 8, 12, 16, ... elements per direction.\\nThe adaptive_refinement mode uses the KellyErrorEstimator to give a decent indication of the non-regular regions in the scalar local solutions.\\n\\u00a0   template <int dim>\\n\\u00a0   void HDG<dim>::refine_grid(const unsigned int cycle)\\n\\u00a0   {\\n\\u00a0     if (cycle == 0)\\n\\u00a0       {\\n\\u00a0         GridGenerator::subdivided_hyper_cube(triangulation, 2, -1, 1);\\n\\u00a0         triangulation.refine_global(3 - dim);\\n\\u00a0       }\\n\\u00a0     else\\n\\u00a0       switch (refinement_mode)\\n\\u00a0         {\\n\\u00a0           case global_refinement:\\n\\u00a0             {\\n\\u00a0               triangulation.clear();\\n\\u00a0               GridGenerator::subdivided_hyper_cube(triangulation,\\n\\u00a0                                                    2 + (cycle % 2),\\n\\u00a0                                                    -1,\\n\\u00a0                                                    1);\\n\\u00a0               triangulation.refine_global(3 - dim + cycle / 2);\\n\\u00a0               break;\\n\\u00a0             }\\n\\u00a0 \\n\\u00a0           case adaptive_refinement:\\n\\u00a0             {\\n\\u00a0               Vector<float> estimated_error_per_cell(\\n\\u00a0                 triangulation.n_active_cells());\\n\\u00a0 \\n\\u00a0               const FEValuesExtractors::Scalar scalar(dim);\\n\\u00a0               std::map<types::boundary_id, const Function<dim> *>\\n\\u00a0                 neumann_boundary;\\n\\u00a0               KellyErrorEstimator<dim>::estimate(dof_handler_local,\\n\\u00a0                                                  QGauss<dim - 1>(fe.degree + 1),\\n\\u00a0                                                  neumann_boundary,\\n\\u00a0                                                  solution_local,\\n\\u00a0                                                  estimated_error_per_cell,\\n\\u00a0                                                  fe_local.component_mask(\\n\\u00a0                                                    scalar));\\n\\u00a0 \\n\\u00a0               GridRefinement::refine_and_coarsen_fixed_number(\\n\\u00a0                 triangulation, estimated_error_per_cell, 0.3, 0.);\\n\\u00a0 \\n\\u00a0               triangulation.execute_coarsening_and_refinement();\\n\\u00a0 \\n\\u00a0               break;\\n\\u00a0             }\\n\\u00a0 \\n\\u00a0           default:\\n\\u00a0             {\\n\\u00a0               DEAL_II_NOT_IMPLEMENTED();\\n\\u00a0             }\\n\\u00a0         }\\n\\u00a0 \\nKellyErrorEstimator::estimatestatic void estimate(const Mapping< dim, spacedim > &mapping, const DoFHandler< dim, spacedim > &dof, const Quadrature< dim - 1 > &quadrature, const std::map< types::boundary_id, const Function< spacedim, Number > * > &neumann_bc, const ReadVector< Number > &solution, Vector< float > &error, const ComponentMask &component_mask={}, const Function< spacedim > *coefficients=nullptr, const unsigned int n_threads=numbers::invalid_unsigned_int, const types::subdomain_id subdomain_id=numbers::invalid_subdomain_id, const types::material_id material_id=numbers::invalid_material_id, const Strategy strategy=cell_diameter_over_24)\\nTriangulation::refine_globalvoid refine_global(const unsigned int times=1)\\nparallel::distributed::Triangulation::execute_coarsening_and_refinementvirtual void execute_coarsening_and_refinement() overrideDefinition tria.cc:3320\\nparallel::distributed::Triangulation::clearvirtual void clear() overrideDefinition tria.cc:1864\\nGridGenerator::subdivided_hyper_cubevoid subdivided_hyper_cube(Triangulation< dim, spacedim > &tria, const unsigned int repetitions, const double left=0., const double right=1., const bool colorize=false)\\nGridRefinement::refine_and_coarsen_fixed_numbervoid refine_and_coarsen_fixed_number(Triangulation< dim, spacedim > &triangulation, const Vector< Number > &criteria, const double top_fraction_of_cells, const double bottom_fraction_of_cells, const unsigned int max_n_cells=std::numeric_limits< unsigned int >::max())Definition grid_refinement.cc:318\\ninternal::FEEvaluationImplHangingNodesRunnerTypes::scalar@ scalar\\nJust as in step-7, we set the boundary indicator of two of the faces to 1 where we want to specify Neumann boundary conditions instead of Dirichlet conditions. Since we re-create the triangulation every time for global refinement, the flags are set in every refinement step, not just at the beginning.\\n\\u00a0     for (const auto &cell : triangulation.cell_iterators())\\n\\u00a0       for (const auto &face : cell->face_iterators())\\n\\u00a0         if (face->at_boundary())\\n\\u00a0           if ((std::fabs(face->center()[0] - (-1)) < 1e-12) ||\\n\\u00a0               (std::fabs(face->center()[1] - (-1)) < 1e-12))\\n\\u00a0             face->set_boundary_id(1);\\n\\u00a0   }\\n\\u00a0 \\ncenterPoint< 3 > centerDefinition data_out_base.cc:267\\nstdSTL namespace.\\n HDG::run\\nThe functionality here is basically the same as step-7. We loop over 10 cycles, refining the grid on each one. At the end, convergence tables are created.\\n\\u00a0   template <int dim>\\n\\u00a0   void HDG<dim>::run()\\n\\u00a0   {\\n\\u00a0     for (unsigned int cycle = 0; cycle < 10; ++cycle)\\n\\u00a0       {\\n\\u00a0         std::cout << \\\"Cycle \\\" << cycle << ':' << std::endl;\\n\\u00a0 \\n\\u00a0         refine_grid(cycle);\\n\\u00a0         setup_system();\\n\\u00a0         assemble_system(false);\\n\\u00a0         solve();\\n\\u00a0         postprocess();\\n\\u00a0         output_results(cycle);\\n\\u00a0       }\\n\\u00a0 \\nThere is one minor change for the convergence table compared to step-7: Since we did not refine our mesh by a factor two in each cycle (but rather used the sequence 2, 3, 4, 6, 8, 12, ...), we need to tell the convergence rate evaluation about this. We do this by setting the number of cells as a reference column and additionally specifying the dimension of the problem, which gives the necessary information for the relation between number of cells and mesh size.\\n\\u00a0     if (refinement_mode == global_refinement)\\n\\u00a0       {\\n\\u00a0         convergence_table.evaluate_convergence_rates(\\n\\u00a0           \\\"val L2\\\", \\\"cells\\\", ConvergenceTable::reduction_rate_log2, dim);\\n\\u00a0         convergence_table.evaluate_convergence_rates(\\n\\u00a0           \\\"grad L2\\\", \\\"cells\\\", ConvergenceTable::reduction_rate_log2, dim);\\n\\u00a0         convergence_table.evaluate_convergence_rates(\\n\\u00a0           \\\"val L2-post\\\", \\\"cells\\\", ConvergenceTable::reduction_rate_log2, dim);\\n\\u00a0       }\\n\\u00a0     convergence_table.write_text(std::cout);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 } // end of namespace Step51\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0 int main()\\n\\u00a0 {\\n\\u00a0   const unsigned int dim = 2;\\n\\u00a0 \\n\\u00a0   try\\n\\u00a0     {\\nConvergenceTable::reduction_rate_log2@ reduction_rate_log2Definition convergence_table.h:88\\nNow for the three calls to the main class in complete analogy to step-7.\\n\\u00a0       {\\n\\u00a0         std::cout << \\\"Solving with Q1 elements, adaptive refinement\\\"\\n\\u00a0                   << std::endl\\n\\u00a0                   << \\\"=============================================\\\"\\n\\u00a0                   << std::endl\\n\\u00a0                   << std::endl;\\n\\u00a0 \\n\\u00a0         Step51::HDG<dim> hdg_problem(1, Step51::HDG<dim>::adaptive_refinement);\\n\\u00a0         hdg_problem.run();\\n\\u00a0 \\n\\u00a0         std::cout << std::endl;\\n\\u00a0       }\\n\\u00a0 \\n\\u00a0       {\\n\\u00a0         std::cout << \\\"Solving with Q1 elements, global refinement\\\" << std::endl\\n\\u00a0                   << \\\"===========================================\\\" << std::endl\\n\\u00a0                   << std::endl;\\n\\u00a0 \\n\\u00a0         Step51::HDG<dim> hdg_problem(1, Step51::HDG<dim>::global_refinement);\\n\\u00a0         hdg_problem.run();\\n\\u00a0 \\n\\u00a0         std::cout << std::endl;\\n\\u00a0       }\\n\\u00a0 \\n\\u00a0       {\\n\\u00a0         std::cout << \\\"Solving with Q3 elements, global refinement\\\" << std::endl\\n\\u00a0                   << \\\"===========================================\\\" << std::endl\\n\\u00a0                   << std::endl;\\n\\u00a0 \\n\\u00a0         Step51::HDG<dim> hdg_problem(3, Step51::HDG<dim>::global_refinement);\\n\\u00a0         hdg_problem.run();\\n\\u00a0 \\n\\u00a0         std::cout << std::endl;\\n\\u00a0       }\\n\\u00a0     }\\n\\u00a0   catch (std::exception &exc)\\n\\u00a0     {\\n\\u00a0       std::cerr << std::endl\\n\\u00a0                 << std::endl\\n\\u00a0                 << \\\"----------------------------------------------------\\\"\\n\\u00a0                 << std::endl;\\n\\u00a0       std::cerr << \\\"Exception on processing: \\\" << std::endl\\n\\u00a0                 << exc.what() << std::endl\\n\\u00a0                 << \\\"Aborting!\\\" << std::endl\\n\\u00a0                 << \\\"----------------------------------------------------\\\"\\n\\u00a0                 << std::endl;\\n\\u00a0       return 1;\\n\\u00a0     }\\n\\u00a0   catch (...)\\n\\u00a0     {\\n\\u00a0       std::cerr << std::endl\\n\\u00a0                 << std::endl\\n\\u00a0                 << \\\"----------------------------------------------------\\\"\\n\\u00a0                 << std::endl;\\n\\u00a0       std::cerr << \\\"Unknown exception!\\\" << std::endl\\n\\u00a0                 << \\\"Aborting!\\\" << std::endl\\n\\u00a0                 << \\\"----------------------------------------------------\\\"\\n\\u00a0                 << std::endl;\\n\\u00a0       return 1;\\n\\u00a0     }\\n\\u00a0 \\n\\u00a0   return 0;\\n\\u00a0 }\\n Results\\nProgram output\\nWe first have a look at the output generated by the program when run in 2D. In the four images below, we show the solution for polynomial degree \\\\(p=1\\\\) and cycles 2, 3, 4, and 8 of the program. In the plots, we overlay the data generated from the internal data (DG part) with the skeleton part ( \\\\(\\\\hat{u}\\\\)) into the same plot. We had to generate two different data sets because cells and faces represent different geometric entities, the combination of which (in the same file) is not supported in the VTK output of deal.II.\\nThe images show the distinctive features of HDG: The cell solution (colored surfaces) is discontinuous between the cells. The solution on the skeleton variable sits on the faces and ties together the local parts. The skeleton solution is not continuous on the vertices where the faces meet, even though its values are quite close along lines in the same coordinate direction. The skeleton solution can be interpreted as a rubber spring between the two sides that balances the jumps in the solution (or rather, the flux  \\\\(\\\\kappa \\\\nabla u\\n+ \\\\mathbf{c} u\\\\)). From the picture at the top left, it is clear that the bulk solution frequently over- and undershoots and that the skeleton variable in indeed a better approximation to the exact solution; this explains why we can get a better solution using a postprocessing step.\\nAs the mesh is refined, the jumps between the cells get small (we represent a smooth solution), and the skeleton solution approaches the interior parts. For cycle 8, there is no visible difference in the two variables. We also see how boundary conditions are implemented weakly and that the interior variables do not exactly satisfy boundary conditions. On the lower and left boundaries, we set Neumann boundary conditions, whereas we set Dirichlet conditions on the right and top boundaries.\\n\\n\\n  \\n\\n  \\n\\nNext, we have a look at the post-processed solution, again at cycles 2, 3, 4, and 8. This is a discontinuous solution that is locally described by second order polynomials. While the solution does not look very good on the mesh of cycle two, it looks much better for cycles three and four. As shown by the convergence table below, we find that is also converges more quickly to the analytical solution.\\n\\n\\n  \\n\\n  \\n\\nFinally, we look at the solution for \\\\(p=3\\\\) at cycle 2. Despite the coarse mesh with only 64 cells, the post-processed solution is similar in quality to the linear solution (not post-processed) at cycle 8 with 4,096 cells. This clearly shows the superiority of high order methods for smooth solutions.\\n\\n\\n  \\n\\nConvergence tables\\nWhen the program is run, it also outputs information about the respective steps and convergence tables with errors in the various components in the end. In 2D, the convergence tables look the following:\\nQ1 elements, adaptive refinement:\\ncells dofs   val L2    grad L2  val L2-post\\n   16    80 1.804e+01 2.207e+01   1.798e+01\\n   31   170 9.874e+00 1.322e+01   9.798e+00\\n   61   314 7.452e-01 3.793e+00   4.891e-01\\n  121   634 3.240e-01 1.511e+00   2.616e-01\\n  238  1198 8.585e-02 8.212e-01   1.808e-02\\n  454  2290 4.802e-02 5.178e-01   2.195e-02\\n  898  4378 2.561e-02 2.947e-01   4.318e-03\\n 1720  7864 1.306e-02 1.664e-01   2.978e-03\\n 3271 14638 7.025e-03 9.815e-02   1.075e-03\\n 6217 27214 4.119e-03 6.407e-02   9.975e-04\\n \\nQ1 elements, global refinement:\\ncells dofs      val L2        grad L2      val L2-post\\n   16    80 1.804e+01    - 2.207e+01    - 1.798e+01    -\\n   36   168 6.125e+00 2.66 9.472e+00 2.09 6.084e+00 2.67\\n   64   288 9.785e-01 6.38 4.260e+00 2.78 7.102e-01 7.47\\n  144   624 2.730e-01 3.15 1.866e+00 2.04 6.115e-02 6.05\\n  256  1088 1.493e-01 2.10 1.046e+00 2.01 2.880e-02 2.62\\n  576  2400 6.965e-02 1.88 4.846e-01 1.90 9.204e-03 2.81\\n 1024  4224 4.018e-02 1.91 2.784e-01 1.93 4.027e-03 2.87\\n 2304  9408 1.831e-02 1.94 1.264e-01 1.95 1.236e-03 2.91\\n 4096 16640 1.043e-02 1.96 7.185e-02 1.96 5.306e-04 2.94\\n 9216 37248 4.690e-03 1.97 3.228e-02 1.97 1.599e-04 2.96\\n \\nQ3 elements, global refinement:\\ncells dofs      val L2        grad L2      val L2-post\\n   16   160 3.613e-01    - 1.891e+00    - 3.020e-01    -\\n   36   336 6.411e-02 4.26 5.081e-01 3.24 3.238e-02 5.51\\n   64   576 3.480e-02 2.12 2.533e-01 2.42 5.277e-03 6.31\\n  144  1248 8.297e-03 3.54 5.924e-02 3.58 6.330e-04 5.23\\n  256  2176 2.254e-03 4.53 1.636e-02 4.47 1.403e-04 5.24\\n  576  4800 4.558e-04 3.94 3.277e-03 3.96 1.844e-05 5.01\\n 1024  8448 1.471e-04 3.93 1.052e-03 3.95 4.378e-06 5.00\\n 2304 18816 2.956e-05 3.96 2.104e-04 3.97 5.750e-07 5.01\\n 4096 33280 9.428e-06 3.97 6.697e-05 3.98 1.362e-07 5.01\\n 9216 74496 1.876e-06 3.98 1.330e-05 3.99 1.788e-08 5.01\\nOne can see the error reduction upon grid refinement, and for the cases where global refinement was performed, also the convergence rates. The quadratic convergence rates of Q1 elements in the \\\\(L_2\\\\) norm for both the scalar variable and the gradient variable is apparent, as is the cubic rate for the postprocessed scalar variable in the \\\\(L_2\\\\) norm. Note this distinctive feature of an HDG solution. In typical continuous finite elements, the gradient of the solution of order \\\\(p\\\\) converges at rate \\\\(p\\\\) only, as opposed to \\\\(p+1\\\\) for the actual solution. Even though superconvergence results for finite elements are also available (e.g. superconvergent patch recovery first introduced by Zienkiewicz and Zhu), these are typically limited to structured meshes and other special cases. For Q3 HDG variables, the scalar variable and gradient converge at fourth order and the postprocessed scalar variable at fifth order.\\nThe same convergence rates are observed in 3d. Q1 elements, adaptive refinement:\\ncells   dofs    val L2    grad L2  val L2-post\\n     8     144 7.122e+00 1.941e+01   6.102e+00\\n    29     500 3.309e+00 1.023e+01   2.145e+00\\n   113    1792 2.204e+00 1.023e+01   1.912e+00\\n   379    5732 6.085e-01 5.008e+00   2.233e-01\\n  1317   19412 1.543e-01 1.464e+00   4.196e-02\\n  4579   64768 5.058e-02 5.611e-01   9.521e-03\\n 14596  199552 2.129e-02 3.122e-01   4.569e-03\\n 46180  611400 1.033e-02 1.622e-01   1.684e-03\\n144859 1864212 5.007e-03 8.371e-02   7.364e-04\\n451060 5684508 2.518e-03 4.562e-02   3.070e-04\\n \\nQ1 elements, global refinement:\\ncells   dofs       val L2          grad L2       val L2-post\\n     8     144 7.122e+00    - 1.941e+01     - 6.102e+00    -\\n    27     432 5.491e+00 0.64 2.184e+01 -0.29 4.448e+00 0.78\\n    64     960 3.646e+00 1.42 1.299e+01  1.81 3.306e+00 1.03\\n   216    3024 1.595e+00 2.04 8.550e+00  1.03 1.441e+00 2.05\\n   512    6912 6.922e-01 2.90 5.306e+00  1.66 2.511e-01 6.07\\n  1728   22464 2.915e-01 2.13 2.490e+00  1.87 8.588e-02 2.65\\n  4096   52224 1.684e-01 1.91 1.453e+00  1.87 4.055e-02 2.61\\n 13824  172800 7.972e-02 1.84 6.861e-01  1.85 1.335e-02 2.74\\n 32768  405504 4.637e-02 1.88 3.984e-01  1.89 5.932e-03 2.82\\n110592 1354752 2.133e-02 1.92 1.830e-01  1.92 1.851e-03 2.87\\n \\nQ3 elements, global refinement:\\ncells   dofs       val L2        grad L2      val L2-post\\n     8     576 5.670e+00    - 1.868e+01    - 5.462e+00    -\\n    27    1728 1.048e+00 4.16 6.988e+00 2.42 8.011e-01 4.73\\n    64    3840 2.831e-01 4.55 2.710e+00 3.29 1.363e-01 6.16\\n   216   12096 7.883e-02 3.15 7.721e-01 3.10 2.158e-02 4.55\\n   512   27648 3.642e-02 2.68 3.305e-01 2.95 5.231e-03 4.93\\n  1728   89856 8.546e-03 3.58 7.581e-02 3.63 7.640e-04 4.74\\n  4096  208896 2.598e-03 4.14 2.313e-02 4.13 1.783e-04 5.06\\n 13824  691200 5.314e-04 3.91 4.697e-03 3.93 2.355e-05 4.99\\n 32768 1622016 1.723e-04 3.91 1.517e-03 3.93 5.602e-06 4.99\\n110592 5419008 3.482e-05 3.94 3.055e-04 3.95 7.374e-07 5.00\\nComparison with continuous finite elements\\nResults for 2D\\nThe convergence tables verify the expected convergence rates stated in the introduction. Now, we want to show a quick comparison of the computational efficiency of the HDG method compared to a usual finite element (continuous Galkerin) method on the problem of this tutorial. Of course, stability aspects of the HDG method compared to continuous finite elements for transport-dominated problems are also important in practice, which is an aspect not seen on a problem with smooth analytic solution. In the picture below, we compare the \\\\(L_2\\\\) error as a function of the number of degrees of freedom (left) and of the computing time spent in the linear solver (right) for two space dimensions of continuous finite elements (CG) and the hybridized discontinuous Galerkin method presented in this tutorial. As opposed to the tutorial where we only use unpreconditioned BiCGStab, the times shown in the figures below use the Trilinos algebraic multigrid preconditioner in TrilinosWrappers::PreconditionAMG. For the HDG part, a wrapper around ChunkSparseMatrix for the trace variable has been used in order to utilize the block structure in the matrix on the finest level.\\n\\n\\n  \\n\\nThe results in the graphs show that the HDG method is slower than continuous finite elements at \\\\(p=1\\\\), about equally fast for cubic elements and faster for sixth order elements. However, we have seen above that the HDG method actually produces solutions which are more accurate than what is represented in the original variables. Therefore, in the next two plots below we instead display the error of the post-processed solution for HDG (denoted by \\\\(p=1^*\\\\) for example). We now see a clear advantage of HDG for the same amount of work for both \\\\(p=3\\\\) and \\\\(p=6\\\\), and about the same quality for \\\\(p=1\\\\).\\n\\n\\n  \\n\\nSince the HDG method actually produces results converging as \\\\(h^{p+2}\\\\), we should compare it to a continuous Galerkin solution with the same asymptotic convergence behavior, i.e., FE_Q with degree \\\\(p+1\\\\). If we do this, we get the convergence curves below. We see that CG with second order polynomials is again clearly better than HDG with linears. However, the advantage of HDG for higher orders remains.\\n\\n\\n  \\n\\nThe results are in line with properties of DG methods in general: Best performance is typically not achieved for linear elements, but rather at somewhat higher order, usually around \\\\(p=3\\\\). This is because of a volume-to-surface effect for discontinuous solutions with too much of the solution living on the surfaces and hence duplicating work when the elements are linear. Put in other words, DG methods are often most efficient when used at relatively high order, despite their focus on a discontinuous (and hence, seemingly low accurate) representation of solutions.\\nResults for 3D\\nWe now show the same figures in 3D: The first row shows the number of degrees of freedom and computing time versus the \\\\(L_2\\\\) error in the scalar variable \\\\(u\\\\) for CG and HDG at order \\\\(p\\\\), the second row shows the post-processed HDG solution instead of the original one, and the third row compares the post-processed HDG solution with CG at order \\\\(p+1\\\\). In 3D, the volume-to-surface effect makes the cost of HDG somewhat higher and the CG solution is clearly better than HDG for linears by any metric. For cubics, HDG and CG are of similar quality, whereas HDG is again more efficient for sixth order polynomials. One can alternatively also use the combination of FE_DGP and FE_FaceP instead of (FE_DGQ, FE_FaceQ), which do not use tensor product polynomials of degree \\\\(p\\\\) but Legendre polynomials of complete degree \\\\(p\\\\). There are fewer degrees of freedom on the skeleton variable for FE_FaceP for a given mesh size, but the solution quality (error vs. number of DoFs) is very similar to the results for FE_FaceQ.\\n\\n\\n  \\n\\n  \\n\\n  \\n\\nOne final note on the efficiency comparison: We tried to use general-purpose sparse matrix structures and similar solvers (optimal AMG preconditioners for both without particular tuning of the AMG parameters on any of them) to give a fair picture of the cost versus accuracy of two methods, on a toy example. It should be noted however that geometric multigrid (GMG) for continuous finite elements is about a factor four to five faster for \\\\(p=3\\\\) and \\\\(p=6\\\\). As of 2019, optimal-complexity iterative solvers for HDG are still under development in the research community. Also, there are other implementation aspects for CG available such as fast matrix-free approaches as shown in step-37 that make higher order continuous elements more competitive. Again, it is not clear to the authors of the tutorial whether similar improvements could be made for HDG. We refer to Kronbichler and Wall (2018) for a recent efficiency evaluation.\\nPossibilities for improvements\\nAs already mentioned in the introduction, one possibility is to implement another post-processing technique as discussed in the literature.\\nA second item that is not done optimally relates to the performance of this program, which is of course an issue in practical applications (weighing in also the better solution quality of (H)DG methods for transport-dominated problems). Let us look at the computing time of the tutorial program and the share of the individual components:\\n\\n\\n\\u00a0 \\u00a0 Setup Assemble Solve Trace reconstruct Post-processing Output  \\n\\n\\u00a0 Total time Relative share  \\n\\n2D, Q1, cycle 9, 37,248 dofs 5.34s 0.7% 1.2% 89.5% 0.9% 2.3% 5.4%  \\n\\n2D, Q3, cycle 9, 74,496 dofs 22.2s 0.4% 4.3% 84.1% 4.1% 3.5% 3.6%  \\n\\n3D, Q1, cycle 7, 172,800 dofs 9.06s 3.1% 8.9% 42.7% 7.0% 20.6% 17.7%  \\n\\n3D, Q3, cycle 7, 691,200 dofs 516s 0.6% 34.5% 13.4% 32.8% 17.1% 1.5%  \\n\\nAs can be seen from the table, the solver and assembly calls dominate the runtime of the program. This also gives a clear indication of where improvements would make the most sense:\\n\\n\\nBetter linear solvers: We use a BiCGStab iterative solver without preconditioner, where the number of iteration increases with increasing problem size (the number of iterations for Q1 elements and global refinements starts at 35 for the small sizes but increase up to 701 for the largest size). To do better, one could for example use an algebraic multigrid preconditioner from Trilinos, or some more advanced variants as the one discussed in Kronbichler and Wall (2018). For diffusion-dominated problems such as the problem at hand with finer meshes, such a solver can be designed that uses the matrix-vector products from the more efficient ChunkSparseMatrix on the finest level, as long as we are not working in parallel with MPI. For MPI-parallelized computations, a standard TrilinosWrappers::SparseMatrix can be used.\\n\\n\\n\\nSpeed up assembly by pre-assembling parts that do not change from one cell to another (those that do neither contain variable coefficients nor mapping-dependent terms). \\n\\n The plain program\\n/* ------------------------------------------------------------------------\\n *\\n * SPDX-License-Identifier: LGPL-2.1-or-later\\n * Copyright (C) 2013 - 2024 by the deal.II authors\\n *\\n * This file is part of the deal.II library.\\n *\\n * Part of the source code is dual licensed under Apache-2.0 WITH\\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\\n * governing the source code and code contributions can be found in\\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\\n *\\n * ------------------------------------------------------------------------\\n *\\n * Author: Martin Kronbichler, Technical University of Munich,\\n *         Scott T. Miller, The Pennsylvania State University, 2013\\n */\\n \\n#include <deal.II/base/quadrature_lib.h>\\n#include <deal.II/base/function.h>\\n#include <deal.II/base/tensor_function.h>\\n#include <deal.II/base/exceptions.h>\\n#include <deal.II/base/work_stream.h>\\n#include <deal.II/base/convergence_table.h>\\n#include <deal.II/lac/vector.h>\\n#include <deal.II/lac/affine_constraints.h>\\n#include <deal.II/lac/full_matrix.h>\\n#include <deal.II/lac/dynamic_sparsity_pattern.h>\\n#include <deal.II/lac/solver_bicgstab.h>\\n#include <deal.II/lac/precondition.h>\\n#include <deal.II/grid/tria.h>\\n#include <deal.II/grid/grid_generator.h>\\n#include <deal.II/grid/grid_refinement.h>\\n#include <deal.II/dofs/dof_handler.h>\\n#include <deal.II/dofs/dof_renumbering.h>\\n#include <deal.II/dofs/dof_tools.h>\\n#include <deal.II/fe/fe_dgq.h>\\n#include <deal.II/fe/fe_system.h>\\n#include <deal.II/fe/fe_values.h>\\n#include <deal.II/numerics/vector_tools.h>\\n#include <deal.II/numerics/error_estimator.h>\\n#include <deal.II/numerics/data_out.h>\\n \\n#include <deal.II/fe/fe_face.h>\\n \\n#include <deal.II/lac/chunk_sparse_matrix.h>\\n \\n#include <deal.II/numerics/data_out_faces.h>\\n \\n#include <iostream>\\n \\n \\n \\nnamespace Step51\\n{\\n using namespace dealii;\\n \\n template <int dim>\\n class SolutionBase\\n  {\\n protected:\\n static const unsigned int n_source_centers = 3;\\n static const Point<dim>   source_centers[n_source_centers];\\n static const double       width;\\n  };\\n \\n \\n template <>\\n const Point<1>\\n    SolutionBase<1>::source_centers[SolutionBase<1>::n_source_centers] =\\n      {Point<1>(-1.0 / 3.0), Point<1>(0.0), Point<1>(+1.0 / 3.0)};\\n \\n \\n template <>\\n const Point<2>\\n    SolutionBase<2>::source_centers[SolutionBase<2>::n_source_centers] =\\n      {Point<2>(-0.5, +0.5), Point<2>(-0.5, -0.5), Point<2>(+0.5, -0.5)};\\n \\n template <>\\n const Point<3>\\n    SolutionBase<3>::source_centers[SolutionBase<3>::n_source_centers] = {\\n Point<3>(-0.5, +0.5, 0.25),\\n Point<3>(-0.6, -0.5, -0.125),\\n Point<3>(+0.5, -0.5, 0.5)};\\n \\n template <int dim>\\n const double SolutionBase<dim>::width = 1. / 5.;\\n \\n \\n template <int dim>\\n class Solution : public Function<dim>, protected SolutionBase<dim>\\n  {\\n public:\\n virtual double value(const Point<dim> &p,\\n const unsigned int /*component*/ = 0) const override\\n {\\n double sum = 0;\\n for (unsigned int i = 0; i < this->n_source_centers; ++i)\\n        {\\n const Tensor<1, dim> x_minus_xi = p - this->source_centers[i];\\n sum +=\\n std::exp(-x_minus_xi.norm_square() / (this->width * this->width));\\n        }\\n \\n return sum /\\n std::pow(2. * numbers::PI * this->width * this->width, dim / 2.);\\n    }\\n \\n virtual Tensor<1, dim>\\n gradient(const Point<dim> &p,\\n const unsigned int /*component*/ = 0) const override\\n {\\n Tensor<1, dim> sum;\\n for (unsigned int i = 0; i < this->n_source_centers; ++i)\\n        {\\n const Tensor<1, dim> x_minus_xi = p - this->source_centers[i];\\n \\n sum +=\\n            (-2 / (this->width * this->width) *\\n std::exp(-x_minus_xi.norm_square() / (this->width * this->width)) *\\n             x_minus_xi);\\n        }\\n \\n return sum /\\n std::pow(2. * numbers::PI * this->width * this->width, dim / 2.);\\n    }\\n  };\\n \\n \\n \\n template <int dim>\\n class SolutionAndGradient : public Function<dim>, protected SolutionBase<dim>\\n  {\\n public:\\n    SolutionAndGradient()\\n      : Function<dim>(dim + 1)\\n    {}\\n \\n virtual void vector_value(const Point<dim> &p,\\n Vector<double>   &v) const override\\n {\\n AssertDimension(v.size(), dim + 1);\\n      Solution<dim>  solution;\\n Tensor<1, dim> grad = solution.gradient(p);\\n for (unsigned int d = 0; d < dim; ++d)\\n        v[d] = -grad[d];\\n      v[dim] = solution.value(p);\\n    }\\n  };\\n \\n \\n \\n template <int dim>\\n class ConvectionVelocity : public TensorFunction<1, dim>\\n  {\\n public:\\n    ConvectionVelocity()\\n      : TensorFunction<1, dim>()\\n    {}\\n \\n virtual Tensor<1, dim> value(const Point<dim> &p) const override\\n {\\n Tensor<1, dim> convection;\\n switch (dim)\\n        {\\n case 1:\\n            convection[0] = 1;\\n break;\\n case 2:\\n            convection[0] = p[1];\\n            convection[1] = -p[0];\\n break;\\n case 3:\\n            convection[0] = p[1];\\n            convection[1] = -p[0];\\n            convection[2] = 1;\\n break;\\n default:\\n DEAL_II_NOT_IMPLEMENTED();\\n        }\\n return convection;\\n    }\\n  };\\n \\n \\n \\n template <int dim>\\n class RightHandSide : public Function<dim>, protected SolutionBase<dim>\\n  {\\n public:\\n virtual double value(const Point<dim> &p,\\n const unsigned int /*component*/ = 0) const override\\n {\\n      ConvectionVelocity<dim> convection_velocity;\\n Tensor<1, dim>          convection = convection_velocity.value(p);\\n double sum        = 0;\\n for (unsigned int i = 0; i < this->n_source_centers; ++i)\\n        {\\n const Tensor<1, dim> x_minus_xi = p - this->source_centers[i];\\n \\n sum +=\\n            ((2 * dim - 2 * convection * x_minus_xi -\\n              4 * x_minus_xi.norm_square() / (this->width * this->width)) /\\n             (this->width * this->width) *\\n std::exp(-x_minus_xi.norm_square() / (this->width * this->width)));\\n        }\\n \\n return sum /\\n std::pow(2. * numbers::PI * this->width * this->width, dim / 2.);\\n    }\\n  };\\n \\n \\n \\n \\n template <int dim>\\n class HDG\\n  {\\n public:\\n enum RefinementMode\\n    {\\n      global_refinement,\\n      adaptive_refinement\\n    };\\n \\n    HDG(const unsigned int degree, const RefinementMode refinement_mode);\\n void run();\\n \\n private:\\n void setup_system();\\n void assemble_system(const bool reconstruct_trace = false);\\n void solve();\\n void postprocess();\\n void refine_grid(const unsigned int cycle);\\n void output_results(const unsigned int cycle);\\n \\n struct PerTaskData;\\n struct ScratchData;\\n \\n struct PostProcessScratchData;\\n \\n void assemble_system_one_cell(\\n const typename DoFHandler<dim>::active_cell_iterator &cell,\\n      ScratchData                                          &scratch,\\n      PerTaskData                                          &task_data);\\n \\n void copy_local_to_global(const PerTaskData &data);\\n \\n void postprocess_one_cell(\\n const typename DoFHandler<dim>::active_cell_iterator &cell,\\n      PostProcessScratchData                               &scratch,\\n unsigned int                                         &empty_data);\\n \\n \\n Triangulation<dim> triangulation;\\n \\n const FESystem<dim> fe_local;\\n DoFHandler<dim>     dof_handler_local;\\n Vector<double>      solution_local;\\n \\n const FE_FaceQ<dim> fe;\\n DoFHandler<dim>     dof_handler;\\n Vector<double>      solution;\\n Vector<double>      system_rhs;\\n \\n const FE_DGQ<dim> fe_u_post;\\n DoFHandler<dim>   dof_handler_u_post;\\n Vector<double>    solution_u_post;\\n \\n AffineConstraints<double> constraints;\\n \\n ChunkSparsityPattern      sparsity_pattern;\\n ChunkSparseMatrix<double> system_matrix;\\n \\n const RefinementMode refinement_mode;\\n ConvergenceTable     convergence_table;\\n  };\\n \\n \\n template <int dim>\\n  HDG<dim>::HDG(const unsigned int degree, const RefinementMode refinement_mode)\\n    : fe_local(FE_DGQ<dim>(degree) ^ dim, FE_DGQ<dim>(degree))\\n    , dof_handler_local(triangulation)\\n    , fe(degree)\\n    , dof_handler(triangulation)\\n    , fe_u_post(degree + 1)\\n    , dof_handler_u_post(triangulation)\\n    , refinement_mode(refinement_mode)\\n  {}\\n \\n \\n \\n template <int dim>\\n void HDG<dim>::setup_system()\\n  {\\n    dof_handler_local.distribute_dofs(fe_local);\\n    dof_handler.distribute_dofs(fe);\\n    dof_handler_u_post.distribute_dofs(fe_u_post);\\n \\n    std::cout << \\\"   Number of degrees of freedom: \\\" << dof_handler.n_dofs()\\n              << std::endl;\\n \\n    solution.reinit(dof_handler.n_dofs());\\n    system_rhs.reinit(dof_handler.n_dofs());\\n \\n    solution_local.reinit(dof_handler_local.n_dofs());\\n    solution_u_post.reinit(dof_handler_u_post.n_dofs());\\n \\n    constraints.clear();\\n DoFTools::make_hanging_node_constraints(dof_handler, constraints);\\n    std::map<types::boundary_id, const Function<dim> *> boundary_functions;\\n    Solution<dim>                                       solution_function;\\n    boundary_functions[0] = &solution_function;\\n VectorTools::project_boundary_values(dof_handler,\\n                                         boundary_functions,\\n QGauss<dim - 1>(fe.degree + 1),\\n                                         constraints);\\n    constraints.close();\\n \\n    {\\n DynamicSparsityPattern dsp(dof_handler.n_dofs());\\n DoFTools::make_sparsity_pattern(dof_handler, dsp, constraints, false);\\n      sparsity_pattern.copy_from(dsp, fe.n_dofs_per_face());\\n    }\\n    system_matrix.reinit(sparsity_pattern);\\n  }\\n \\n \\n \\n template <int dim>\\n struct HDG<dim>::PerTaskData\\n  {\\n FullMatrix<double> cell_matrix;\\n Vector<double>                       cell_vector;\\n    std::vector<types::global_dof_index> dof_indices;\\n \\n bool trace_reconstruct;\\n \\n    PerTaskData(const unsigned int n_dofs, const bool trace_reconstruct)\\n      : cell_matrix(n_dofs, n_dofs)\\n      , cell_vector(n_dofs)\\n      , dof_indices(n_dofs)\\n      , trace_reconstruct(trace_reconstruct)\\n    {}\\n  };\\n \\n \\n \\n template <int dim>\\n struct HDG<dim>::ScratchData\\n  {\\n FEValues<dim>     fe_values_local;\\n FEFaceValues<dim> fe_face_values_local;\\n FEFaceValues<dim> fe_face_values;\\n \\n FullMatrix<double> ll_matrix;\\n FullMatrix<double> lf_matrix;\\n FullMatrix<double> fl_matrix;\\n FullMatrix<double> tmp_matrix;\\n Vector<double>     l_rhs;\\n Vector<double>     tmp_rhs;\\n \\n    std::vector<Tensor<1, dim>> q_phi;\\n    std::vector<double>         q_phi_div;\\n    std::vector<double>         u_phi;\\n    std::vector<Tensor<1, dim>> u_phi_grad;\\n    std::vector<double>         tr_phi;\\n    std::vector<double>         trace_values;\\n \\n    std::vector<std::vector<unsigned int>> fe_local_support_on_face;\\n    std::vector<std::vector<unsigned int>> fe_support_on_face;\\n \\n    ConvectionVelocity<dim> convection_velocity;\\n    RightHandSide<dim>      right_hand_side;\\n const Solution<dim>     exact_solution;\\n \\n    ScratchData(const FiniteElement<dim> &fe,\\n const FiniteElement<dim> &fe_local,\\n const QGauss<dim>        &quadrature_formula,\\n const QGauss<dim - 1>    &face_quadrature_formula,\\n const UpdateFlags         local_flags,\\n const UpdateFlags         local_face_flags,\\n const UpdateFlags         flags)\\n      : fe_values_local(fe_local, quadrature_formula, local_flags)\\n      , fe_face_values_local(fe_local,\\n                             face_quadrature_formula,\\n                             local_face_flags)\\n      , fe_face_values(fe, face_quadrature_formula, flags)\\n      , ll_matrix(fe_local.n_dofs_per_cell(), fe_local.n_dofs_per_cell())\\n      , lf_matrix(fe_local.n_dofs_per_cell(), fe.n_dofs_per_cell())\\n      , fl_matrix(fe.n_dofs_per_cell(), fe_local.n_dofs_per_cell())\\n      , tmp_matrix(fe.n_dofs_per_cell(), fe_local.n_dofs_per_cell())\\n      , l_rhs(fe_local.n_dofs_per_cell())\\n      , tmp_rhs(fe_local.n_dofs_per_cell())\\n      , q_phi(fe_local.n_dofs_per_cell())\\n      , q_phi_div(fe_local.n_dofs_per_cell())\\n      , u_phi(fe_local.n_dofs_per_cell())\\n      , u_phi_grad(fe_local.n_dofs_per_cell())\\n      , tr_phi(fe.n_dofs_per_cell())\\n      , trace_values(face_quadrature_formula.size())\\n      , fe_local_support_on_face(GeometryInfo<dim>::faces_per_cell)\\n      , fe_support_on_face(GeometryInfo<dim>::faces_per_cell)\\n      , exact_solution()\\n    {\\n for (const unsigned int face_no : GeometryInfo<dim>::face_indices())\\n        for (unsigned int i = 0; i < fe_local.n_dofs_per_cell(); ++i)\\n          {\\n if (fe_local.has_support_on_face(i, face_no))\\n              fe_local_support_on_face[face_no].push_back(i);\\n          }\\n \\n for (const unsigned int face_no : GeometryInfo<dim>::face_indices())\\n        for (unsigned int i = 0; i < fe.n_dofs_per_cell(); ++i)\\n          {\\n if (fe.has_support_on_face(i, face_no))\\n              fe_support_on_face[face_no].push_back(i);\\n          }\\n    }\\n \\n    ScratchData(const ScratchData &sd)\\n      : fe_values_local(sd.fe_values_local.get_fe(),\\n                        sd.fe_values_local.get_quadrature(),\\n                        sd.fe_values_local.get_update_flags())\\n      , fe_face_values_local(sd.fe_face_values_local.get_fe(),\\n                             sd.fe_face_values_local.get_quadrature(),\\n                             sd.fe_face_values_local.get_update_flags())\\n      , fe_face_values(sd.fe_face_values.get_fe(),\\n                       sd.fe_face_values.get_quadrature(),\\n                       sd.fe_face_values.get_update_flags())\\n      , ll_matrix(sd.ll_matrix)\\n      , lf_matrix(sd.lf_matrix)\\n      , fl_matrix(sd.fl_matrix)\\n      , tmp_matrix(sd.tmp_matrix)\\n      , l_rhs(sd.l_rhs)\\n      , tmp_rhs(sd.tmp_rhs)\\n      , q_phi(sd.q_phi)\\n      , q_phi_div(sd.q_phi_div)\\n      , u_phi(sd.u_phi)\\n      , u_phi_grad(sd.u_phi_grad)\\n      , tr_phi(sd.tr_phi)\\n      , trace_values(sd.trace_values)\\n      , fe_local_support_on_face(sd.fe_local_support_on_face)\\n      , fe_support_on_face(sd.fe_support_on_face)\\n      , exact_solution()\\n    {}\\n  };\\n \\n \\n \\n template <int dim>\\n struct HDG<dim>::PostProcessScratchData\\n  {\\n FEValues<dim> fe_values_local;\\n FEValues<dim> fe_values;\\n \\n    std::vector<double>         u_values;\\n    std::vector<Tensor<1, dim>> u_gradients;\\n FullMatrix<double> cell_matrix;\\n \\n Vector<double> cell_rhs;\\n Vector<double> cell_sol;\\n \\n    PostProcessScratchData(const FiniteElement<dim> &fe,\\n const FiniteElement<dim> &fe_local,\\n const QGauss<dim>        &quadrature_formula,\\n const UpdateFlags         local_flags,\\n const UpdateFlags         flags)\\n      : fe_values_local(fe_local, quadrature_formula, local_flags)\\n      , fe_values(fe, quadrature_formula, flags)\\n      , u_values(quadrature_formula.size())\\n      , u_gradients(quadrature_formula.size())\\n      , cell_matrix(fe.n_dofs_per_cell(), fe.n_dofs_per_cell())\\n      , cell_rhs(fe.n_dofs_per_cell())\\n      , cell_sol(fe.n_dofs_per_cell())\\n    {}\\n \\n    PostProcessScratchData(const PostProcessScratchData &sd)\\n      : fe_values_local(sd.fe_values_local.get_fe(),\\n                        sd.fe_values_local.get_quadrature(),\\n                        sd.fe_values_local.get_update_flags())\\n      , fe_values(sd.fe_values.get_fe(),\\n                  sd.fe_values.get_quadrature(),\\n                  sd.fe_values.get_update_flags())\\n      , u_values(sd.u_values)\\n      , u_gradients(sd.u_gradients)\\n      , cell_matrix(sd.cell_matrix)\\n      , cell_rhs(sd.cell_rhs)\\n      , cell_sol(sd.cell_sol)\\n    {}\\n  };\\n \\n \\n \\n template <int dim>\\n void HDG<dim>::assemble_system(const bool trace_reconstruct)\\n  {\\n const QGauss<dim>     quadrature_formula(fe.degree + 1);\\n const QGauss<dim - 1> face_quadrature_formula(fe.degree + 1);\\n \\n const UpdateFlags local_flags(update_values | update_gradients |\\n update_JxW_values | update_quadrature_points);\\n \\n const UpdateFlags local_face_flags(update_values);\\n \\n const UpdateFlags flags(update_values | update_normal_vectors |\\n update_quadrature_points | update_JxW_values);\\n \\n    PerTaskData task_data(fe.n_dofs_per_cell(), trace_reconstruct);\\n    ScratchData scratch(fe,\\n                        fe_local,\\n                        quadrature_formula,\\n                        face_quadrature_formula,\\n                        local_flags,\\n                        local_face_flags,\\n                        flags);\\n \\n WorkStream::run(dof_handler.begin_active(),\\n                    dof_handler.end(),\\n                    *this,\\n                    &HDG<dim>::assemble_system_one_cell,\\n                    &HDG<dim>::copy_local_to_global,\\n                    scratch,\\n                    task_data);\\n  }\\n \\n \\n \\n template <int dim>\\n void HDG<dim>::assemble_system_one_cell(\\n const typename DoFHandler<dim>::active_cell_iterator &cell,\\n    ScratchData                                          &scratch,\\n    PerTaskData                                          &task_data)\\n  {\\n const typename DoFHandler<dim>::active_cell_iterator loc_cell =\\n      cell->as_dof_handler_iterator(dof_handler_local);\\n \\n const unsigned int n_q_points =\\n      scratch.fe_values_local.get_quadrature().size();\\n const unsigned int n_face_q_points =\\n      scratch.fe_face_values_local.get_quadrature().size();\\n \\n const unsigned int loc_dofs_per_cell =\\n      scratch.fe_values_local.get_fe().n_dofs_per_cell();\\n \\n const FEValuesExtractors::Vector fluxes(0);\\n const FEValuesExtractors::Scalar scalar(dim);\\n \\n    scratch.ll_matrix = 0;\\n    scratch.l_rhs     = 0;\\n if (!task_data.trace_reconstruct)\\n      {\\n        scratch.lf_matrix     = 0;\\n        scratch.fl_matrix     = 0;\\n        task_data.cell_matrix = 0;\\n        task_data.cell_vector = 0;\\n      }\\n    scratch.fe_values_local.reinit(loc_cell);\\n \\n for (unsigned int q = 0; q < n_q_points; ++q)\\n      {\\n const double rhs_value = scratch.right_hand_side.value(\\n          scratch.fe_values_local.quadrature_point(q));\\n const Tensor<1, dim> convection = scratch.convection_velocity.value(\\n          scratch.fe_values_local.quadrature_point(q));\\n const double JxW = scratch.fe_values_local.JxW(q);\\n for (unsigned int k = 0; k < loc_dofs_per_cell; ++k)\\n          {\\n            scratch.q_phi[k] = scratch.fe_values_local[fluxes].value(k, q);\\n            scratch.q_phi_div[k] =\\n              scratch.fe_values_local[fluxes].divergence(k, q);\\n            scratch.u_phi[k] = scratch.fe_values_local[scalar].value(k, q);\\n            scratch.u_phi_grad[k] =\\n              scratch.fe_values_local[scalar].gradient(k, q);\\n          }\\n for (unsigned int i = 0; i < loc_dofs_per_cell; ++i)\\n          {\\n for (unsigned int j = 0; j < loc_dofs_per_cell; ++j)\\n              scratch.ll_matrix(i, j) +=\\n                (scratch.q_phi[i] * scratch.q_phi[j] -\\n                 scratch.q_phi_div[i] * scratch.u_phi[j] +\\n                 scratch.u_phi[i] * scratch.q_phi_div[j] -\\n                 (scratch.u_phi_grad[i] * convection) * scratch.u_phi[j]) *\\n                JxW;\\n            scratch.l_rhs(i) += scratch.u_phi[i] * rhs_value * JxW;\\n          }\\n      }\\n \\n for (const auto face_no : cell->face_indices())\\n      {\\n        scratch.fe_face_values_local.reinit(loc_cell, face_no);\\n        scratch.fe_face_values.reinit(cell, face_no);\\n \\n if (task_data.trace_reconstruct)\\n          scratch.fe_face_values.get_function_values(solution,\\n                                                     scratch.trace_values);\\n \\n for (unsigned int q = 0; q < n_face_q_points; ++q)\\n          {\\n const double     JxW = scratch.fe_face_values.JxW(q);\\n const Point<dim> quadrature_point =\\n              scratch.fe_face_values.quadrature_point(q);\\n const Tensor<1, dim> normal =\\n              scratch.fe_face_values.normal_vector(q);\\n const Tensor<1, dim> convection =\\n              scratch.convection_velocity.value(quadrature_point);\\n \\n const double tau_stab = (5. + std::abs(convection * normal));\\n \\n for (unsigned int k = 0;\\n                 k < scratch.fe_local_support_on_face[face_no].size();\\n                 ++k)\\n              {\\n const unsigned int kk =\\n                  scratch.fe_local_support_on_face[face_no][k];\\n                scratch.q_phi[k] =\\n                  scratch.fe_face_values_local[fluxes].value(kk, q);\\n                scratch.u_phi[k] =\\n                  scratch.fe_face_values_local[scalar].value(kk, q);\\n              }\\n \\n if (!task_data.trace_reconstruct)\\n              {\\n for (unsigned int k = 0;\\n                     k < scratch.fe_support_on_face[face_no].size();\\n                     ++k)\\n                  scratch.tr_phi[k] = scratch.fe_face_values.shape_value(\\n                    scratch.fe_support_on_face[face_no][k], q);\\n for (unsigned int i = 0;\\n                     i < scratch.fe_local_support_on_face[face_no].size();\\n                     ++i)\\n for (unsigned int j = 0;\\n                       j < scratch.fe_support_on_face[face_no].size();\\n                       ++j)\\n                    {\\n const unsigned int ii =\\n                        scratch.fe_local_support_on_face[face_no][i];\\n const unsigned int jj =\\n                        scratch.fe_support_on_face[face_no][j];\\n                      scratch.lf_matrix(ii, jj) +=\\n                        ((scratch.q_phi[i] * normal +\\n                          (convection * normal - tau_stab) * scratch.u_phi[i]) *\\n                         scratch.tr_phi[j]) *\\n                        JxW;\\n \\n                      scratch.fl_matrix(jj, ii) -=\\n                        ((scratch.q_phi[i] * normal +\\n                          tau_stab * scratch.u_phi[i]) *\\n                         scratch.tr_phi[j]) *\\n                        JxW;\\n                    }\\n \\n for (unsigned int i = 0;\\n                     i < scratch.fe_support_on_face[face_no].size();\\n                     ++i)\\n for (unsigned int j = 0;\\n                       j < scratch.fe_support_on_face[face_no].size();\\n                       ++j)\\n                    {\\n const unsigned int ii =\\n                        scratch.fe_support_on_face[face_no][i];\\n const unsigned int jj =\\n                        scratch.fe_support_on_face[face_no][j];\\n                      task_data.cell_matrix(ii, jj) +=\\n                        ((convection * normal - tau_stab) * scratch.tr_phi[i] *\\n                         scratch.tr_phi[j]) *\\n                        JxW;\\n                    }\\n \\n if (cell->face(face_no)->at_boundary() &&\\n                    (cell->face(face_no)->boundary_id() == 1))\\n                  {\\n const double neumann_value =\\n                      -scratch.exact_solution.gradient(quadrature_point) *\\n                        normal +\\n                      convection * normal *\\n                        scratch.exact_solution.value(quadrature_point);\\n for (unsigned int i = 0;\\n                         i < scratch.fe_support_on_face[face_no].size();\\n                         ++i)\\n                      {\\n const unsigned int ii =\\n                          scratch.fe_support_on_face[face_no][i];\\n                        task_data.cell_vector(ii) +=\\n                          scratch.tr_phi[i] * neumann_value * JxW;\\n                      }\\n                  }\\n              }\\n \\n for (unsigned int i = 0;\\n                 i < scratch.fe_local_support_on_face[face_no].size();\\n                 ++i)\\n for (unsigned int j = 0;\\n                   j < scratch.fe_local_support_on_face[face_no].size();\\n                   ++j)\\n                {\\n const unsigned int ii =\\n                    scratch.fe_local_support_on_face[face_no][i];\\n const unsigned int jj =\\n                    scratch.fe_local_support_on_face[face_no][j];\\n                  scratch.ll_matrix(ii, jj) +=\\n                    tau_stab * scratch.u_phi[i] * scratch.u_phi[j] * JxW;\\n                }\\n \\n if (task_data.trace_reconstruct)\\n for (unsigned int i = 0;\\n                   i < scratch.fe_local_support_on_face[face_no].size();\\n                   ++i)\\n                {\\n const unsigned int ii =\\n                    scratch.fe_local_support_on_face[face_no][i];\\n                  scratch.l_rhs(ii) -=\\n                    (scratch.q_phi[i] * normal +\\n                     scratch.u_phi[i] * (convection * normal - tau_stab)) *\\n                    scratch.trace_values[q] * JxW;\\n                }\\n          }\\n      }\\n \\n    scratch.ll_matrix.gauss_jordan();\\n \\n if (task_data.trace_reconstruct == false)\\n      {\\n        scratch.fl_matrix.mmult(scratch.tmp_matrix, scratch.ll_matrix);\\n        scratch.tmp_matrix.vmult_add(task_data.cell_vector, scratch.l_rhs);\\n        scratch.tmp_matrix.mmult(task_data.cell_matrix,\\n                                 scratch.lf_matrix,\\n true);\\n        cell->get_dof_indices(task_data.dof_indices);\\n      }\\n else\\n      {\\n        scratch.ll_matrix.vmult(scratch.tmp_rhs, scratch.l_rhs);\\n        loc_cell->set_dof_values(scratch.tmp_rhs, solution_local);\\n      }\\n  }\\n \\n \\n \\n template <int dim>\\n void HDG<dim>::copy_local_to_global(const PerTaskData &data)\\n  {\\n if (data.trace_reconstruct == false)\\n      constraints.distribute_local_to_global(data.cell_matrix,\\n                                             data.cell_vector,\\n                                             data.dof_indices,\\n                                             system_matrix,\\n                                             system_rhs);\\n  }\\n \\n \\n \\n template <int dim>\\n void HDG<dim>::solve()\\n  {\\n SolverControl                  solver_control(system_matrix.m() * 10,\\n                                 1e-11 * system_rhs.l2_norm());\\n SolverBicgstab<Vector<double>> solver(solver_control);\\n    solver.solve(system_matrix, solution, system_rhs, PreconditionIdentity());\\n \\n    std::cout << \\\"   Number of BiCGStab iterations: \\\"\\n              << solver_control.last_step() << std::endl;\\n \\n    system_matrix.clear();\\n    sparsity_pattern.reinit(0, 0, 0, 1);\\n \\n    constraints.distribute(solution);\\n \\n    assemble_system(true);\\n  }\\n \\n \\n \\n \\n template <int dim>\\n void HDG<dim>::postprocess()\\n  {\\n    {\\n const QGauss<dim> quadrature_formula(fe_u_post.degree + 1);\\n const UpdateFlags local_flags(update_values);\\n const UpdateFlags flags(update_values | update_gradients |\\n update_JxW_values);\\n \\n      PostProcessScratchData scratch(\\n        fe_u_post, fe_local, quadrature_formula, local_flags, flags);\\n \\n WorkStream::run(\\n        dof_handler_u_post.begin_active(),\\n        dof_handler_u_post.end(),\\n        [this](const typename DoFHandler<dim>::active_cell_iterator &cell,\\n               PostProcessScratchData                               &scratch,\\n unsigned int                                         &data) {\\n          this->postprocess_one_cell(cell, scratch, data);\\n        },\\n        std::function<void(const unsigned int &)>(),\\n        scratch,\\n        0U);\\n    }\\n \\n Vector<float> difference_per_cell(triangulation.n_active_cells());\\n \\n ComponentSelectFunction<dim> value_select(dim, dim + 1);\\n VectorTools::integrate_difference(dof_handler_local,\\n                                      solution_local,\\n                                      SolutionAndGradient<dim>(),\\n                                      difference_per_cell,\\n QGauss<dim>(fe.degree + 2),\\n VectorTools::L2_norm,\\n                                      &value_select);\\n const double L2_error =\\n VectorTools::compute_global_error(triangulation,\\n                                        difference_per_cell,\\n VectorTools::L2_norm);\\n \\n ComponentSelectFunction<dim> gradient_select(\\n      std::pair<unsigned int, unsigned int>(0, dim), dim + 1);\\n VectorTools::integrate_difference(dof_handler_local,\\n                                      solution_local,\\n                                      SolutionAndGradient<dim>(),\\n                                      difference_per_cell,\\n QGauss<dim>(fe.degree + 2),\\n VectorTools::L2_norm,\\n                                      &gradient_select);\\n const double grad_error =\\n VectorTools::compute_global_error(triangulation,\\n                                        difference_per_cell,\\n VectorTools::L2_norm);\\n \\n VectorTools::integrate_difference(dof_handler_u_post,\\n                                      solution_u_post,\\n                                      Solution<dim>(),\\n                                      difference_per_cell,\\n QGauss<dim>(fe.degree + 3),\\n VectorTools::L2_norm);\\n const double post_error =\\n VectorTools::compute_global_error(triangulation,\\n                                        difference_per_cell,\\n VectorTools::L2_norm);\\n \\n    convergence_table.add_value(\\\"cells\\\", triangulation.n_active_cells());\\n    convergence_table.add_value(\\\"dofs\\\", dof_handler.n_dofs());\\n \\n    convergence_table.add_value(\\\"val L2\\\", L2_error);\\n    convergence_table.set_scientific(\\\"val L2\\\", true);\\n    convergence_table.set_precision(\\\"val L2\\\", 3);\\n \\n    convergence_table.add_value(\\\"grad L2\\\", grad_error);\\n    convergence_table.set_scientific(\\\"grad L2\\\", true);\\n    convergence_table.set_precision(\\\"grad L2\\\", 3);\\n \\n    convergence_table.add_value(\\\"val L2-post\\\", post_error);\\n    convergence_table.set_scientific(\\\"val L2-post\\\", true);\\n    convergence_table.set_precision(\\\"val L2-post\\\", 3);\\n  }\\n \\n \\n \\n template <int dim>\\n void HDG<dim>::postprocess_one_cell(\\n const typename DoFHandler<dim>::active_cell_iterator &cell,\\n    PostProcessScratchData                               &scratch,\\n unsigned int &)\\n  {\\n const typename DoFHandler<dim>::active_cell_iterator loc_cell =\\n      cell->as_dof_handler_iterator(dof_handler_local);\\n \\n    scratch.fe_values_local.reinit(loc_cell);\\n    scratch.fe_values.reinit(cell);\\n \\n const FEValuesExtractors::Vector fluxes(0);\\n const FEValuesExtractors::Scalar scalar(dim);\\n \\n const unsigned int n_q_points = scratch.fe_values.get_quadrature().size();\\n const unsigned int dofs_per_cell = scratch.fe_values.dofs_per_cell;\\n \\n    scratch.fe_values_local[scalar].get_function_values(solution_local,\\n                                                        scratch.u_values);\\n    scratch.fe_values_local[fluxes].get_function_values(solution_local,\\n                                                        scratch.u_gradients);\\n \\n double sum = 0;\\n for (unsigned int i = 1; i < dofs_per_cell; ++i)\\n      {\\n for (unsigned int j = 0; j < dofs_per_cell; ++j)\\n          {\\n sum = 0;\\n for (unsigned int q = 0; q < n_q_points; ++q)\\n              sum += (scratch.fe_values.shape_grad(i, q) *\\n                      scratch.fe_values.shape_grad(j, q)) *\\n                     scratch.fe_values.JxW(q);\\n            scratch.cell_matrix(i, j) = sum;\\n          }\\n \\n sum = 0;\\n for (unsigned int q = 0; q < n_q_points; ++q)\\n          sum -= (scratch.fe_values.shape_grad(i, q) * scratch.u_gradients[q]) *\\n                 scratch.fe_values.JxW(q);\\n        scratch.cell_rhs(i) = sum;\\n      }\\n for (unsigned int j = 0; j < dofs_per_cell; ++j)\\n      {\\n sum = 0;\\n for (unsigned int q = 0; q < n_q_points; ++q)\\n          sum += scratch.fe_values.shape_value(j, q) * scratch.fe_values.JxW(q);\\n        scratch.cell_matrix(0, j) = sum;\\n      }\\n    {\\n sum = 0;\\n for (unsigned int q = 0; q < n_q_points; ++q)\\n        sum += scratch.u_values[q] * scratch.fe_values.JxW(q);\\n      scratch.cell_rhs(0) = sum;\\n    }\\n \\n    scratch.cell_matrix.gauss_jordan();\\n    scratch.cell_matrix.vmult(scratch.cell_sol, scratch.cell_rhs);\\n    cell->distribute_local_to_global(scratch.cell_sol, solution_u_post);\\n  }\\n \\n \\n \\n template <int dim>\\n void HDG<dim>::output_results(const unsigned int cycle)\\n  {\\n    std::string filename;\\n switch (refinement_mode)\\n      {\\n case global_refinement:\\n          filename = \\\"solution-global\\\";\\n break;\\n case adaptive_refinement:\\n          filename = \\\"solution-adaptive\\\";\\n break;\\n default:\\n DEAL_II_NOT_IMPLEMENTED();\\n      }\\n \\n    std::string face_out(filename);\\n    face_out += \\\"-face\\\";\\n \\n    filename += \\\"-q\\\" + Utilities::int_to_string(fe.degree, 1);\\n    filename += \\\"-\\\" + Utilities::int_to_string(cycle, 2);\\n    filename += \\\".vtk\\\";\\n    std::ofstream output(filename);\\n \\n DataOut<dim> data_out;\\n \\n    std::vector<std::string> names(dim, \\\"gradient\\\");\\n    names.emplace_back(\\\"solution\\\");\\n    std::vector<DataComponentInterpretation::DataComponentInterpretation>\\n      component_interpretation(\\n        dim + 1, DataComponentInterpretation::component_is_part_of_vector);\\n    component_interpretation[dim] =\\n DataComponentInterpretation::component_is_scalar;\\n    data_out.add_data_vector(dof_handler_local,\\n                             solution_local,\\n                             names,\\n                             component_interpretation);\\n \\n    std::vector<std::string> post_name(1, \\\"u_post\\\");\\n    std::vector<DataComponentInterpretation::DataComponentInterpretation>\\n      post_comp_type(1, DataComponentInterpretation::component_is_scalar);\\n    data_out.add_data_vector(dof_handler_u_post,\\n                             solution_u_post,\\n                             post_name,\\n                             post_comp_type);\\n \\n    data_out.build_patches(fe.degree);\\n    data_out.write_vtk(output);\\n \\n    face_out += \\\"-q\\\" + Utilities::int_to_string(fe.degree, 1);\\n    face_out += \\\"-\\\" + Utilities::int_to_string(cycle, 2);\\n    face_out += \\\".vtk\\\";\\n    std::ofstream face_output(face_out);\\n \\n DataOutFaces<dim>        data_out_face(false);\\n    std::vector<std::string> face_name(1, \\\"u_hat\\\");\\n    std::vector<DataComponentInterpretation::DataComponentInterpretation>\\n      face_component_type(1, DataComponentInterpretation::component_is_scalar);\\n \\n    data_out_face.add_data_vector(dof_handler,\\n                                  solution,\\n                                  face_name,\\n                                  face_component_type);\\n \\n    data_out_face.build_patches(fe.degree);\\n    data_out_face.write_vtk(face_output);\\n  }\\n \\n \\n \\n template <int dim>\\n void HDG<dim>::refine_grid(const unsigned int cycle)\\n  {\\n if (cycle == 0)\\n      {\\n GridGenerator::subdivided_hyper_cube(triangulation, 2, -1, 1);\\n triangulation.refine_global(3 - dim);\\n      }\\n else\\n switch (refinement_mode)\\n        {\\n case global_refinement:\\n            {\\n triangulation.clear();\\n GridGenerator::subdivided_hyper_cube(triangulation,\\n                                                   2 + (cycle % 2),\\n                                                   -1,\\n                                                   1);\\n triangulation.refine_global(3 - dim + cycle / 2);\\n break;\\n            }\\n \\n case adaptive_refinement:\\n            {\\n Vector<float> estimated_error_per_cell(\\n triangulation.n_active_cells());\\n \\n const FEValuesExtractors::Scalar scalar(dim);\\n              std::map<types::boundary_id, const Function<dim> *>\\n                neumann_boundary;\\n KellyErrorEstimator<dim>::estimate(dof_handler_local,\\n QGauss<dim - 1>(fe.degree + 1),\\n                                                 neumann_boundary,\\n                                                 solution_local,\\n                                                 estimated_error_per_cell,\\n                                                 fe_local.component_mask(\\n                                                   scalar));\\n \\n GridRefinement::refine_and_coarsen_fixed_number(\\n triangulation, estimated_error_per_cell, 0.3, 0.);\\n \\n triangulation.execute_coarsening_and_refinement();\\n \\n break;\\n            }\\n \\n default:\\n            {\\n DEAL_II_NOT_IMPLEMENTED();\\n            }\\n        }\\n \\n for (const auto &cell : triangulation.cell_iterators())\\n      for (const auto &face : cell->face_iterators())\\n        if (face->at_boundary())\\n          if ((std::fabs(face->center()[0] - (-1)) < 1e-12) ||\\n              (std::fabs(face->center()[1] - (-1)) < 1e-12))\\n            face->set_boundary_id(1);\\n  }\\n \\n template <int dim>\\n void HDG<dim>::run()\\n  {\\n for (unsigned int cycle = 0; cycle < 10; ++cycle)\\n      {\\n        std::cout << \\\"Cycle \\\" << cycle << ':' << std::endl;\\n \\n        refine_grid(cycle);\\n        setup_system();\\n        assemble_system(false);\\n        solve();\\n        postprocess();\\n        output_results(cycle);\\n      }\\n \\n if (refinement_mode == global_refinement)\\n      {\\n        convergence_table.evaluate_convergence_rates(\\n \\\"val L2\\\", \\\"cells\\\", ConvergenceTable::reduction_rate_log2, dim);\\n        convergence_table.evaluate_convergence_rates(\\n \\\"grad L2\\\", \\\"cells\\\", ConvergenceTable::reduction_rate_log2, dim);\\n        convergence_table.evaluate_convergence_rates(\\n \\\"val L2-post\\\", \\\"cells\\\", ConvergenceTable::reduction_rate_log2, dim);\\n      }\\n    convergence_table.write_text(std::cout);\\n  }\\n \\n} // end of namespace Step51\\n \\n \\n \\nint main()\\n{\\n const unsigned int dim = 2;\\n \\n try\\n    {\\n      {\\n        std::cout << \\\"Solving with Q1 elements, adaptive refinement\\\"\\n                  << std::endl\\n                  << \\\"=============================================\\\"\\n                  << std::endl\\n                  << std::endl;\\n \\n        Step51::HDG<dim> hdg_problem(1, Step51::HDG<dim>::adaptive_refinement);\\n        hdg_problem.run();\\n \\n        std::cout << std::endl;\\n      }\\n \\n      {\\n        std::cout << \\\"Solving with Q1 elements, global refinement\\\" << std::endl\\n                  << \\\"===========================================\\\" << std::endl\\n                  << std::endl;\\n \\n        Step51::HDG<dim> hdg_problem(1, Step51::HDG<dim>::global_refinement);\\n        hdg_problem.run();\\n \\n        std::cout << std::endl;\\n      }\\n \\n      {\\n        std::cout << \\\"Solving with Q3 elements, global refinement\\\" << std::endl\\n                  << \\\"===========================================\\\" << std::endl\\n                  << std::endl;\\n \\n        Step51::HDG<dim> hdg_problem(3, Step51::HDG<dim>::global_refinement);\\n        hdg_problem.run();\\n \\n        std::cout << std::endl;\\n      }\\n    }\\n catch (std::exception &exc)\\n    {\\n      std::cerr << std::endl\\n                << std::endl\\n                << \\\"----------------------------------------------------\\\"\\n                << std::endl;\\n      std::cerr << \\\"Exception on processing: \\\" << std::endl\\n                << exc.what() << std::endl\\n                << \\\"Aborting!\\\" << std::endl\\n                << \\\"----------------------------------------------------\\\"\\n                << std::endl;\\n return 1;\\n    }\\n catch (...)\\n    {\\n      std::cerr << std::endl\\n                << std::endl\\n                << \\\"----------------------------------------------------\\\"\\n                << std::endl;\\n      std::cerr << \\\"Unknown exception!\\\" << std::endl\\n                << \\\"Aborting!\\\" << std::endl\\n                << \\\"----------------------------------------------------\\\"\\n                << std::endl;\\n return 1;\\n    }\\n \\n return 0;\\n}\\naffine_constraints.h\\nchunk_sparse_matrix.h\\nDataOutInterface::write_vtkvoid write_vtk(std::ostream &out) constDefinition data_out_base.cc:7681\\nDataOut_DoFData::add_data_vectorvoid add_data_vector(const VectorType &data, const std::vector< std::string > &names, const DataVectorType type=type_automatic, const std::vector< DataComponentInterpretation::DataComponentInterpretation > &data_component_interpretation={})Definition data_out_dof_data.h:1069\\nDataOut::build_patchesvirtual void build_patches(const unsigned int n_subdivisions=0)Definition data_out.cc:1062\\nDoFHandler::reinitvoid reinit(const Triangulation< dim, spacedim > &tria)\\nFiniteElement::component_maskComponentMask component_mask(const FEValuesExtractors::Scalar &scalar) const\\nTensor::norm_squareconstexpr numbers::NumberTraits< Number >::real_type norm_square() const\\nVector::sizevirtual size_type size() const override\\nconvergence_table.h\\ndata_out_faces.h\\ndof_handler.h\\ndof_renumbering.h\\ndof_tools.h\\ndynamic_sparsity_pattern.h\\nerror_estimator.h\\nfe_values.h\\nfe_dgq.h\\nfe_face.h\\nfe_system.h\\nfull_matrix.h\\nfunction.h\\ngrid_refinement.h\\ntria.h\\ngrid_generator.h\\nexceptions.h\\nDifferentiation::SD::fabsExpression fabs(const Expression &x)Definition symengine_math.cc:269\\nLocalIntegrators::Advection::cell_matrixvoid cell_matrix(FullMatrix< double > &M, const FEValuesBase< dim > &fe, const FEValuesBase< dim > &fetest, const ArrayView< const std::vector< double > > &velocity, const double factor=1.)Definition advection.h:74\\nPhysics::Elasticity::Kinematics::eSymmetricTensor< 2, dim, Number > e(const Tensor< 2, dim, Number > &F)\\nPhysics::Elasticity::Kinematics::dSymmetricTensor< 2, dim, Number > d(const Tensor< 2, dim, Number > &F, const Tensor< 2, dim, Number > &dF_dt)\\nWorkStream::internal::tbb_no_coloring::runvoid run(const Iterator &begin, const std_cxx20::type_identity_t< Iterator > &end, Worker worker, Copier copier, const ScratchData &sample_scratch_data, const CopyData &sample_copy_data, const unsigned int queue_length, const unsigned int chunk_size)Definition work_stream.h:471\\ninternal::EvaluatorQuantity::value@ value\\ninternal::EvaluatorQuantity::gradient@ gradient\\ndata_out.h\\nprecondition.h\\nquadrature_lib.h\\nsolver_bicgstab.h\\ntensor_function.h\\nvector.h\\nvector_tools.h\\nwork_stream.h\\n \\n\\n\\n\\n\\nGenerated by\\u00a0 1.11.0\\n\\n\\n\\n\\n\", \"type\": \"Document\"}}]"