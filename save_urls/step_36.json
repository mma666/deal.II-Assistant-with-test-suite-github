"[{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"document\", \"Document\"], \"kwargs\": {\"metadata\": {\"source\": \"https://dealii.org/current/doxygen/deal.II/step_36.html\", \"content_type\": \"text/html\", \"title\": \"The deal.II Library: The step-36 tutorial program\", \"language\": \"en-US\"}, \"page_content\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\nThe deal.II Library: The step-36 tutorial program\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\u00a0Reference documentation for deal.II version 9.6.0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\\(\\\\newcommand{\\\\dealvcentcolon}{\\\\mathrel{\\\\mathop{:}}}\\\\)\\n\\\\(\\\\newcommand{\\\\dealcoloneq}{\\\\dealvcentcolon\\\\mathrel{\\\\mkern-1.2mu}=}\\\\)\\n\\\\(\\\\newcommand{\\\\jump}[1]{\\\\left[\\\\!\\\\left[ #1 \\\\right]\\\\!\\\\right]}\\\\)\\n\\\\(\\\\newcommand{\\\\average}[1]{\\\\left\\\\{\\\\!\\\\left\\\\{ #1 \\\\right\\\\}\\\\!\\\\right\\\\}}\\\\)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLoading...\\nSearching...\\nNo Matches\\n\\n\\n\\n\\n\\n\\n\\nThe step-36 tutorial program\\n\\n\\nThis tutorial depends on step-4.\\n\\n\\nTable of contents\\n\\n\\n Introduction\\n\\nEigenvalues and Dirichlet boundary conditions\\nImplementation details\\n\\n The commented program\\n\\nInclude files\\nThe EigenvalueProblem class template\\nImplementation of the EigenvalueProblem class\\n\\nEigenvalueProblem::EigenvalueProblem\\nEigenvalueProblem::make_grid_and_dofs\\nEigenvalueProblem::assemble_system\\nEigenvalueProblem::solve\\nEigenvalueProblem::output_results\\nEigenvalueProblem::run\\n\\nThe main function\\n\\n\\n Results\\n\\nRunning the problem\\nPossibilities for extensions\\n\\n The plain program\\n   \\n\\n\\nThis program was contributed by Toby D. Young and Wolfgang Bangerth. \\nPreamble\\nThe problem we want to solve in this example is an eigenspectrum problem. Eigenvalue problems appear in a wide context of problems, for example in the computation of electromagnetic standing waves in cavities, vibration modes of drum membranes, or oscillations of lakes and estuaries. One of the most enigmatic applications is probably the computation of stationary or quasi-static wave functions in quantum mechanics. The latter application is what we would like to investigate here, though the general techniques outlined in this program are of course equally applicable to the other applications above.\\nEigenspectrum problems have the general form    \\n\\\\begin{align*}\\n    L \\\\Psi &= \\\\varepsilon \\\\Psi \\\\qquad &&\\\\text{in}\\\\ \\\\Omega, \\\\\\\\\\n    \\\\Psi   &= 0 &&\\\\text{on}\\\\ \\\\partial\\\\Omega,\\n\\\\end{align*}\\n\\n where the Dirichlet boundary condition on \\\\(\\\\Psi=\\\\Psi(\\\\mathbf x)\\\\) could also be replaced by Neumann or Robin conditions; \\\\(L\\\\) is an operator that generally also contains differential operators.\\nUnder suitable conditions, the above equations have a set of solutions \\\\(\\\\Psi_\\\\ell,\\\\varepsilon_\\\\ell\\\\), \\\\(\\\\ell\\\\in {\\\\cal I}\\\\), where \\\\(\\\\cal I\\\\) can be a finite or infinite set (and in the latter case it may be a discrete or sometimes at least in part a continuous set). In either case, let us note that there is no longer just a single solution, but a set of solutions (the various eigenfunctions and corresponding eigenvalues) that we want to compute. The problem of numerically finding all eigenvalues (eigenfunctions) of such eigenvalue problems is a formidable challenge. In fact, if the set \\\\(\\\\cal I\\\\) is infinite, the challenge is of course intractable. Most of the time however we are really only interested in a small subset of these values (functions); and fortunately, the interface to the SLEPc library that we will use for this tutorial program allows us to select which portion of the eigenspectrum and how many solutions we want to solve for.\\nIn this program, the eigenspectrum solvers we use are classes provided by deal.II that wrap around the linear algebra implementation of the SLEPc library; SLEPc itself builds on the PETSc library for linear algebra contents.\\n Introduction\\nThe basic equation of stationary quantum mechanics is the Schr\\u00f6dinger equation which models the motion of particles in an external potential \\\\(V(\\\\mathbf x)\\\\). The particle is described by a wave function \\\\(\\\\Psi(\\\\mathbf x)\\\\) that satisfies a relation of the (nondimensionalized) form    \\n\\\\begin{align*} [-\\\\Delta + V(\\\\mathbf x)]\\n\\\\Psi(\\\\mathbf x) &= \\\\varepsilon \\\\Psi(\\\\mathbf x) \\\\qquad &&\\\\text{in}\\\\\\n\\\\Omega\\\\quad, \\\\\\\\ \\\\Psi &= 0 &&\\\\text{on}\\\\ \\\\partial\\\\Omega\\\\quad.\\n\\\\end{align*}\\n\\n As a consequence, this particle can only exist in a certain number of eigenstates that correspond to the energy eigenvalues \\\\(\\\\varepsilon_\\\\ell\\\\) admitted as solutions of this equation. The orthodox (Copenhagen) interpretation of quantum mechanics posits that, if a particle has energy \\\\(\\\\varepsilon_\\\\ell\\\\) then the probability of finding it at location \\\\(\\\\mathbf x\\\\) is proportional to  \\\\(|\\\\Psi_\\\\ell(\\\\mathbf\\nx)|^2\\\\) where \\\\(\\\\Psi_\\\\ell\\\\) is the eigenfunction that corresponds to this eigenvalue.\\nIn order to numerically find solutions to this equation, i.e. a set of pairs of eigenvalues/eigenfunctions, we use the usual finite element approach of multiplying the equation from the left with test functions, integrating by parts, and searching for solutions in finite dimensional spaces by approximating  \\\\(\\\\Psi(\\\\mathbf\\nx)\\\\approx\\\\Psi_h(\\\\mathbf x)=\\\\sum_{j}\\\\phi_j(\\\\mathbf x)\\\\tilde\\\\psi_j\\\\), where \\\\(\\\\tilde\\\\psi\\\\) is a vector of expansion coefficients. We then immediately arrive at the following equation that discretizes the continuous eigenvalue problem:   \\n\\\\[ \\\\sum_j [(\\\\nabla\\\\phi_i,\\n\\\\nabla\\\\phi_j)+(V(\\\\mathbf x)\\\\phi_i,\\\\phi_j)] \\\\tilde{\\\\psi}_j =\\n\\\\varepsilon_h \\\\sum_j (\\\\phi_i, \\\\phi_j) \\\\tilde{\\\\psi}_j\\\\quad.  \\\\]\\n\\n In matrix and vector notation, this equation then reads:  \\n\\\\[ A\\n\\\\tilde{\\\\Psi} = \\\\varepsilon_h M \\\\tilde{\\\\Psi} \\\\quad, \\\\]\\n\\n where \\\\(A\\\\) is the stiffness matrix arising from the differential operator \\\\(L\\\\), and \\\\(M\\\\) is the mass matrix. The solution to the eigenvalue problem is an eigenspectrum \\\\(\\\\varepsilon_{h,\\\\ell}\\\\), with associated eigenfunctions \\\\(\\\\Psi_\\\\ell=\\\\sum_j \\\\phi_j\\\\tilde{\\\\psi}_j\\\\).\\nEigenvalues and Dirichlet boundary conditions\\nIn this program, we use Dirichlet boundary conditions for the wave function \\\\(\\\\Psi\\\\). What this means, from the perspective of a finite element code, is that only the interior degrees of freedom are real degrees of freedom: the ones on the boundary are not free but are forced to have a zero value, after all. On the other hand, the finite element method gains much of its power and simplicity from the fact that we just do the same thing on every cell, without having to think too much about where a cell is, whether it bounds on a less refined cell and consequently has a hanging node, or is adjacent to the boundary. All such checks would make the assembly of finite element linear systems unbearably difficult to write and even more so to read.\\nConsequently, of course, when you distribute degrees of freedom with your DoFHandler object, you don't care whether some of the degrees of freedom you enumerate are at a Dirichlet boundary. They all get numbers. We just have to take care of these degrees of freedom at a later time when we apply boundary values. There are two basic ways of doing this (either using MatrixTools::apply_boundary_values() after assembling the linear system, or using AffineConstraints::distribute_local_to_global() during assembly; see the constraints topic for more information), but both result in the same: a linear system that has a total number of rows equal to the number of all degrees of freedom, including those that lie on the boundary. However, degrees of freedom that are constrained by Dirichlet conditions are separated from the rest of the linear system by zeroing out the corresponding row and column, putting a single positive entry on the diagonal, and the corresponding Dirichlet value on the right hand side.\\nIf you assume for a moment that we had renumbered degrees of freedom in such a way that all of those on the Dirichlet boundary come last, then the linear system we would get when solving a regular PDE with a right hand side would look like this:            \\n\\\\begin{align*}\\n  \\\\begin{pmatrix}\\n    A_i & 0 \\\\\\\\ 0 & D_b\\n  \\\\end{pmatrix}\\n  \\\\begin{pmatrix}\\n    U_i \\\\\\\\ U_b\\n  \\\\end{pmatrix}\\n  =\\n  \\\\begin{pmatrix}\\n    F_i \\\\\\\\ F_b\\n  \\\\end{pmatrix}.\\n\\\\end{align*}\\n\\n Here, subscripts \\\\(i\\\\) and \\\\(b\\\\) correspond to interior and boundary degrees of freedom, respectively. The interior degrees of freedom satisfy the linear system \\\\(A_i U_i=F_i\\\\) which yields the correct solution in the interior, and boundary values are determined by \\\\(U_b = D_b^{-1} F_b\\\\) where \\\\(D_b\\\\) is a diagonal matrix that results from the process of eliminating boundary degrees of freedom, and \\\\(F_b\\\\) is chosen in such a way that \\\\(U_{b,j}=D_{b,jj}^{-1} F_{b,j}\\\\) has the correct boundary values for every boundary degree of freedom \\\\(j\\\\). (For the curious, the entries of the matrix \\\\(D_b\\\\) result from adding modified local contributions to the global matrix where for the local matrices the diagonal elements, if non-zero, are set to their absolute value; otherwise, they are set to the average of absolute values of the diagonal. This process guarantees that the entries of \\\\(D_b\\\\) are positive and of a size comparable to the rest of the diagonal entries, ensuring that the resulting matrix does not incur unreasonable losses of accuracy due to roundoff involving matrix entries of drastically different size. The actual values that end up on the diagonal are difficult to predict and you should treat them as arbitrary and unpredictable, but positive.)\\nFor \\\"regular\\\" linear systems, this all leads to the correct solution. On the other hand, for eigenvalue problems, this is not so trivial. There, eliminating boundary values affects both matrices \\\\(A\\\\) and \\\\(M\\\\) that we will solve with in the current tutorial program. After elimination of boundary values, we then receive an eigenvalue problem that can be partitioned like this:                \\n\\\\begin{align*}\\n  \\\\begin{pmatrix}\\n    A_i & 0 \\\\\\\\ 0 & D_A\\n  \\\\end{pmatrix}\\n  \\\\begin{pmatrix}\\n    \\\\tilde\\\\Psi_i \\\\\\\\ \\\\tilde\\\\Psi_b\\n  \\\\end{pmatrix}\\n  =\\n  \\\\epsilon_h\\n  \\\\begin{pmatrix}\\n    M_i & 0 \\\\\\\\ 0 & D_M\\n  \\\\end{pmatrix}\\n  \\\\begin{pmatrix}\\n    \\\\tilde\\\\Psi_i \\\\\\\\ \\\\tilde\\\\Psi_b\\n  \\\\end{pmatrix}.\\n\\\\end{align*}\\n\\n This form makes it clear that there are two sets of eigenvalues: the ones we care about, and spurious eigenvalues from the separated problem   \\n\\\\[\\n  D_A \\\\tilde \\\\Psi_b = \\\\epsilon_h D_M \\\\Psi_b.\\n\\\\]\\n\\n These eigenvalues are spurious since they result from an eigenvalue system that operates only on boundary nodes \\u2013 nodes that are not real degrees of freedom. Of course, since the two matrices \\\\(D_A,D_M\\\\) are diagonal, we can exactly quantify these spurious eigenvalues: they are \\\\(\\\\varepsilon_{h,j}=D_{A,jj}/D_{M,jj}\\\\) (where the indices \\\\(j\\\\) corresponds exactly to the degrees of freedom that are constrained by Dirichlet boundary values).\\nSo how does one deal with them? The fist part is to recognize when our eigenvalue solver finds one of them. To this end, the program computes and prints an interval within which these eigenvalues lie, by computing the minimum and maximum of the expression \\\\(\\\\varepsilon_{h,j}=D_{A,jj}/D_{M,jj}\\\\) over all constrained degrees of freedom. In the program below, this already suffices: we find that this interval lies outside the set of smallest eigenvalues and corresponding eigenfunctions we are interested in and compute, so there is nothing we need to do here.\\nOn the other hand, it may happen that we find that one of the eigenvalues we compute in this program happens to be in this interval, and in that case we would not know immediately whether it is a spurious or a true eigenvalue. In that case, one could simply scale the diagonal elements of either matrix after computing the two matrices, thus shifting them away from the frequency of interest in the eigen-spectrum. This can be done by using the following code, making sure that all spurious eigenvalues are exactly equal to \\\\(1.234\\\\cdot 10^5\\\\): for (unsigned int i = 0; i < dof_handler.n_dofs(); ++i)\\n if (constraints.is_constrained(i))\\n    {\\n      stiffness_matrix.set(i, i, 1.234e5);\\n      mass_matrix.set(i, i, 1);\\n    }\\n However, this strategy is not pursued here as the spurious eigenvalues we get from our program as-is happen to be greater than the lowest five that we will calculate and are interested in.\\nImplementation details\\nThe program below is essentially just a slightly modified version of step-4. The things that are different are the following:\\n\\n\\nThe main class (named EigenvalueProblem) now no longer has a single solution vector, but a whole set of vectors for the various eigenfunctions we want to compute. Moreover, the main function, which has the top-level control over everything here, initializes and finalizes the interface to SLEPc and PETSc simultaneously via SlepcInitialize and SlepFinalize.\\n\\n\\n\\nWe use PETSc matrices and vectors as in step-17 and step-18 since that is what the SLEPc eigenvalue solvers require.\\n\\n\\n\\nThe function EigenvalueProblem::solve is entirely different from anything seen so far in the tutorial, as it does not just solve a linear system but actually solves the eigenvalue problem. It is built on the SLEPc library, and more immediately on the deal.II SLEPc wrappers in the class SLEPcWrappers::SolverKrylovSchur.\\n\\n\\n\\nWe use the ParameterHandler class to describe a few input parameters, such as the exact form of the potential  \\\\(V({\\\\mathbf\\nx})\\\\), the number of global refinement steps of the mesh, or the number of eigenvalues we want to solve for. We could go much further with this but stop at making only a few of the things that one could select at run time actual input file parameters. In order to see what could be done in this regard, take a look at step-29 and step-33.\\n\\n\\n\\nWe use the FunctionParser class to make the potential  \\\\(V(\\\\mathbf\\nx)\\\\) a run-time parameter that can be specified in the input file as a formula.\\n\\n\\n\\nThe rest of the program follows in a pretty straightforward way from step-4.\\n The commented program\\n Include files\\nAs mentioned in the introduction, this program is essentially only a slightly revised version of step-4. As a consequence, most of the following include files are as used there, or at least as used already in previous tutorial programs:\\n\\u00a0 #include <deal.II/base/quadrature_lib.h>\\n\\u00a0 #include <deal.II/base/function.h>\\n\\u00a0 #include <deal.II/base/function_parser.h>\\n\\u00a0 #include <deal.II/base/parameter_handler.h>\\n\\u00a0 #include <deal.II/base/utilities.h>\\n\\u00a0 #include <deal.II/grid/tria.h>\\n\\u00a0 #include <deal.II/grid/grid_generator.h>\\n\\u00a0 #include <deal.II/dofs/dof_handler.h>\\n\\u00a0 #include <deal.II/dofs/dof_tools.h>\\n\\u00a0 #include <deal.II/fe/fe_q.h>\\n\\u00a0 #include <deal.II/fe/fe_values.h>\\n\\u00a0 #include <deal.II/numerics/vector_tools.h>\\n\\u00a0 #include <deal.II/numerics/data_out.h>\\n\\u00a0 #include <deal.II/lac/affine_constraints.h>\\n\\u00a0 #include <deal.II/lac/full_matrix.h>\\n\\u00a0 \\nIndexSet is used to set the size of each PETScWrappers::MPI::Vector:\\n\\u00a0 #include <deal.II/base/index_set.h>\\n\\u00a0 \\nPETSc appears here because SLEPc depends on this library:\\n\\u00a0 #include <deal.II/lac/petsc_sparse_matrix.h>\\n\\u00a0 #include <deal.II/lac/petsc_vector.h>\\n\\u00a0 \\nAnd then we need to actually import the interfaces for solvers that SLEPc provides:\\n\\u00a0 #include <deal.II/lac/slepc_solver.h>\\n\\u00a0 \\nWe also need some standard C++:\\n\\u00a0 #include <fstream>\\n\\u00a0 #include <iostream>\\n\\u00a0 \\nFinally, as in previous programs, we import all the deal.II class and function names into the namespace into which everything in this program will go:\\n\\u00a0 namespace Step36\\n\\u00a0 {\\n\\u00a0   using namespace dealii;\\n\\u00a0 \\ndealiiDefinition namespace_dealii.h:25\\n The EigenvalueProblem class template\\nFollowing is the class declaration for the main class template. It looks pretty much exactly like what has already been shown in step-4:\\n\\u00a0   template <int dim>\\n\\u00a0   class EigenvalueProblem\\n\\u00a0   {\\n\\u00a0   public:\\n\\u00a0     EigenvalueProblem(const std::string &prm_file);\\n\\u00a0     void run();\\n\\u00a0 \\n\\u00a0   private:\\n\\u00a0     void         make_grid_and_dofs();\\n\\u00a0     void         assemble_system();\\n\\u00a0     unsigned int solve();\\n\\u00a0     void         output_results() const;\\n\\u00a0 \\n\\u00a0     Triangulation<dim> triangulation;\\n\\u00a0     const FE_Q<dim>    fe;\\n\\u00a0     DoFHandler<dim>    dof_handler;\\n\\u00a0 \\nDoFHandlerDefinition dof_handler.h:317\\nFE_QDefinition fe_q.h:554\\nTriangulationDefinition tria.h:1323\\ntriangulationconst ::parallel::distributed::Triangulation< dim, spacedim > * triangulationDefinition p4est_wrappers.cc:68\\nWith these exceptions: For our eigenvalue problem, we need both a stiffness matrix for the left hand side as well as a mass matrix for the right hand side. We also need not just one solution function, but a whole set of these for the eigenfunctions we want to compute, along with the corresponding eigenvalues:\\n\\u00a0     PETScWrappers::SparseMatrix             stiffness_matrix, mass_matrix;\\n\\u00a0     std::vector<PETScWrappers::MPI::Vector> eigenfunctions;\\n\\u00a0     std::vector<double>                     eigenvalues;\\n\\u00a0 \\nPETScWrappers::SparseMatrixDefinition petsc_sparse_matrix.h:54\\neigenvaluesstd::array< Number, 1 > eigenvalues(const SymmetricTensor< 2, 1, Number > &T)\\nAnd then we need an object that will store several run-time parameters that we will specify in an input file :\\n\\u00a0     ParameterHandler parameters;\\n\\u00a0 \\nParameterHandlerDefinition parameter_handler.h:855\\nFinally, we will have an object that contains \\\"constraints\\\" on our degrees of freedom. This could include hanging node constraints if we had adaptively refined meshes (which we don't have in the current program). Here, we will store the constraints for boundary nodes \\\\(U_i=0\\\\).\\n\\u00a0     AffineConstraints<double> constraints;\\n\\u00a0   };\\n\\u00a0 \\nAffineConstraintsDefinition affine_constraints.h:507\\n Implementation of the EigenvalueProblem class\\n EigenvalueProblem::EigenvalueProblem\\nFirst up, the constructor. The main new part is handling the run-time input parameters. We need to declare their existence first, and then read their values from the input file whose name is specified as an argument to this function:\\n\\u00a0   template <int dim>\\n\\u00a0   EigenvalueProblem<dim>::EigenvalueProblem(const std::string &prm_file)\\n\\u00a0     : fe(1)\\n\\u00a0     , dof_handler(triangulation)\\n\\u00a0   {\\nTODO investigate why the minimum number of refinement steps required to obtain the correct eigenvalue degeneracies is 6\\n\\u00a0     parameters.declare_entry(\\n\\u00a0       \\\"Global mesh refinement steps\\\",\\n\\u00a0       \\\"5\\\",\\n\\u00a0       Patterns::Integer(0, 20),\\n\\u00a0       \\\"The number of times the 1-cell coarse mesh should \\\"\\n\\u00a0       \\\"be refined globally for our computations.\\\");\\n\\u00a0     parameters.declare_entry(\\\"Number of eigenvalues/eigenfunctions\\\",\\n\\u00a0                              \\\"5\\\",\\n\\u00a0                              Patterns::Integer(0, 100),\\n\\u00a0                              \\\"The number of eigenvalues/eigenfunctions \\\"\\n\\u00a0                              \\\"to be computed.\\\");\\n\\u00a0     parameters.declare_entry(\\\"Potential\\\",\\n\\u00a0                              \\\"0\\\",\\n\\u00a0                              Patterns::Anything(),\\n\\u00a0                              \\\"A functional description of the potential.\\\");\\n\\u00a0 \\n\\u00a0     parameters.parse_input(prm_file);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\nPatterns::AnythingDefinition patterns.h:1021\\nPatterns::IntegerDefinition patterns.h:188\\n EigenvalueProblem::make_grid_and_dofs\\nThe next function creates a mesh on the domain \\\\([-1,1]^d\\\\), refines it as many times as the input file calls for, and then attaches a DoFHandler to it and initializes the matrices and vectors to their correct sizes. We also build the constraints that correspond to the boundary values \\\\(u|_{\\\\partial\\\\Omega}=0\\\\).\\nFor the matrices, we use the PETSc wrappers. These have the ability to allocate memory as necessary as non-zero entries are added. This seems inefficient: we could as well first compute the sparsity pattern, initialize the matrices with it, and as we then insert entries we can be sure that we do not need to re-allocate memory and free the one used previously. One way to do that would be to use code like this:  DynamicSparsityPattern\\n   dsp (dof_handler.n_dofs(),\\n        dof_handler.n_dofs());\\nDoFTools::make_sparsity_pattern (dof_handler, dsp);\\ndsp.compress ();\\nstiffness_matrix.reinit (dsp);\\nmass_matrix.reinit (dsp);\\nDynamicSparsityPatternDefinition dynamic_sparsity_pattern.h:322\\nDoFTools::make_sparsity_patternvoid make_sparsity_pattern(const DoFHandler< dim, spacedim > &dof_handler, SparsityPatternBase &sparsity_pattern, const AffineConstraints< number > &constraints={}, const bool keep_constrained_dofs=true, const types::subdomain_id subdomain_id=numbers::invalid_subdomain_id)Definition dof_tools_sparsity.cc:56\\n  instead of the two reinit() calls for the stiffness and mass matrices below.\\nThis doesn't quite work, unfortunately. The code above may lead to a few entries in the non-zero pattern to which we only ever write zero entries; most notably, this holds true for off-diagonal entries for those rows and columns that belong to boundary nodes. This shouldn't be a problem, but for whatever reason, PETSc's ILU preconditioner, which we use to solve linear systems in the eigenvalue solver, doesn't like these extra entries and aborts with an error message.\\nIn the absence of any obvious way to avoid this, we simply settle for the second best option, which is have PETSc allocate memory as necessary. That said, since this is not a time critical part, this whole affair is of no further importance.\\n\\u00a0   template <int dim>\\n\\u00a0   void EigenvalueProblem<dim>::make_grid_and_dofs()\\n\\u00a0   {\\n\\u00a0     GridGenerator::hyper_cube(triangulation, -1, 1);\\n\\u00a0     triangulation.refine_global(\\n\\u00a0       parameters.get_integer(\\\"Global mesh refinement steps\\\"));\\n\\u00a0     dof_handler.distribute_dofs(fe);\\n\\u00a0 \\n\\u00a0     DoFTools::make_zero_boundary_constraints(dof_handler, constraints);\\n\\u00a0     constraints.close();\\n\\u00a0 \\n\\u00a0     stiffness_matrix.reinit(dof_handler.n_dofs(),\\n\\u00a0                             dof_handler.n_dofs(),\\n\\u00a0                             dof_handler.max_couplings_between_dofs());\\n\\u00a0     mass_matrix.reinit(dof_handler.n_dofs(),\\n\\u00a0                        dof_handler.n_dofs(),\\n\\u00a0                        dof_handler.max_couplings_between_dofs());\\n\\u00a0 \\nTriangulation::refine_globalvoid refine_global(const unsigned int times=1)\\nDoFTools::make_zero_boundary_constraintsvoid make_zero_boundary_constraints(const DoFHandler< dim, spacedim > &dof, const types::boundary_id boundary_id, AffineConstraints< number > &zero_boundary_constraints, const ComponentMask &component_mask={})Definition dof_tools_constraints.cc:4712\\nGridGenerator::hyper_cubevoid hyper_cube(Triangulation< dim, spacedim > &tria, const double left=0., const double right=1., const bool colorize=false)\\nThe next step is to take care of the eigenspectrum. In this case, the outputs are eigenvalues and eigenfunctions, so we set the size of the list of eigenfunctions and eigenvalues to be as large as we asked for in the input file. When using a PETScWrappers::MPI::Vector, the Vector is initialized using an IndexSet. IndexSet is used not only to resize the PETScWrappers::MPI::Vector but it also associates an index in the PETScWrappers::MPI::Vector with a degree of freedom (see step-40 for a more detailed explanation). The function complete_index_set() creates an IndexSet where every valid index is part of the set. Note that this program can only be run sequentially and will throw an exception if used in parallel.\\n\\u00a0     IndexSet eigenfunction_index_set = dof_handler.locally_owned_dofs();\\n\\u00a0     eigenfunctions.resize(\\n\\u00a0       parameters.get_integer(\\\"Number of eigenvalues/eigenfunctions\\\"));\\n\\u00a0     for (auto &eigenfunction : eigenfunctions)\\n\\u00a0       eigenfunction.reinit(eigenfunction_index_set, MPI_COMM_WORLD);\\n\\u00a0 \\n\\u00a0     eigenvalues.resize(eigenfunctions.size());\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\nIndexSetDefinition index_set.h:70\\n EigenvalueProblem::assemble_system\\nHere, we assemble the global stiffness and mass matrices from local contributions   \\\\(A^K_{ij} = \\\\int_K \\\\nabla\\\\varphi_i(\\\\mathbf x) \\\\cdot\\n   \\\\nabla\\\\varphi_j(\\\\mathbf x) + V(\\\\mathbf x)\\\\varphi_i(\\\\mathbf\\n   x)\\\\varphi_j(\\\\mathbf x)\\\\) and  \\\\(M^K_{ij} = \\\\int_K \\\\varphi_i(\\\\mathbf\\n   x)\\\\varphi_j(\\\\mathbf x)\\\\) respectively. This function should be immediately familiar if you've seen previous tutorial programs. The only thing new would be setting up an object that described the potential \\\\(V(\\\\mathbf x)\\\\) using the expression that we got from the input file. We then need to evaluate this object at the quadrature points on each cell. If you've seen how to evaluate function objects (see, for example the coefficient in step-5), the code here will also look rather familiar.\\n\\u00a0   template <int dim>\\n\\u00a0   void EigenvalueProblem<dim>::assemble_system()\\n\\u00a0   {\\n\\u00a0     const QGauss<dim> quadrature_formula(fe.degree + 1);\\n\\u00a0 \\n\\u00a0     FEValues<dim> fe_values(fe,\\n\\u00a0                             quadrature_formula,\\n\\u00a0                             update_values | update_gradients |\\n\\u00a0                               update_quadrature_points | update_JxW_values);\\n\\u00a0 \\n\\u00a0     const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\\n\\u00a0     const unsigned int n_q_points    = quadrature_formula.size();\\n\\u00a0 \\n\\u00a0     FullMatrix<double> cell_stiffness_matrix(dofs_per_cell, dofs_per_cell);\\n\\u00a0     FullMatrix<double> cell_mass_matrix(dofs_per_cell, dofs_per_cell);\\n\\u00a0 \\n\\u00a0     std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\\n\\u00a0 \\n\\u00a0     FunctionParser<dim> potential;\\n\\u00a0     potential.initialize(FunctionParser<dim>::default_variable_names(),\\n\\u00a0                          parameters.get(\\\"Potential\\\"),\\n\\u00a0                          typename FunctionParser<dim>::ConstMap());\\n\\u00a0 \\n\\u00a0     std::vector<double> potential_values(n_q_points);\\n\\u00a0     for (const auto &cell : dof_handler.active_cell_iterators())\\n\\u00a0       {\\n\\u00a0         fe_values.reinit(cell);\\n\\u00a0         cell_stiffness_matrix = 0;\\n\\u00a0         cell_mass_matrix      = 0;\\n\\u00a0 \\n\\u00a0         potential.value_list(fe_values.get_quadrature_points(),\\n\\u00a0                              potential_values);\\n\\u00a0 \\n\\u00a0         for (unsigned int q_point = 0; q_point < n_q_points; ++q_point)\\n\\u00a0           for (unsigned int i = 0; i < dofs_per_cell; ++i)\\n\\u00a0             for (unsigned int j = 0; j < dofs_per_cell; ++j)\\n\\u00a0               {\\n\\u00a0                 cell_stiffness_matrix(i, j) +=           \\n\\u00a0                   (fe_values.shape_grad(i, q_point) *    \\n\\u00a0                      fe_values.shape_grad(j, q_point)    \\n\\u00a0                    +                                     \\n\\u00a0                    potential_values[q_point] *           \\n\\u00a0                      fe_values.shape_value(i, q_point) * \\n\\u00a0                      fe_values.shape_value(j, q_point)   \\n\\u00a0                    ) *                                   \\n\\u00a0                   fe_values.JxW(q_point);                \\n\\u00a0 \\n\\u00a0                 cell_mass_matrix(i, j) +=              \\n\\u00a0                   (fe_values.shape_value(i, q_point) * \\n\\u00a0                    fe_values.shape_value(j, q_point)   \\n\\u00a0                    ) *                                 \\n\\u00a0                   fe_values.JxW(q_point);              \\n\\u00a0               }\\n\\u00a0 \\nFEValuesDefinition fe_values.h:63\\nFullMatrixDefinition full_matrix.h:79\\nFunctionParserDefinition function_parser.h:227\\nFunctionParser::initializevirtual void initialize(const std::string &vars, const std::vector< std::string > &expressions, const ConstMap &constants, const bool time_dependent=false) overrideDefinition function_parser.cc:73\\nFunctionParser::ConstMapstd::map< std::string, double > ConstMapDefinition function_parser.h:282\\nQGaussDefinition quadrature_lib.h:40\\nupdate_values@ update_valuesShape function values.Definition fe_update_flags.h:75\\nupdate_JxW_values@ update_JxW_valuesTransformed quadrature weights.Definition fe_update_flags.h:134\\nupdate_gradients@ update_gradientsShape function gradients.Definition fe_update_flags.h:81\\nupdate_quadrature_points@ update_quadrature_pointsTransformed quadrature points.Definition fe_update_flags.h:127\\nNow that we have the local matrix contributions, we transfer them into the global objects and take care of zero boundary constraints:\\n\\u00a0         cell->get_dof_indices(local_dof_indices);\\n\\u00a0 \\n\\u00a0         constraints.distribute_local_to_global(cell_stiffness_matrix,\\n\\u00a0                                                local_dof_indices,\\n\\u00a0                                                stiffness_matrix);\\n\\u00a0         constraints.distribute_local_to_global(cell_mass_matrix,\\n\\u00a0                                                local_dof_indices,\\n\\u00a0                                                mass_matrix);\\n\\u00a0       }\\n\\u00a0 \\nAt the end of the function, we tell PETSc that the matrices have now been fully assembled and that the sparse matrix representation can now be compressed as no more entries will be added:\\n\\u00a0     stiffness_matrix.compress(VectorOperation::add);\\n\\u00a0     mass_matrix.compress(VectorOperation::add);\\n\\u00a0 \\n\\u00a0 \\nVectorOperation::add@ addDefinition vector_operation.h:53\\nBefore leaving the function, we calculate spurious eigenvalues, introduced to the system by zero Dirichlet constraints. As discussed in the introduction, the use of Dirichlet boundary conditions coupled with the fact that the degrees of freedom located at the boundary of the domain remain part of the linear system we solve, introduces a number of spurious eigenvalues. Below, we output the interval within which they all lie to ensure that we can ignore them should they show up in our computations.\\n\\u00a0     double min_spurious_eigenvalue = std::numeric_limits<double>::max(),\\n\\u00a0            max_spurious_eigenvalue = -std::numeric_limits<double>::max();\\n\\u00a0 \\n\\u00a0     for (unsigned int i = 0; i < dof_handler.n_dofs(); ++i)\\n\\u00a0       if (constraints.is_constrained(i))\\n\\u00a0         {\\n\\u00a0           const double ev         = stiffness_matrix(i, i) / mass_matrix(i, i);\\n\\u00a0           min_spurious_eigenvalue = std::min(min_spurious_eigenvalue, ev);\\n\\u00a0           max_spurious_eigenvalue = std::max(max_spurious_eigenvalue, ev);\\n\\u00a0         }\\n\\u00a0 \\n\\u00a0     std::cout << \\\"   Spurious eigenvalues are all in the interval \\\" << '['\\n\\u00a0               << min_spurious_eigenvalue << ',' << max_spurious_eigenvalue\\n\\u00a0               << ']' << std::endl;\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\nstd::min::VectorizedArray< Number, width > min(const ::VectorizedArray< Number, width > &, const ::VectorizedArray< Number, width > &)Definition vectorization.h:6960\\nstd::max::VectorizedArray< Number, width > max(const ::VectorizedArray< Number, width > &, const ::VectorizedArray< Number, width > &)Definition vectorization.h:6943\\n EigenvalueProblem::solve\\nThis is the key new functionality of the program. Now that the system is set up, here is a good time to actually solve the problem: As with other examples this is done using a \\\"solve\\\" routine. Essentially, it works as in other programs: you set up a SolverControl object that describes the accuracy to which we want to solve the linear systems, and then we select the kind of solver we want. Here we choose the Krylov-Schur solver of SLEPc, a pretty fast and robust choice for this kind of problem:\\n\\u00a0   template <int dim>\\n\\u00a0   unsigned int EigenvalueProblem<dim>::solve()\\n\\u00a0   {\\nWe start here, as we normally do, by assigning convergence control we want:\\n\\u00a0     SolverControl                    solver_control(dof_handler.n_dofs(), 1e-9);\\n\\u00a0     SLEPcWrappers::SolverKrylovSchur eigensolver(solver_control);\\n\\u00a0 \\nSLEPcWrappers::SolverKrylovSchurDefinition slepc_solver.h:392\\nSolverControlDefinition solver_control.h:67\\nBefore we actually solve for the eigenfunctions and -values, we have to also select which set of eigenvalues to solve for. Lets select those eigenvalues and corresponding eigenfunctions with the smallest real part (in fact, the problem we solve here is symmetric and so the eigenvalues are purely real). After that, we can actually let SLEPc do its work:\\n\\u00a0     eigensolver.set_which_eigenpairs(EPS_SMALLEST_REAL);\\n\\u00a0 \\n\\u00a0     eigensolver.set_problem_type(EPS_GHEP);\\n\\u00a0 \\n\\u00a0     eigensolver.solve(stiffness_matrix,\\n\\u00a0                       mass_matrix,\\n\\u00a0                       eigenvalues,\\n\\u00a0                       eigenfunctions,\\n\\u00a0                       eigenfunctions.size());\\n\\u00a0 \\nThe output of the call above is a set of vectors and values. In eigenvalue problems, the eigenfunctions are only determined up to a constant that can be fixed pretty arbitrarily. Knowing nothing about the origin of the eigenvalue problem, SLEPc has no other choice than to normalize the eigenvectors to one in the \\\\(l_2\\\\) (vector) norm. Unfortunately this norm has little to do with any norm we may be interested from a eigenfunction perspective: the \\\\(L_2(\\\\Omega)\\\\) norm, or maybe the \\\\(L_\\\\infty(\\\\Omega)\\\\) norm.\\nLet us choose the latter and rescale eigenfunctions so that they have \\\\(\\\\|\\\\phi_i(\\\\mathbf x)\\\\|_{L^\\\\infty(\\\\Omega)}=1\\\\) instead of \\\\(\\\\|\\\\Phi\\\\|_{l_2}=1\\\\) (where \\\\(\\\\phi_i\\\\) is the \\\\(i\\\\)th eigenfunction and \\\\(\\\\Phi_i\\\\) the corresponding vector of nodal values). For the \\\\(Q_1\\\\) elements chosen here, we know that the maximum of the function \\\\(\\\\phi_i(\\\\mathbf x)\\\\) is attained at one of the nodes, so  \\\\(\\\\max_{\\\\mathbf\\n   x}\\\\phi_i(\\\\mathbf x)=\\\\max_j (\\\\Phi_i)_j\\\\), making the normalization in the \\\\(L_\\\\infty\\\\) norm trivial. Note that this doesn't work as easily if we had chosen \\\\(Q_k\\\\) elements with \\\\(k>1\\\\): there, the maximum of a function does not necessarily have to be attained at a node, and so \\\\(\\\\max_{\\\\mathbf x}\\\\phi_i(\\\\mathbf x)\\\\ge\\\\max_j (\\\\Phi_i)_j\\\\) (although the equality is usually nearly true).\\n\\u00a0     for (auto &eigenfunction : eigenfunctions)\\n\\u00a0       eigenfunction /= eigenfunction.linfty_norm();\\n\\u00a0 \\nlinfty_normNumber linfty_norm(const Tensor< 2, dim, Number > &t)Definition tensor.h:3065\\nFinally return the number of iterations it took to converge:\\n\\u00a0     return solver_control.last_step();\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n EigenvalueProblem::output_results\\nThis is the last significant function of this program. It uses the DataOut class to generate graphical output from the eigenfunctions for later visualization. It works as in many of the other tutorial programs.\\nThe whole collection of functions is then output as a single VTK file.\\n\\u00a0   template <int dim>\\n\\u00a0   void EigenvalueProblem<dim>::output_results() const\\n\\u00a0   {\\n\\u00a0     DataOut<dim> data_out;\\n\\u00a0 \\n\\u00a0     data_out.attach_dof_handler(dof_handler);\\n\\u00a0 \\n\\u00a0     for (unsigned int i = 0; i < eigenfunctions.size(); ++i)\\n\\u00a0       data_out.add_data_vector(eigenfunctions[i],\\n\\u00a0                                std::string(\\\"eigenfunction_\\\") +\\n\\u00a0                                  Utilities::int_to_string(i));\\n\\u00a0 \\nDataOut_DoFData::attach_dof_handlervoid attach_dof_handler(const DoFHandler< dim, spacedim > &)\\nDataOutDefinition data_out.h:147\\nUtilities::int_to_stringstd::string int_to_string(const unsigned int value, const unsigned int digits=numbers::invalid_unsigned_int)Definition utilities.cc:470\\nThe only thing worth discussing may be that because the potential is specified as a function expression in the input file, it would be nice to also have it as a graphical representation along with the eigenfunctions. The process to achieve this is relatively straightforward: we build an object that represents \\\\(V(\\\\mathbf x)\\\\) and then we interpolate this continuous function onto the finite element space. The result we also attach to the DataOut object for visualization.\\n\\u00a0     Vector<double> projected_potential(dof_handler.n_dofs());\\n\\u00a0     {\\n\\u00a0       FunctionParser<dim> potential;\\n\\u00a0       potential.initialize(FunctionParser<dim>::default_variable_names(),\\n\\u00a0                            parameters.get(\\\"Potential\\\"),\\n\\u00a0                            typename FunctionParser<dim>::ConstMap());\\n\\u00a0       VectorTools::interpolate(dof_handler, potential, projected_potential);\\n\\u00a0     }\\n\\u00a0     data_out.add_data_vector(projected_potential, \\\"interpolated_potential\\\");\\n\\u00a0 \\n\\u00a0     data_out.build_patches();\\n\\u00a0 \\n\\u00a0     std::ofstream output(\\\"eigenvectors.vtk\\\");\\n\\u00a0     data_out.write_vtk(output);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\nVectorDefinition vector.h:120\\nVectorTools::interpolatevoid interpolate(const Mapping< dim, spacedim > &mapping, const DoFHandler< dim, spacedim > &dof, const Function< spacedim, typename VectorType::value_type > &function, VectorType &vec, const ComponentMask &component_mask={})\\n EigenvalueProblem::run\\nThis is the function which has the top-level control over everything. It is almost exactly the same as in step-4:\\n\\u00a0   template <int dim>\\n\\u00a0   void EigenvalueProblem<dim>::run()\\n\\u00a0   {\\n\\u00a0     make_grid_and_dofs();\\n\\u00a0 \\n\\u00a0     std::cout << \\\"   Number of active cells:       \\\"\\n\\u00a0               << triangulation.n_active_cells() << std::endl\\n\\u00a0               << \\\"   Number of degrees of freedom: \\\" << dof_handler.n_dofs()\\n\\u00a0               << std::endl;\\n\\u00a0 \\n\\u00a0     assemble_system();\\n\\u00a0 \\n\\u00a0     const unsigned int n_iterations = solve();\\n\\u00a0     std::cout << \\\"   Solver converged in \\\" << n_iterations << \\\" iterations.\\\"\\n\\u00a0               << std::endl;\\n\\u00a0 \\n\\u00a0     output_results();\\n\\u00a0 \\n\\u00a0     std::cout << std::endl;\\n\\u00a0     for (unsigned int i = 0; i < eigenvalues.size(); ++i)\\n\\u00a0       std::cout << \\\"      Eigenvalue \\\" << i << \\\" : \\\" << eigenvalues[i]\\n\\u00a0                 << std::endl;\\n\\u00a0   }\\n\\u00a0 } // namespace Step36\\n\\u00a0 \\nTriangulation::n_active_cellsunsigned int n_active_cells() const\\n The main function\\n\\u00a0 int main(int argc, char **argv)\\n\\u00a0 {\\n\\u00a0   try\\n\\u00a0     {\\n\\u00a0       using namespace dealii;\\n\\u00a0       using namespace Step36;\\n\\u00a0 \\n\\u00a0       Utilities::MPI::MPI_InitFinalize mpi_initialization(argc, argv, 1);\\n\\u00a0 \\n\\u00a0 \\nUtilities::MPI::MPI_InitFinalizeDefinition mpi.h:1081\\nThis program can only be run in serial. Otherwise, throw an exception.\\n\\u00a0       AssertThrow(Utilities::MPI::n_mpi_processes(MPI_COMM_WORLD) == 1,\\n\\u00a0                   ExcMessage(\\n\\u00a0                     \\\"This program can only be run in serial, use ./step-36\\\"));\\n\\u00a0 \\n\\u00a0       EigenvalueProblem<2> problem(\\\"step-36.prm\\\");\\n\\u00a0       problem.run();\\n\\u00a0     }\\n\\u00a0 \\nAssertThrow#define AssertThrow(cond, exc)Definition exceptions.h:1739\\nUtilities::MPI::n_mpi_processesunsigned int n_mpi_processes(const MPI_Comm mpi_communicator)Definition mpi.cc:92\\nAll the while, we are watching out if any exceptions should have been generated. If that is so, we panic...\\n\\u00a0   catch (std::exception &exc)\\n\\u00a0     {\\n\\u00a0       std::cerr << std::endl\\n\\u00a0                 << std::endl\\n\\u00a0                 << \\\"----------------------------------------------------\\\"\\n\\u00a0                 << std::endl;\\n\\u00a0       std::cerr << \\\"Exception on processing: \\\" << std::endl\\n\\u00a0                 << exc.what() << std::endl\\n\\u00a0                 << \\\"Aborting!\\\" << std::endl\\n\\u00a0                 << \\\"----------------------------------------------------\\\"\\n\\u00a0                 << std::endl;\\n\\u00a0 \\n\\u00a0       return 1;\\n\\u00a0     }\\n\\u00a0   catch (...)\\n\\u00a0     {\\n\\u00a0       std::cerr << std::endl\\n\\u00a0                 << std::endl\\n\\u00a0                 << \\\"----------------------------------------------------\\\"\\n\\u00a0                 << std::endl;\\n\\u00a0       std::cerr << \\\"Unknown exception!\\\" << std::endl\\n\\u00a0                 << \\\"Aborting!\\\" << std::endl\\n\\u00a0                 << \\\"----------------------------------------------------\\\"\\n\\u00a0                 << std::endl;\\n\\u00a0       return 1;\\n\\u00a0     }\\n\\u00a0 \\nIf no exceptions are thrown, then we tell the program to stop monkeying around and exit nicely:\\n\\u00a0   std::cout << std::endl << \\\"   Job done.\\\" << std::endl;\\n\\u00a0 \\n\\u00a0   return 0;\\n\\u00a0 }\\n Results\\nRunning the problem\\nThe problem's input is parameterized by an input file step-36.prm which could, for example, contain the following text:\\nset Global mesh refinement steps         = 5\\nset Number of eigenvalues/eigenfunctions = 5\\nset Potential                            = 0\\nHere, the potential is zero inside the domain, and we know that the eigenvalues are given by \\\\(\\\\lambda_{(mn)}=\\\\frac{\\\\pi^2}{4}(m^2+n^2)\\\\) where \\\\(m,n\\\\in{\\\\mathbb N^+}\\\\). Eigenfunctions are sines and cosines with \\\\(m\\\\) and \\\\(n\\\\) periods in \\\\(x\\\\) and \\\\(y\\\\) directions. This matches the output our program generates: examples/step-36> make run\\n============================ Running step-36\\n   Number of active cells:       1024\\n   Number of degrees of freedom: 1089\\n   Solver converged in 67 iterations.\\n \\n      Eigenvalue 0 : 4.93877\\n      Eigenvalue 1 : 12.3707\\n      Eigenvalue 2 : 12.3707\\n      Eigenvalue 3 : 19.8027\\n      Eigenvalue 4 : 24.837\\n \\n   Job done.  \\n These eigenvalues are exactly the ones that correspond to pairs \\\\((m,n)=(1,1)\\\\), \\\\((1,2)\\\\) and \\\\((2,1)\\\\), \\\\((2,2)\\\\), and \\\\((3,1)\\\\). A visualization of the corresponding eigenfunctions would look like this:\\n\\n\\n   \\n\\n  \\n\\nPossibilities for extensions\\nIt is always worth playing a few games in the playground! So here goes with a few suggestions:\\n\\n\\nThe potential used above (called the infinite well because it is a flat potential surrounded by infinitely high walls) is interesting because it allows for analytically known solutions. Apart from that, it is rather boring, however. That said, it is trivial to play around with the potential by just setting it to something different in the input file. For example, let us assume that we wanted to work with the following potential in 2d:            \\n\\\\[\\n  V(x,y) = \\\\left\\\\{\\n       \\\\begin{array}{ll}\\n         -100 & \\\\text{if}\\\\ \\\\sqrt{x^2+y^2}<\\\\frac 34 \\\\ \\\\text{and}\\n                         \\\\ xy>0\\n         \\\\\\\\\\n         -5 & \\\\text{if}\\\\ \\\\sqrt{x^2+y^2}<\\\\frac 34 \\\\ \\\\text{and}\\n                         \\\\ xy\\\\le 0\\n         \\\\\\\\\\n         0 & \\\\text{otherwise}\\n      \\\\end{array} \\\\right.\\\\quad.\\n\\\\]\\n\\n In other words, the potential is -100 in two sectors of a circle of radius 0.75, -5 in the other two sectors, and zero outside the circle. We can achieve this by using the following in the input file : set Potential = if (x^2 + y^2 < 0.75^2, if (x*y > 0, -100, -5), 0)\\n If in addition we also increase the mesh refinement by one level, we get the following results: examples/step-36> make run\\n============================ Running step-36\\n   Number of active cells:       4096\\n   Number of degrees of freedom: 4225\\n \\n   Eigenvalue 0 : -74.2562\\n   Eigenvalue 1 : -72.7322\\n   Eigenvalue 2 : -42.7406\\n   Eigenvalue 3 : -42.2232\\n   Eigenvalue 4 : -37.0744\\nThe output file also contains an interpolated version of the potential, which looks like this (note that as expected the lowest few eigenmodes have probability densities \\\\(|\\\\Psi(\\\\mathbf x)|^2\\\\) that are significant only where the potential is the lowest, i.e. in the top right and bottom left sector of inner circle of the potential):\\n\\nThe first five eigenfunctions are now like this:\\n\\n\\n   \\n\\n  \\n\\n\\n\\n\\nIn our derivation of the problem we have assumed that the particle is confined to a domain \\\\(\\\\Omega\\\\) and that at the boundary of this domain its probability \\\\(|\\\\Psi|^2\\\\) of being is zero. This is equivalent to solving the eigenvalue problem on all of \\\\({\\\\mathbb R}^d\\\\) and assuming that the energy potential is finite only inside a region \\\\(\\\\Omega\\\\) and infinite outside. It is relatively easy to show that \\\\(|\\\\Psi(\\\\mathbf x)|^2\\\\) at all locations \\\\(\\\\mathbf x\\\\) where  \\\\(V(\\\\mathbf\\nx)=\\\\infty\\\\). So the question is what happens if our potential is not of this form, i.e. there is no bounded domain outside of which the potential is infinite? In that case, it may be worth to just consider a very large domain at the boundary of which \\\\(V(\\\\mathbf x)\\\\) is at least very large, if not infinite. Play around with a few cases like this and explore how the spectrum and eigenfunctions change as we make the computational region larger and larger.\\n\\n\\n\\nWhat happens if we investigate the simple harmonic oscillator problem \\\\(V(\\\\mathbf x)=c|\\\\mathbf x|^2\\\\)? This potential is exactly of the form discussed in the previous paragraph and has hyper spherical symmetry. One may want to use a large spherical domain with a large outer radius, to approximate the whole-space problem (say, by invoking GridGenerator::hyper_ball).\\n\\n\\n\\nThe plots above show the wave function \\\\(\\\\Psi(\\\\mathbf x)\\\\), but the physical quantity of interest is actually the probability density \\\\(|\\\\Psi(\\\\mathbf x)|^2\\\\) for the particle to be at location \\\\(\\\\mathbf x\\\\). Some visualization programs can compute derived quantities from the data in an input file, but we can also do so right away when creating the output file. The facility to do that is the DataPostprocessor class that can be used in conjunction with the DataOut class. Examples of how this can be done can be found in step-29 and step-33.\\n\\n\\n\\nWhat happens if the particle in the box has internal degrees of freedom? For example, if the particle were a spin- \\\\(1/2\\\\) particle? In that case, we may want to start solving a vector-valued problem instead.\\n\\n\\n\\nOur implementation of the deal.II library here uses the PETScWrappers and SLEPcWrappers and is suitable for running on serial machine architecture. However, for larger grids and with a larger number of degrees-of-freedom, we may want to run our application on parallel architectures. A parallel implementation of the above code can be particularly useful here since the generalized eigenspectrum problem is somewhat more expensive to solve than the standard problems considered in most of the earlier tutorials. Fortunately, modifying the above program to be MPI compliant is a relatively straightforward procedure. A sketch of how this can be done can be found in step-17.\\n\\n\\n\\nFinally, there are alternatives to using the SLEPc eigenvalue solvers. deal.II has interfaces to one of them, ARPACK (see the ARPACK configuration page for setup instructions), implemented in the ArpackSolver class. Here is a short and quick overview of what one would need to change to use it, provided you have a working installation of ARPACK and deal.II has been configured properly for it (see the deal.II README file):\\nFirst, in order to use the ARPACK interfaces, we can go back to using standard deal.II matrices and vectors, so we start by replacing the PETSc and SLEPc headers #include <deal.II/lac/petsc_sparse_matrix.h>\\n#include <deal.II/lac/petsc_vector.h>\\n#include <deal.II/lac/slepc_solver.h>\\npetsc_sparse_matrix.h\\npetsc_vector.h\\nslepc_solver.h\\n with these: #include <deal.II/lac/arpack_solver.h>\\n#include <deal.II/lac/sparse_direct.h>\\n#include <deal.II/lac/sparse_matrix.h>\\n#include <deal.II/lac/compressed_sparsity_pattern.h>\\narpack_solver.h\\nsparse_direct.h\\nsparse_matrix.h\\n ARPACK allows complex eigenvalues, so we will also need #include <complex>\\nSecondly, we switch back to the deal.II matrix and vector definitions in the main class: SparsityPattern                     sparsity_pattern;\\nSparseMatrix<double>                stiffness_matrix, mass_matrix;\\nstd::vector<Vector<double> >        eigenfunctions;\\nstd::vector<std::complex<double>>   eigenvalues;\\nSparseMatrixDefinition sparse_matrix.h:520\\nSparsityPatternDefinition sparsity_pattern.h:343\\n and initialize them as usual in make_grid_and_dofs(): sparsity_pattern.reinit (dof_handler.n_dofs(),\\n                         dof_handler.n_dofs(),\\n                         dof_handler.max_couplings_between_dofs());\\n \\nDoFTools::make_sparsity_pattern (dof_handler, sparsity_pattern);\\nconstraints.condense (sparsity_pattern);\\nsparsity_pattern.compress();\\n \\nstiffness_matrix.reinit (sparsity_pattern);\\nmass_matrix.reinit (sparsity_pattern);\\nSparseMatrix::reinitvirtual void reinit(const SparsityPattern &sparsity)\\nSparsityPattern::reinitvoid reinit(const size_type m, const size_type n, const ArrayView< const unsigned int > &row_lengths)Definition sparsity_pattern.cc:202\\nSparsityPattern::compressvoid compress()Definition sparsity_pattern.cc:331\\nFor solving the eigenvalue problem with ARPACK, we finally need to modify solve(): template <int dim>\\nunsigned int EigenvalueProblem<dim>::solve ()\\n{\\n SolverControl solver_control (dof_handler.n_dofs(), 1e-9);\\n \\n SparseDirectUMFPACK inverse;\\n  inverse.initialize (stiffness_matrix);\\n \\n const unsigned int num_arnoldi_vectors = 2*eigenvalues.size() + 2;\\n ArpackSolver::AdditionalData additional_data(num_arnoldi_vectors);\\n \\n ArpackSolver eigensolver (solver_control, additional_data);\\n  eigensolver.solve (stiffness_matrix,\\n                     mass_matrix,\\n                     inverse,\\n eigenvalues,\\n                     eigenfunctions,\\n eigenvalues.size());\\n \\n for (unsigned int i=0; i<eigenfunctions.size(); ++i)\\n    eigenfunctions[i] /= eigenfunctions[i].linfty_norm ();\\n \\n return solver_control.last_step ();\\n}\\nArpackSolverDefinition arpack_solver.h:167\\nSparseDirectUMFPACKDefinition sparse_direct.h:92\\nSparseDirectUMFPACK::initializevoid initialize(const SparsityPattern &sparsity_pattern)Definition sparse_direct.cc:67\\nArpackSolver::AdditionalDataDefinition arpack_solver.h:226\\n Note how we have used an exact decomposition (using SparseDirectUMFPACK) as a preconditioner to ARPACK. \\n\\n\\n The plain program\\n/* ------------------------------------------------------------------------\\n *\\n * SPDX-License-Identifier: LGPL-2.1-or-later\\n * Copyright (C) 2009 - 2024 by the deal.II authors\\n *\\n * This file is part of the deal.II library.\\n *\\n * Part of the source code is dual licensed under Apache-2.0 WITH\\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\\n * governing the source code and code contributions can be found in\\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\\n *\\n * ------------------------------------------------------------------------\\n *\\n * Authors: Toby D. Young, Polish Academy of Sciences,\\n *          Wolfgang Bangerth, Texas A&M University\\n */\\n \\n \\n#include <deal.II/base/quadrature_lib.h>\\n#include <deal.II/base/function.h>\\n#include <deal.II/base/function_parser.h>\\n#include <deal.II/base/parameter_handler.h>\\n#include <deal.II/base/utilities.h>\\n#include <deal.II/grid/tria.h>\\n#include <deal.II/grid/grid_generator.h>\\n#include <deal.II/dofs/dof_handler.h>\\n#include <deal.II/dofs/dof_tools.h>\\n#include <deal.II/fe/fe_q.h>\\n#include <deal.II/fe/fe_values.h>\\n#include <deal.II/numerics/vector_tools.h>\\n#include <deal.II/numerics/data_out.h>\\n#include <deal.II/lac/affine_constraints.h>\\n#include <deal.II/lac/full_matrix.h>\\n \\n#include <deal.II/base/index_set.h>\\n \\n#include <deal.II/lac/petsc_sparse_matrix.h>\\n#include <deal.II/lac/petsc_vector.h>\\n \\n#include <deal.II/lac/slepc_solver.h>\\n \\n#include <fstream>\\n#include <iostream>\\n \\nnamespace Step36\\n{\\n using namespace dealii;\\n \\n \\n template <int dim>\\n class EigenvalueProblem\\n  {\\n public:\\n    EigenvalueProblem(const std::string &prm_file);\\n void run();\\n \\n private:\\n void         make_grid_and_dofs();\\n void         assemble_system();\\n unsigned int solve();\\n void         output_results() const;\\n \\n Triangulation<dim> triangulation;\\n const FE_Q<dim>    fe;\\n DoFHandler<dim>    dof_handler;\\n \\n PETScWrappers::SparseMatrix             stiffness_matrix, mass_matrix;\\n    std::vector<PETScWrappers::MPI::Vector> eigenfunctions;\\n    std::vector<double>                     eigenvalues;\\n \\n ParameterHandler parameters;\\n \\n AffineConstraints<double> constraints;\\n  };\\n \\n \\n \\n template <int dim>\\n  EigenvalueProblem<dim>::EigenvalueProblem(const std::string &prm_file)\\n    : fe(1)\\n    , dof_handler(triangulation)\\n  {\\n    parameters.declare_entry(\\n \\\"Global mesh refinement steps\\\",\\n \\\"5\\\",\\n Patterns::Integer(0, 20),\\n \\\"The number of times the 1-cell coarse mesh should \\\"\\n \\\"be refined globally for our computations.\\\");\\n    parameters.declare_entry(\\\"Number of eigenvalues/eigenfunctions\\\",\\n \\\"5\\\",\\n Patterns::Integer(0, 100),\\n \\\"The number of eigenvalues/eigenfunctions \\\"\\n \\\"to be computed.\\\");\\n    parameters.declare_entry(\\\"Potential\\\",\\n \\\"0\\\",\\n Patterns::Anything(),\\n \\\"A functional description of the potential.\\\");\\n \\n    parameters.parse_input(prm_file);\\n  }\\n \\n \\n \\n template <int dim>\\n void EigenvalueProblem<dim>::make_grid_and_dofs()\\n  {\\n GridGenerator::hyper_cube(triangulation, -1, 1);\\n triangulation.refine_global(\\n      parameters.get_integer(\\\"Global mesh refinement steps\\\"));\\n    dof_handler.distribute_dofs(fe);\\n \\n DoFTools::make_zero_boundary_constraints(dof_handler, constraints);\\n    constraints.close();\\n \\n    stiffness_matrix.reinit(dof_handler.n_dofs(),\\n                            dof_handler.n_dofs(),\\n                            dof_handler.max_couplings_between_dofs());\\n mass_matrix.reinit(dof_handler.n_dofs(),\\n                       dof_handler.n_dofs(),\\n                       dof_handler.max_couplings_between_dofs());\\n \\n IndexSet eigenfunction_index_set = dof_handler.locally_owned_dofs();\\n    eigenfunctions.resize(\\n      parameters.get_integer(\\\"Number of eigenvalues/eigenfunctions\\\"));\\n for (auto &eigenfunction : eigenfunctions)\\n      eigenfunction.reinit(eigenfunction_index_set, MPI_COMM_WORLD);\\n \\n eigenvalues.resize(eigenfunctions.size());\\n  }\\n \\n \\n \\n template <int dim>\\n void EigenvalueProblem<dim>::assemble_system()\\n  {\\n const QGauss<dim> quadrature_formula(fe.degree + 1);\\n \\n FEValues<dim> fe_values(fe,\\n                            quadrature_formula,\\n update_values | update_gradients |\\n update_quadrature_points | update_JxW_values);\\n \\n const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\\n const unsigned int n_q_points    = quadrature_formula.size();\\n \\n FullMatrix<double> cell_stiffness_matrix(dofs_per_cell, dofs_per_cell);\\n FullMatrix<double> cell_mass_matrix(dofs_per_cell, dofs_per_cell);\\n \\n    std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\\n \\n FunctionParser<dim> potential;\\n    potential.initialize(FunctionParser<dim>::default_variable_names(),\\n                         parameters.get(\\\"Potential\\\"),\\n typename FunctionParser<dim>::ConstMap());\\n \\n    std::vector<double> potential_values(n_q_points);\\n for (const auto &cell : dof_handler.active_cell_iterators())\\n      {\\n        fe_values.reinit(cell);\\n        cell_stiffness_matrix = 0;\\n        cell_mass_matrix      = 0;\\n \\n        potential.value_list(fe_values.get_quadrature_points(),\\n                             potential_values);\\n \\n for (unsigned int q_point = 0; q_point < n_q_points; ++q_point)\\n for (unsigned int i = 0; i < dofs_per_cell; ++i)\\n for (unsigned int j = 0; j < dofs_per_cell; ++j)\\n              {\\n                cell_stiffness_matrix(i, j) +=           \\n                  (fe_values.shape_grad(i, q_point) *    \\n                     fe_values.shape_grad(j, q_point)    \\n                   +                                     \\n                   potential_values[q_point] *           \\n                     fe_values.shape_value(i, q_point) * \\n                     fe_values.shape_value(j, q_point)   \\n                   ) *                                   \\n                  fe_values.JxW(q_point);                \\n \\n                cell_mass_matrix(i, j) +=              \\n                  (fe_values.shape_value(i, q_point) * \\n                   fe_values.shape_value(j, q_point)   \\n                   ) *                                 \\n                  fe_values.JxW(q_point);              \\n              }\\n \\n        cell->get_dof_indices(local_dof_indices);\\n \\n        constraints.distribute_local_to_global(cell_stiffness_matrix,\\n                                               local_dof_indices,\\n                                               stiffness_matrix);\\n        constraints.distribute_local_to_global(cell_mass_matrix,\\n                                               local_dof_indices,\\n                                               mass_matrix);\\n      }\\n \\n    stiffness_matrix.compress(VectorOperation::add);\\n mass_matrix.compress(VectorOperation::add);\\n \\n \\n double min_spurious_eigenvalue = std::numeric_limits<double>::max(),\\n           max_spurious_eigenvalue = -std::numeric_limits<double>::max();\\n \\n for (unsigned int i = 0; i < dof_handler.n_dofs(); ++i)\\n if (constraints.is_constrained(i))\\n        {\\n const double ev         = stiffness_matrix(i, i) / mass_matrix(i, i);\\n          min_spurious_eigenvalue = std::min(min_spurious_eigenvalue, ev);\\n          max_spurious_eigenvalue = std::max(max_spurious_eigenvalue, ev);\\n        }\\n \\n    std::cout << \\\"   Spurious eigenvalues are all in the interval \\\" << '['\\n              << min_spurious_eigenvalue << ',' << max_spurious_eigenvalue\\n              << ']' << std::endl;\\n  }\\n \\n \\n \\n template <int dim>\\n unsigned int EigenvalueProblem<dim>::solve()\\n  {\\n SolverControl                    solver_control(dof_handler.n_dofs(), 1e-9);\\n SLEPcWrappers::SolverKrylovSchur eigensolver(solver_control);\\n \\n    eigensolver.set_which_eigenpairs(EPS_SMALLEST_REAL);\\n \\n    eigensolver.set_problem_type(EPS_GHEP);\\n \\n    eigensolver.solve(stiffness_matrix,\\n                      mass_matrix,\\n eigenvalues,\\n                      eigenfunctions,\\n                      eigenfunctions.size());\\n \\n for (auto &eigenfunction : eigenfunctions)\\n      eigenfunction /= eigenfunction.linfty_norm();\\n \\n return solver_control.last_step();\\n  }\\n \\n \\n \\n template <int dim>\\n void EigenvalueProblem<dim>::output_results() const\\n {\\n DataOut<dim> data_out;\\n \\n    data_out.attach_dof_handler(dof_handler);\\n \\n for (unsigned int i = 0; i < eigenfunctions.size(); ++i)\\n      data_out.add_data_vector(eigenfunctions[i],\\n                               std::string(\\\"eigenfunction_\\\") +\\n Utilities::int_to_string(i));\\n \\n Vector<double> projected_potential(dof_handler.n_dofs());\\n    {\\n FunctionParser<dim> potential;\\n      potential.initialize(FunctionParser<dim>::default_variable_names(),\\n                           parameters.get(\\\"Potential\\\"),\\n typename FunctionParser<dim>::ConstMap());\\n VectorTools::interpolate(dof_handler, potential, projected_potential);\\n    }\\n    data_out.add_data_vector(projected_potential, \\\"interpolated_potential\\\");\\n \\n    data_out.build_patches();\\n \\n    std::ofstream output(\\\"eigenvectors.vtk\\\");\\n    data_out.write_vtk(output);\\n  }\\n \\n \\n \\n template <int dim>\\n void EigenvalueProblem<dim>::run()\\n  {\\n    make_grid_and_dofs();\\n \\n    std::cout << \\\"   Number of active cells:       \\\"\\n              << triangulation.n_active_cells() << std::endl\\n              << \\\"   Number of degrees of freedom: \\\" << dof_handler.n_dofs()\\n              << std::endl;\\n \\n    assemble_system();\\n \\n const unsigned int n_iterations = solve();\\n    std::cout << \\\"   Solver converged in \\\" << n_iterations << \\\" iterations.\\\"\\n              << std::endl;\\n \\n    output_results();\\n \\n    std::cout << std::endl;\\n for (unsigned int i = 0; i < eigenvalues.size(); ++i)\\n      std::cout << \\\"      Eigenvalue \\\" << i << \\\" : \\\" << eigenvalues[i]\\n                << std::endl;\\n  }\\n} // namespace Step36\\n \\nint main(int argc, char **argv)\\n{\\n try\\n    {\\n using namespace dealii;\\n using namespace Step36;\\n \\n Utilities::MPI::MPI_InitFinalize mpi_initialization(argc, argv, 1);\\n \\n \\n AssertThrow(Utilities::MPI::n_mpi_processes(MPI_COMM_WORLD) == 1,\\n                  ExcMessage(\\n \\\"This program can only be run in serial, use ./step-36\\\"));\\n \\n      EigenvalueProblem<2> problem(\\\"step-36.prm\\\");\\n      problem.run();\\n    }\\n \\n catch (std::exception &exc)\\n    {\\n      std::cerr << std::endl\\n                << std::endl\\n                << \\\"----------------------------------------------------\\\"\\n                << std::endl;\\n      std::cerr << \\\"Exception on processing: \\\" << std::endl\\n                << exc.what() << std::endl\\n                << \\\"Aborting!\\\" << std::endl\\n                << \\\"----------------------------------------------------\\\"\\n                << std::endl;\\n \\n return 1;\\n    }\\n catch (...)\\n    {\\n      std::cerr << std::endl\\n                << std::endl\\n                << \\\"----------------------------------------------------\\\"\\n                << std::endl;\\n      std::cerr << \\\"Unknown exception!\\\" << std::endl\\n                << \\\"Aborting!\\\" << std::endl\\n                << \\\"----------------------------------------------------\\\"\\n                << std::endl;\\n return 1;\\n    }\\n \\n  std::cout << std::endl << \\\"   Job done.\\\" << std::endl;\\n \\n return 0;\\n}\\naffine_constraints.h\\nDataOutInterface::write_vtkvoid write_vtk(std::ostream &out) constDefinition data_out_base.cc:7681\\nDataOut_DoFData::add_data_vectorvoid add_data_vector(const VectorType &data, const std::vector< std::string > &names, const DataVectorType type=type_automatic, const std::vector< DataComponentInterpretation::DataComponentInterpretation > &data_component_interpretation={})Definition data_out_dof_data.h:1069\\nDataOut::build_patchesvirtual void build_patches(const unsigned int n_subdivisions=0)Definition data_out.cc:1062\\nFunction::value_listvirtual void value_list(const std::vector< Point< dim > > &points, std::vector< RangeNumberType > &values, const unsigned int component=0) const\\ndof_handler.h\\ndof_tools.h\\nfe_values.h\\nfe_q.h\\nfull_matrix.h\\nfunction.h\\nfunction_parser.h\\ntria.h\\ngrid_generator.h\\nutilities.h\\nindex_set.h\\nLocalIntegrators::L2::mass_matrixvoid mass_matrix(FullMatrix< double > &M, const FEValuesBase< dim > &fe, const double factor=1.)Definition l2.h:57\\ninternal::reinitvoid reinit(MatrixBlock< MatrixType > &v, const BlockSparsityPattern &p)Definition matrix_block.h:617\\ndata_out.h\\nparameter_handler.h\\nquadrature_lib.h\\nvector_tools.h\\n \\n\\n\\n\\n\\nGenerated by\\u00a0 1.11.0\\n\\n\\n\\n\\n\", \"type\": \"Document\"}}]"