"[{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"document\", \"Document\"], \"kwargs\": {\"metadata\": {\"source\": \"https://dealii.org/current/doxygen/deal.II/step_53.html\", \"content_type\": \"text/html\", \"title\": \"The deal.II Library: The step-53 tutorial program\", \"language\": \"en-US\"}, \"page_content\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\nThe deal.II Library: The step-53 tutorial program\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\u00a0Reference documentation for deal.II version 9.6.0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\\(\\\\newcommand{\\\\dealvcentcolon}{\\\\mathrel{\\\\mathop{:}}}\\\\)\\n\\\\(\\\\newcommand{\\\\dealcoloneq}{\\\\dealvcentcolon\\\\mathrel{\\\\mkern-1.2mu}=}\\\\)\\n\\\\(\\\\newcommand{\\\\jump}[1]{\\\\left[\\\\!\\\\left[ #1 \\\\right]\\\\!\\\\right]}\\\\)\\n\\\\(\\\\newcommand{\\\\average}[1]{\\\\left\\\\{\\\\!\\\\left\\\\{ #1 \\\\right\\\\}\\\\!\\\\right\\\\}}\\\\)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLoading...\\nSearching...\\nNo Matches\\n\\n\\n\\n\\n\\n\\n\\nThe step-53 tutorial program\\n\\n\\nThis tutorial depends on step-49.\\n\\n\\nTable of contents\\n\\n\\n Introduction\\n\\nWhere geometry and meshes intersect\\nThe example case\\nImplementation\\n\\n The commented program\\n\\nDescribing topography: AfricaTopography\\nDescribing the geometry: AfricaGeometry\\nCreating the mesh\\nThe main function\\n\\n\\n Results\\n\\nIssues with adaptively refined meshes generated this way\\n\\n The plain program\\n   \\n\\n\\nThis program was contributed by Wolfgang Bangerth and Luca Heltai, using data provided by D. Sarah Stamps.\\nNoteThis program elaborates on concepts of geometry and the classes that implement it. These classes are grouped into the documentation topic on Manifold description for triangulations. See there for additional information.\\n\\nThis tutorial is also available as a Jupyter Python notebook that uses the deal.II python interface. The notebook is available in the same directory as the original C++ program. Rendered notebook can also be viewed on the github.\\n Introduction\\nPartial differential equations for realistic problems are often posed on domains with complicated geometries. To provide just a few examples, consider these cases:\\nAmong the two arguably most important industrial applications for the finite element method, aerodynamics and more generally fluid dynamics is one. Computer simulations today are used in the design of every airplane, car, train and ship. The domain in which the partial differential equation is posed is, in these cases, the air surrounding the plane with its wings, flaps and engines; the air surrounding the car with its wheel, wheel wells, mirrors and, in the case of race cars, all sorts of aerodynamic equipment; the air surrounding the train with its wheels and gaps between cars. In the case of ships, the domain is the water surrounding the ship with its rudders and propellers.\\nThe other of the two big applications of the finite element method is structural engineering in which the domains are bridges, airplane nacelles and wings, and other solid bodies of often complicated shapes.\\nFinite element modeling is also often used to describe the generation and propagation of earthquake waves. In these cases, one needs to accurately represent the geometry of faults in the Earth crust. Since faults intersect, dip at angles, and are often not completely straight, domains are frequently very complex. One could cite many more examples of complicated geometries in which one wants to pose and solve a partial differential equation. What this shows is that the \\\"real\\\" world is much more complicated than what we have shown in almost all of the tutorial programs preceding this one.\\n\\nThis program is therefore devoted to showing how one deals with complex geometries using a concrete application. In particular, what it shows is how we make a mesh fit the domain we want to solve on. On the other hand, what the program does not show is how to create a coarse mesh for a domain. The process to arrive at a coarse mesh is called \\\"mesh generation\\\" and there are a number of high-quality programs that do this much better than we could ever implement. However, deal.II does have the ability to read in meshes in many formats generated by mesh generators and then make them fit a given shape, either by deforming a mesh or refining it a number of times until it fits. The deal.II Frequently Asked Questions page referenced from http://www.dealii.org/ provides resources to mesh generators.\\nWhere geometry and meshes intersect\\nLet us assume that you have a complex domain and that you already have a coarse mesh that somehow represents the general features of the domain. Then there are two situations in which it is necessary to describe to a deal.II program the details of your geometry:\\n\\nMesh refinement: Whenever a cell is refined, it is necessary to introduce new vertices in the Triangulation. In the simplest case, one assumes that the objects that make up the Triangulation are straight line segments, a bi-linear surface or a tri-linear volume. The next vertex is then simply put into the middle of the old ones. However, for curved boundaries or if we want to solve a PDE on a curved, lower-dimensional manifold embedded in a higher-dimensional space, this is insufficient since it will not respect the actual geometry. We will therefore have to tell Triangulation where to put new points.\\nIntegration: When using higher order finite element methods, it is often necessary to compute integrals using curved approximations of the boundary, i.e., describe each edge or face of cells as curves, instead of straight line segments or bilinear patches. The same is, of course, true when integrating boundary terms (e.g., inhomogeneous Neumann boundary conditions). For the purpose of integration, the various Mapping classes then provide the transformation from the reference cell to the actual cell.\\n\\nIn both cases, we need a way to provide information about the geometry of the domain at the level of an individual cell, its faces and edges. This is where the Manifold class comes into play. Manifold is an abstract base class that only defines an interface by which the Triangulation and Mapping classes can query geometric information about the domain. Conceptually, Manifold sees the world in a way not dissimilar to how the mathematical subdiscipline geometry sees it: a domain is essentially just a collection of points that is somehow equipped with the notion of a distance between points so that we can obtain a point \\\"in the middle\\\" of some other points.\\ndeal.II provides a number of classes that implement the interface provided by Manifold for a variety of common geometries. On the other hand, in this program we will consider only a very common and much simpler case, namely the situation where (a part of) the domain we want to solve on can be described by transforming a much simpler domain (we will call this the \\\"reference domain\\\"). In the language of mathematics, this means that the (part of the) domain is a chart. Charts are described by a smooth function that maps from the simpler domain to the chart (the \\\"push-forward\\\" function) and its inverse (the \\\"pull-back\\\" function). If the domain as a whole is not a chart (e.g., the surface of a sphere), then it can often be described as a collection of charts (e.g., the northern hemisphere and the southern hemisphere are each charts) and the domain can then be describe by an atlas.\\nIf a domain can be decomposed into an atlas, all we need to do is provide the pull-back and push-forward functions for each of the charts. In deal.II, this means providing a class derived from ChartManifold, and this is precisely what we will do in this program.\\nThe example case\\nTo illustrate how one describes geometries using charts in deal.II, we will consider a case that originates in an application of the ASPECT mantle convection code, using a data set provided by D. Sarah Stamps. In the concrete application, we were interested in describing flow in the Earth mantle under the East African Rift, a zone where two continental plates drift apart. Not to beat around the bush, the geometry we want to describe looks like this:\\n\\nIn particular, though you cannot see this here, the top surface is not just colored by the elevation but is, in fact, deformed to follow the correct topography. While the actual application is not relevant here, the geometry is. The domain we are interested in is a part of the Earth that ranges from the surface to a depth of 500km, from 26 to 35 degrees East of the Greenwich meridian, and from 5 degrees North of the equator to 10 degrees South.\\nThis description of the geometry suggests to start with a box \\\\(\\\\hat U=[26,35]\\\\times[-10,5]\\\\times[-500000,0]\\\\) (measured in degrees, degrees, and meters) and to provide a map \\\\(\\\\varphi\\\\) so that \\\\(\\\\varphi^{-1}(\\\\hat U)=\\\\Omega\\\\) where \\\\(\\\\Omega\\\\) is the domain we seek. \\\\((\\\\Omega,\\\\varphi)\\\\) is then a chart, \\\\(\\\\varphi\\\\) the pull-back operator, and \\\\(\\\\varphi^{-1}\\\\) the push-forward operator. If we need a point \\\\(q\\\\) that is the \\\"average\\\" of other points \\\\(q_i\\\\in\\\\Omega\\\\), the ChartManifold class then first applies the pull-back to obtain \\\\(\\\\hat q_i=\\\\varphi(q_i)\\\\), averages these to a point \\\\(\\\\hat p\\\\) and then computes \\\\(p=\\\\varphi^{-1}(\\\\hat p)\\\\).\\nOur goal here is therefore to implement a class that describes \\\\(\\\\varphi\\\\) and \\\\(\\\\varphi^{-1}\\\\). If Earth was a sphere, then this would not be difficult: if we denote by \\\\((\\\\hat \\\\phi,\\\\hat \\\\theta,\\\\hat d)\\\\) the points of \\\\(\\\\hat U\\\\) (i.e., longitude counted eastward, latitude counted northward, and elevation relative to zero depth), then    \\n\\\\[\\n  \\\\mathbf x = \\\\varphi^{-1}(\\\\hat \\\\phi,\\\\hat \\\\theta,\\\\hat d)\\n  = (R+\\\\hat d) (\\\\cos\\\\hat \\\\phi\\\\cos\\\\hat \\\\theta, \\\\sin\\\\hat \\\\phi\\\\cos\\\\hat \\\\theta, \\\\sin\\\\hat \\\\theta)^T\\n\\\\]\\n\\n provides coordinates in a Cartesian coordinate system, where \\\\(R\\\\) is the radius of the sphere. However, the Earth is not a sphere:\\n\\n\\nIt is flattened at the poles and larger at the equator: the semi-major axis is approximately 22km longer than the semi-minor axis. We will account for this using the WGS 84 reference standard for the Earth shape. The formula used in WGS 84 to obtain a position in Cartesian coordinates from longitude, latitude, and elevation is          \\n\\\\[\\n  \\\\mathbf x = \\\\varphi_\\\\text{WGS84}^{-1}(\\\\phi,\\\\theta,d)\\n  = \\\\left(\\n    \\\\begin{array}{c}\\n     (\\\\bar R(\\\\theta)+d) \\\\cos\\\\phi\\\\cos\\\\theta, \\\\\\\\\\n     (\\\\bar R(\\\\theta)+d) \\\\sin\\\\phi\\\\cos\\\\theta, \\\\\\\\\\n     ((1-e^2)\\\\bar R(\\\\theta)+d) \\\\sin\\\\theta\\n    \\\\end{array}\\n    \\\\right),\\n\\\\]\\n\\n where \\\\(\\\\bar R(\\\\theta)=\\\\frac{R}{\\\\sqrt{1-(e \\\\sin\\\\theta)^2}}\\\\), and radius and ellipticity are given by \\\\(R=6378137\\\\text{m}, e=0.081819190842622\\\\). In this formula, we assume that the arguments to sines and cosines are evaluated in degree, not radians (though we will have to change this assumption in the code).\\n\\n\\n\\nIt has topography in the form of mountains and valleys. We will account for this using real topography data (see below for a description of where this data comes from). Using this data set, we can look up elevations on a latitude-longitude mesh laid over the surface of the Earth. Starting with the box \\\\(\\\\hat U=[26,35]\\\\times[-10,5]\\\\times[-500000,0]\\\\), we will therefore first stretch it in vertical direction before handing it off to the WGS 84 function: if \\\\(h(\\\\hat\\\\phi,\\\\hat\\\\theta)\\\\) is the height at longitude \\\\(\\\\hat\\\\phi\\\\) and latitude \\\\(\\\\hat\\\\theta\\\\), then we define         \\n\\\\[\\n  (\\\\phi,\\\\theta,d) =\\n  \\\\varphi_\\\\text{topo}^{-1}(\\\\hat\\\\phi,\\\\hat\\\\theta,\\\\hat d)\\n  = \\\\left(\\n      \\\\hat\\\\phi,\\n      \\\\hat\\\\theta,\\n      \\\\hat d + \\\\frac{\\\\hat d+500000}{500000}h(\\\\hat\\\\phi,\\\\hat\\\\theta)\\n    \\\\right).\\n\\\\]\\n\\n Using this function, the top surface of the box \\\\(\\\\hat U\\\\) is displaced to the correct topography, the bottom surface remains where it was, and points in between are linearly interpolated. \\n\\nUsing these two functions, we can then define the entire push-forward function \\\\(\\\\varphi^{-1}: \\\\hat U \\\\rightarrow \\\\Omega\\\\) as       \\n\\\\[\\n  \\\\mathbf x\\n  =\\n  \\\\varphi^{-1}(\\\\hat\\\\phi,\\\\hat\\\\theta,\\\\hat d)\\n  =\\n  \\\\varphi_\\\\text{WGS84}^{-1}(\\\\varphi_\\\\text{topo}^{-1}(\\\\hat\\\\phi,\\\\hat\\\\theta,\\\\hat d)).\\n\\\\]\\n\\n In addition, we will have to define the inverse of this function, the pull-back operation, which we can write as       \\n\\\\[\\n  (\\\\hat\\\\phi,\\\\hat\\\\theta,\\\\hat d)\\n  =\\n  \\\\varphi(\\\\mathbf x)\\n  =\\n  \\\\varphi_\\\\text{topo}(\\\\varphi_\\\\text{WGS84}(\\\\mathbf x)).\\n\\\\]\\n\\n We can obtain one of the components of this function by inverting the formula above:         \\n\\\\[\\n  (\\\\hat\\\\phi,\\\\hat\\\\theta,\\\\hat d) =\\n  \\\\varphi_\\\\text{topo}(\\\\phi,\\\\theta,d)\\n  = \\\\left(\\n      \\\\phi,\\n      \\\\theta,\\n      500000\\\\frac{d-h(\\\\phi,\\\\theta)}{500000+h(\\\\phi,\\\\theta)}\\n    \\\\right).\\n\\\\]\\n\\n Computing \\\\(\\\\varphi_\\\\text{WGS84}(\\\\mathbf x)\\\\) is also possible though a lot more awkward. We won't show the formula here but instead only provide the implementation in the program.\\nImplementation\\nThere are a number of issues we need to address in the program. At the largest scale, we need to write a class that implements the interface of ChartManifold. This involves a function push_forward() that takes a point in the reference domain \\\\(\\\\hat U\\\\) and transform it into real space using the function \\\\(\\\\varphi^{-1}\\\\) outlined above, and its inverse function pull_back() implementing \\\\(\\\\varphi\\\\). We will do so in the AfricaGeometry class below that looks, in essence, like this: class AfricaGeometry : public ChartManifold<3,3>\\n{\\npublic:\\n virtual\\n Point<3>\\n pull_back(const Point<3> &space_point) const;\\n \\n virtual\\n Point<3>\\n push_forward(const Point<3> &chart_point) const;\\n \\nprivate:\\n  ... some member variables and other member functions...;\\n};\\nChartManifoldDefinition manifold.h:908\\nChartManifold::push_forwardvirtual Point< spacedim > push_forward(const Point< chartdim > &chart_point) const =0\\nChartManifold::pull_backvirtual Point< chartdim > pull_back(const Point< spacedim > &space_point) const =0\\nPointDefinition point.h:111\\nThe transformations above have two parts: the WGS 84 transformations and the topography transformation. Consequently, the AfricaGeometry class will have additional (non-virtual) member functions AfricaGeometry::push_forward_wgs84() and AfricaGeometry::push_forward_topo() that implement these two pieces, and corresponding pull back functions.\\nThe WGS 84 transformation functions are not particularly interesting (even though the formulas they implement are impressive). The more interesting part is the topography transformation. Recall that for this, we needed to evaluate the elevation function \\\\(h(\\\\hat\\\\phi,\\\\hat\\\\theta)\\\\). There is of course no formula for this: Earth is what it is, the best one can do is look up the altitude from some table. This is, in fact what we will do.\\nThe data we use was originally created by the Shuttle Radar Topography Mission, was downloaded from the US Geologic Survey (USGS) and processed by D. Sarah Stamps who also wrote the initial version of the WGS 84 transformation functions. The topography data so processed is stored in a file topography.txt.gz that, when unpacked looks like this: 6.983333 25.000000 700\\n6.983333 25.016667 692\\n6.983333 25.033333 701\\n6.983333 25.050000 695\\n6.983333 25.066667 710\\n6.983333 25.083333 702\\n...\\n-11.983333 35.950000 707\\n-11.983333 35.966667 687\\n-11.983333 35.983333 659\\n The data is formatted as latitude longitude elevation where the first two columns are provided in degrees North of the equator and degrees East of the Greenwich meridian. The final column is given in meters above the WGS 84 zero elevation.\\nIn the transformation functions, we need to evaluate \\\\(h(\\\\hat\\\\phi,\\\\hat\\\\theta)\\\\) for a given longitude \\\\(\\\\hat\\\\phi\\\\) and latitude \\\\(\\\\hat\\\\theta\\\\). In general, this data point will not be available and we will have to interpolate between adjacent data points. Writing such an interpolation routine is not particularly difficult, but it is a bit tedious and error prone. Fortunately, we can somehow shoehorn this data set into an existing class: Functions::InterpolatedUniformGridData . Unfortunately, the class does not fit the bill quite exactly and so we need to work around it a bit. The problem comes from the way we initialize this class: in its simplest form, it takes a stream of values that it assumes form an equispaced mesh in the \\\\(x-y\\\\) plane (or, here, the \\\\(\\\\phi-\\\\theta\\\\) plane). Which is what they do here, sort of: they are ordered latitude first, longitude second; and more awkwardly, the first column starts at the largest values and counts down, rather than the usual other way around.\\nNow, while tutorial programs are meant to illustrate how to code with deal.II, they do not necessarily have to satisfy the same quality standards as one would have to do with production codes. In a production code, we would write a function that reads the data and (i) automatically determines the extents of the first and second column, (ii) automatically determines the number of data points in each direction, (iii) does the interpolation regardless of the order in which data is arranged, if necessary by switching the order between reading and presenting it to the Functions::InterpolatedUniformGridData class.\\nOn the other hand, tutorial programs are best if they are short and demonstrate key points rather than dwell on unimportant aspects and, thereby, obscure what we really want to show. Consequently, we will allow ourselves a bit of leeway:\\nsince this program is intended solely for a particular geometry around the area of the East-African rift and since this is precisely the area described by the data file, we will hardcode in the program that there are \\\\(1139\\\\times 660\\\\) pieces of data;\\nwe will hardcode the boundaries of the data \\\\([-11.98333^\\\\circ,6.983333^\\\\circ]\\\\times[25^\\\\circ,35.98333^\\\\circ]\\\\);\\nwe will lie to the Functions::InterpolatedUniformGridData class: the class will only see the data in the last column of this data file, and we will pretend that the data is arranged in a way that there are 1139 data points in the first coordinate direction that are arranged in ascending order but in an interval \\\\([-6.983333^\\\\circ,11.98333^\\\\circ]\\\\) (not the negated bounds). Then, when we need to look something up for a latitude \\\\(\\\\hat\\\\theta\\\\), we can ask the interpolating table class for a value at \\\\(-\\\\hat\\\\theta\\\\). With this little trick, we can avoid having to switch around the order of data as read from file.\\n\\nAll of this then calls for a class that essentially looks like this: class AfricaTopography\\n{\\npublic:\\n  AfricaTopography ()\\n    :\\n    topography_data (...initialize somehow...)\\n  {}\\n \\n double value (const double lon, const double lat) const\\n {\\n return topography_data.value (Point<2>(-lat * 180/numbers::PI,\\n                                           lon * 180/numbers::PI));\\n  }\\n \\nprivate:\\n const Functions::InterpolatedUniformGridData<2> topography_data;\\n};\\nFunctions::InterpolatedUniformGridDataDefinition function_lib.h:1600\\nnumbers::PIstatic constexpr double PIDefinition numbers.h:259\\nNote how the value() function negates the latitude. It also switches from the format \\\\(\\\\phi,\\\\theta\\\\) that we use everywhere else to the latitude-longitude format used in the table. Finally, it takes its arguments in radians as that is what we do everywhere else in the program, but then converts them to the degree-based system used for table lookup. As you will see in the implementation below, the function has a few more (static) member functions that we will call in the initialization of the topography_data member variable: the class type of this variable has a constructor that allows us to set everything right at construction time, rather than having to fill data later on, but this constructor takes a number of objects that can't be constructed in-place (at least not in C++98). Consequently, the construction of each of the objects we want to pass in the initialization happens in a number of static member functions.\\nHaving discussed the general outline of how we want to implement things, let us go to the program and show how it is done in practice.\\n The commented program\\nLet us start with the include files we need here. Obviously, we need the ones that describe the triangulation (tria.h), and that allow us to create and output triangulations (grid_generator.h and grid_out.h). Furthermore, we need the header file that declares the Manifold and ChartManifold classes that we will need to describe the geometry (manifold.h). We will then also need the GridTools::transform() function from the last of the following header files; the purpose for this function will become discussed at the point where we use it.\\n\\u00a0 #include <deal.II/grid/tria.h>\\n\\u00a0 #include <deal.II/grid/grid_generator.h>\\n\\u00a0 #include <deal.II/grid/grid_out.h>\\n\\u00a0 #include <deal.II/grid/manifold.h>\\n\\u00a0 #include <deal.II/grid/grid_tools.h>\\n\\u00a0 \\nThe remainder of the include files relate to reading the topography data. As explained in the introduction, we will read it from a file and then use the Functions::InterpolatedUniformGridData class that is declared in the first of the following header files. Because the data is large, the file we read from is stored as gzip compressed data and we make use of some BOOST-provided functionality to read directly from gzipped data.\\n\\u00a0 #include <deal.II/base/function_lib.h>\\n\\u00a0 \\n\\u00a0 #include <boost/iostreams/filtering_stream.hpp>\\n\\u00a0 #include <boost/iostreams/filter/gzip.hpp>\\n\\u00a0 #include <boost/iostreams/device/file.hpp>\\n\\u00a0 \\n\\u00a0 #include <fstream>\\n\\u00a0 #include <iostream>\\n\\u00a0 #include <memory>\\n\\u00a0 \\n\\u00a0 \\nboostDefinition bounding_box.h:26\\nThe final part of the top matter is to open a namespace into which to put everything, and then to import the dealii namespace into it.\\n\\u00a0 namespace Step53\\n\\u00a0 {\\n\\u00a0   using namespace dealii;\\n\\u00a0 \\n\\u00a0 \\ndealiiDefinition namespace_dealii.h:25\\n Describing topography: AfricaTopography\\nThe first significant part of this program is the class that describes the topography \\\\(h(\\\\hat phi,\\\\hat \\\\theta)\\\\) as a function of longitude and latitude. As discussed in the introduction, we will make our life a bit easier here by not writing the class in the most general way possible but by only writing it for the particular purpose we are interested in here: interpolating data obtained from one very specific data file that contains information about a particular area of the world for which we know the extents.\\nThe general layout of the class has been discussed already above. Following is its declaration, including three static member functions that we will need in initializing the topography_data member variable.\\n\\u00a0   class AfricaTopography\\n\\u00a0   {\\n\\u00a0   public:\\n\\u00a0     AfricaTopography();\\n\\u00a0 \\n\\u00a0     double value(const double lon, const double lat) const;\\n\\u00a0 \\n\\u00a0   private:\\n\\u00a0     const Functions::InterpolatedUniformGridData<2> topography_data;\\n\\u00a0 \\n\\u00a0     static std::vector<double> get_data();\\n\\u00a0   };\\n\\u00a0 \\n\\u00a0 \\nLet us move to the implementation of the class. The interesting parts of the class are the constructor and the value() function. The former initializes the Functions::InterpolatedUniformGridData member variable and we will use the constructor that requires us to pass in the end points of the 2-dimensional data set we want to interpolate (which are here given by the intervals \\\\([-6.983333, 11.98333]\\\\), using the trick of switching end points discussed in the introduction, and \\\\([25, 35.983333]\\\\), both given in degrees), the number of intervals into which the data is split (379 in latitude direction and 219 in longitude direction, for a total of \\\\(380\\\\times 220\\\\) data points), and a Table object that contains the data. The data then of course has size \\\\(380\\\\times 220\\\\) and we initialize it by providing an iterator to the first of the 83,600 elements of a std::vector object returned by the get_data() function below. Note that all of the member functions we call here are static because (i) they do not access any member variables of the class, and (ii) because they are called at a time when the object is not initialized fully anyway.\\n\\u00a0   AfricaTopography::AfricaTopography()\\n\\u00a0     : topography_data({{std::make_pair(-6.983333, 11.966667),\\n\\u00a0                         std::make_pair(25, 35.95)}},\\n\\u00a0                       {{379, 219}},\\n\\u00a0                       Table<2, double>(380, 220, get_data().begin()))\\n\\u00a0   {}\\n\\u00a0 \\n\\u00a0 \\n\\u00a0   double AfricaTopography::value(const double lon, const double lat) const\\n\\u00a0   {\\n\\u00a0     return topography_data.value(\\n\\u00a0       Point<2>(-lat * 180 / numbers::PI, lon * 180 / numbers::PI));\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\nTableDefinition array_view.h:39\\nTrilinosWrappers::internal::beginVectorType::value_type * begin(VectorType &V)Definition trilinos_sparse_matrix.cc:50\\nThe only other function of greater interest is the get_data() function. It returns a temporary vector that contains all 83,600 data points describing the altitude and is read from the file topography.txt.gz. Because the file is compressed by gzip, we cannot just read it through an object of type std::ifstream, but there are convenient methods in the BOOST library (see http://www.boost.org) that allows us to read from compressed files without first having to uncompress it on disk. The result is, basically, just another input stream that, for all practical purposes, looks just like the ones we always use.\\nWhen reading the data, we read the three columns but ignore the first two. The datum in the last column is appended to an array that we the return and that will be copied into the table from which topography_data is initialized. Since the BOOST.iostreams library does not provide a very useful exception when the input file does not exist, is not readable, or does not contain the correct number of data lines, we catch all exceptions it may produce and create our own one. To this end, in the catch clause, we let the program run into an AssertThrow(false, ...) statement. Since the condition is always false, this always triggers an exception. In other words, this is equivalent to writing throw ExcMessage(\\\"...\\\") but it also fills certain fields in the exception object that will later be printed on the screen identifying the function, file and line where the exception happened.\\n\\u00a0   std::vector<double> AfricaTopography::get_data()\\n\\u00a0   {\\n\\u00a0     std::vector<double> data;\\n\\u00a0 \\n\\u00a0     boost::iostreams::filtering_istream in;\\n\\u00a0     in.push(boost::iostreams::basic_gzip_decompressor<>());\\n\\u00a0     in.push(boost::iostreams::file_source(\\\"topography.txt.gz\\\"));\\n\\u00a0 \\n\\u00a0     for (unsigned int line = 0; line < 83600; ++line)\\n\\u00a0       {\\n\\u00a0         try\\n\\u00a0           {\\n\\u00a0             double lat, lon, elevation;\\n\\u00a0             in >> lat >> lon >> elevation;\\n\\u00a0 \\n\\u00a0             data.push_back(elevation);\\n\\u00a0           }\\n\\u00a0         catch (...)\\n\\u00a0           {\\n\\u00a0             AssertThrow(false,\\n\\u00a0                         ExcMessage(\\\"Could not read all 83,600 data points \\\"\\n\\u00a0                                    \\\"from the file <topography.txt.gz>!\\\"));\\n\\u00a0           }\\n\\u00a0       }\\n\\u00a0 \\n\\u00a0     return data;\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\nAssertThrow#define AssertThrow(cond, exc)Definition exceptions.h:1739\\n Describing the geometry: AfricaGeometry\\nThe following class is then the main one of this program. Its structure has been described in much detail in the introduction and does not need much introduction any more.\\n\\u00a0   class AfricaGeometry : public ChartManifold<3, 3>\\n\\u00a0   {\\n\\u00a0   public:\\n\\u00a0     virtual Point<3> pull_back(const Point<3> &space_point) const override;\\n\\u00a0 \\n\\u00a0     virtual Point<3> push_forward(const Point<3> &chart_point) const override;\\n\\u00a0 \\n\\u00a0     virtual std::unique_ptr<Manifold<3, 3>> clone() const override;\\n\\u00a0 \\n\\u00a0   private:\\n\\u00a0     static const double R;\\n\\u00a0     static const double ellipticity;\\n\\u00a0 \\n\\u00a0     const AfricaTopography topography;\\n\\u00a0 \\n\\u00a0     Point<3> push_forward_wgs84(const Point<3> &phi_theta_d) const;\\n\\u00a0     Point<3> pull_back_wgs84(const Point<3> &x) const;\\n\\u00a0 \\n\\u00a0     Point<3> push_forward_topo(const Point<3> &phi_theta_d_hat) const;\\n\\u00a0     Point<3> pull_back_topo(const Point<3> &phi_theta_d) const;\\n\\u00a0   };\\n\\u00a0 \\n\\u00a0 \\n\\u00a0   const double AfricaGeometry::R           = 6378137;\\n\\u00a0   const double AfricaGeometry::ellipticity = 8.1819190842622e-2;\\n\\u00a0 \\n\\u00a0 \\nManifold< dim, dim >::clonevirtual std::unique_ptr< Manifold< dim, spacedim > > clone() const=0\\nThe implementation, as well, is pretty straightforward if you have read the introduction. In particular, both of the pull back and push forward functions are just concatenations of the respective functions of the WGS 84 and topography mappings:\\n\\u00a0   Point<3> AfricaGeometry::pull_back(const Point<3> &space_point) const\\n\\u00a0   {\\n\\u00a0     return pull_back_topo(pull_back_wgs84(space_point));\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0   Point<3> AfricaGeometry::push_forward(const Point<3> &chart_point) const\\n\\u00a0   {\\n\\u00a0     return push_forward_wgs84(push_forward_topo(chart_point));\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\nThe next function is required by the interface of the Manifold base class, and allows cloning the AfricaGeometry class. Notice that, while the function returns a std::unique_ptr<Manifold<3,3>>, we internally create a unique_ptr<AfricaGeometry>. In other words, the library requires a pointer-to-base-class, which we provide by creating a pointer-to-derived-class.\\n\\u00a0   std::unique_ptr<Manifold<3, 3>> AfricaGeometry::clone() const\\n\\u00a0   {\\n\\u00a0     return std::make_unique<AfricaGeometry>();\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\nThe following two functions then define the forward and inverse transformations that correspond to the WGS 84 reference shape of Earth. The forward transform follows the formula shown in the introduction. The inverse transform is significantly more complicated and is, at the very least, not intuitive. It also suffers from the fact that it returns an angle that at the end of the function we need to clip back into the interval \\\\([0,2\\\\pi]\\\\) if it should have escaped from there.\\n\\u00a0   Point<3> AfricaGeometry::push_forward_wgs84(const Point<3> &phi_theta_d) const\\n\\u00a0   {\\n\\u00a0     const double phi   = phi_theta_d[0];\\n\\u00a0     const double theta = phi_theta_d[1];\\n\\u00a0     const double d     = phi_theta_d[2];\\n\\u00a0 \\n\\u00a0     const double R_bar = R / std::sqrt(1 - (ellipticity * ellipticity *\\n\\u00a0                                             std::sin(theta) * std::sin(theta)));\\n\\u00a0 \\n\\u00a0     return {(R_bar + d) * std::cos(phi) * std::cos(theta),\\n\\u00a0             (R_bar + d) * std::sin(phi) * std::cos(theta),\\n\\u00a0             ((1 - ellipticity * ellipticity) * R_bar + d) * std::sin(theta)};\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0   Point<3> AfricaGeometry::pull_back_wgs84(const Point<3> &x) const\\n\\u00a0   {\\n\\u00a0     const double b   = std::sqrt(R * R * (1 - ellipticity * ellipticity));\\n\\u00a0     const double ep  = std::sqrt((R * R - b * b) / (b * b));\\n\\u00a0     const double p   = std::sqrt(x[0] * x[0] + x[1] * x[1]);\\n\\u00a0     const double th  = std::atan2(R * x[2], b * p);\\n\\u00a0     const double phi = std::atan2(x[1], x[0]);\\n\\u00a0     const double theta =\\n\\u00a0       std::atan2(x[2] + ep * ep * b * Utilities::fixed_power<3>(std::sin(th)),\\n\\u00a0                  (p - (ellipticity * ellipticity * R *\\n\\u00a0                        Utilities::fixed_power<3>(std::cos(th)))));\\n\\u00a0     const double R_bar =\\n\\u00a0       R / (std::sqrt(1 - ellipticity * ellipticity * std::sin(theta) *\\n\\u00a0                            std::sin(theta)));\\n\\u00a0     const double R_plus_d = p / std::cos(theta);\\n\\u00a0 \\n\\u00a0     Point<3> phi_theta_d;\\n\\u00a0     if (phi < 0)\\n\\u00a0       phi_theta_d[0] = phi + 2 * numbers::PI;\\n\\u00a0     else if (phi > 2 * numbers::PI)\\n\\u00a0       phi_theta_d[0] = phi - 2 * numbers::PI;\\n\\u00a0     else\\n\\u00a0       phi_theta_d[0] = phi;\\n\\u00a0     phi_theta_d[1] = theta;\\n\\u00a0     phi_theta_d[2] = R_plus_d - R_bar;\\n\\u00a0     return phi_theta_d;\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\nPhysics::Elasticity::Kinematics::bSymmetricTensor< 2, dim, Number > b(const Tensor< 2, dim, Number > &F)\\nUtilities::fixed_powerconstexpr T fixed_power(const T t)Definition utilities.h:942\\nstd::cos::VectorizedArray< Number, width > cos(const ::VectorizedArray< Number, width > &)Definition vectorization.h:6609\\nstd::sin::VectorizedArray< Number, width > sin(const ::VectorizedArray< Number, width > &)Definition vectorization.h:6589\\nstd::sqrt::VectorizedArray< Number, width > sqrt(const ::VectorizedArray< Number, width > &)Definition vectorization.h:6869\\nIn contrast, the topography transformations follow exactly the description in the introduction. There is not consequently not much to add:\\n\\u00a0   Point<3>\\n\\u00a0   AfricaGeometry::push_forward_topo(const Point<3> &phi_theta_d_hat) const\\n\\u00a0   {\\n\\u00a0     const double d_hat = phi_theta_d_hat[2];\\n\\u00a0     const double h = topography.value(phi_theta_d_hat[0], phi_theta_d_hat[1]);\\n\\u00a0     const double d = d_hat + (d_hat + 500000) / 500000 * h;\\n\\u00a0     return {phi_theta_d_hat[0], phi_theta_d_hat[1], d};\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0   Point<3> AfricaGeometry::pull_back_topo(const Point<3> &phi_theta_d) const\\n\\u00a0   {\\n\\u00a0     const double d     = phi_theta_d[2];\\n\\u00a0     const double h     = topography.value(phi_theta_d[0], phi_theta_d[1]);\\n\\u00a0     const double d_hat = 500000 * (d - h) / (500000 + h);\\n\\u00a0     return {phi_theta_d[0], phi_theta_d[1], d_hat};\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\nPhysics::Elasticity::Kinematics::dSymmetricTensor< 2, dim, Number > d(const Tensor< 2, dim, Number > &F, const Tensor< 2, dim, Number > &dF_dt)\\n Creating the mesh\\nHaving so described the properties of the geometry, not it is time to deal with the mesh used to discretize it. To this end, we create objects for the geometry and triangulation, and then proceed to create a \\\\(1\\\\times 2\\\\times 1\\\\) rectangular mesh that corresponds to the reference domain \\\\(\\\\hat U=[26,35]\\\\times[-10,5]\\\\times[-500000,0]\\\\). We choose this number of subdivisions because it leads to cells that are roughly like cubes instead of stretched in one direction or another.\\nOf course, we are not actually interested in meshing the reference domain. We are interested in meshing the real domain. Consequently, we will use the GridTools::transform() function that simply moves every point of a triangulation according to a given transformation. The transformation function it wants is a function that takes as its single argument a point in the reference domain and returns the corresponding location in the domain that we want to map to. This is, of course, exactly the push forward function of the geometry we use. We wrap it by a lambda function to obtain the kind of function object required for the transformation.\\n\\u00a0   void run()\\n\\u00a0   {\\n\\u00a0     AfricaGeometry   geometry;\\n\\u00a0     Triangulation<3> triangulation;\\n\\u00a0 \\n\\u00a0     {\\n\\u00a0       const Point<3> corner_points[2] = {\\n\\u00a0         Point<3>(26 * numbers::PI / 180, -10 * numbers::PI / 180, -500000),\\n\\u00a0         Point<3>(35 * numbers::PI / 180, 5 * numbers::PI / 180, 0)};\\n\\u00a0       std::vector<unsigned int> subdivisions(3);\\n\\u00a0       subdivisions[0] = 1;\\n\\u00a0       subdivisions[1] = 2;\\n\\u00a0       subdivisions[2] = 1;\\n\\u00a0       GridGenerator::subdivided_hyper_rectangle(\\n\\u00a0         triangulation, subdivisions, corner_points[0], corner_points[1], true);\\n\\u00a0 \\n\\u00a0       GridTools::transform(\\n\\u00a0         [&geometry](const Point<3> &chart_point) {\\n\\u00a0           return geometry.push_forward(chart_point);\\n\\u00a0         },\\n\\u00a0         triangulation);\\n\\u00a0     }\\n\\u00a0 \\nTriangulationDefinition tria.h:1323\\nGridGenerator::subdivided_hyper_rectanglevoid subdivided_hyper_rectangle(Triangulation< dim, spacedim > &tria, const std::vector< unsigned int > &repetitions, const Point< dim > &p1, const Point< dim > &p2, const bool colorize=false)\\nGridTools::transformvoid transform(const Transformation &transformation, Triangulation< dim, spacedim > &triangulation)\\ntriangulationconst ::parallel::distributed::Triangulation< dim, spacedim > * triangulationDefinition p4est_wrappers.cc:68\\nThe next step is to explain to the triangulation to use our geometry object whenever a new point is needed upon refining the mesh. We do this by telling the triangulation to use our geometry for everything that has manifold indicator zero, and then proceed to mark all cells and their bounding faces and edges with manifold indicator zero. This ensures that the triangulation consults our geometry object every time a new vertex is needed. Since manifold indicators are inherited from mother to children, this also happens after several recursive refinement steps.\\n\\u00a0     triangulation.set_manifold(0, geometry);\\n\\u00a0     for (const auto &cell : triangulation.active_cell_iterators())\\n\\u00a0       cell->set_all_manifold_ids(0);\\n\\u00a0 \\nTriangulation::set_manifoldvoid set_manifold(const types::manifold_id number, const Manifold< dim, spacedim > &manifold_object)\\nThe last step is to refine the mesh beyond its initial  \\\\(1\\\\times 2\\\\times\\n   1\\\\) coarse mesh. We could just refine globally a number of times, but since for the purpose of this tutorial program we're really only interested in what is happening close to the surface, we just refine 6 times all of the cells that have a face at a boundary with indicator 5. Looking this up in the documentation of the GridGenerator::subdivided_hyper_rectangle() function we have used above reveals that boundary indicator 5 corresponds to the top surface of the domain (and this is what the last true argument in the call to GridGenerator::subdivided_hyper_rectangle() above meant: to \\\"color\\\" the boundaries by assigning each boundary a unique boundary indicator).\\n\\u00a0     for (unsigned int i = 0; i < 6; ++i)\\n\\u00a0       {\\n\\u00a0         for (const auto &cell : triangulation.active_cell_iterators())\\n\\u00a0           for (const auto &face : cell->face_iterators())\\n\\u00a0             if (face->boundary_id() == 5)\\n\\u00a0               {\\n\\u00a0                 cell->set_refine_flag();\\n\\u00a0                 break;\\n\\u00a0               }\\n\\u00a0         triangulation.execute_coarsening_and_refinement();\\n\\u00a0 \\n\\u00a0         std::cout << \\\"Refinement step \\\" << i + 1 << \\\": \\\"\\n\\u00a0                   << triangulation.n_active_cells() << \\\" cells, \\\"\\n\\u00a0                   << GridTools::minimal_cell_diameter(triangulation) / 1000\\n\\u00a0                   << \\\"km minimal cell diameter\\\" << std::endl;\\n\\u00a0       }\\n\\u00a0 \\nTriangulation::n_active_cellsunsigned int n_active_cells() const\\nparallel::distributed::Triangulation::execute_coarsening_and_refinementvirtual void execute_coarsening_and_refinement() overrideDefinition tria.cc:3320\\nGridTools::minimal_cell_diameterdouble minimal_cell_diameter(const Triangulation< dim, spacedim > &triangulation, const Mapping< dim, spacedim > &mapping=(ReferenceCells::get_hypercube< dim >() .template get_default_linear_mapping< dim, spacedim >()))Definition grid_tools_geometry.cc:407\\nHaving done this all, we can now output the mesh into a file of its own:\\n\\u00a0     const std::string filename = \\\"mesh.vtu\\\";\\n\\u00a0     std::ofstream     out(filename);\\n\\u00a0     GridOut           grid_out;\\n\\u00a0     grid_out.write_vtu(triangulation, out);\\n\\u00a0   }\\n\\u00a0 } // namespace Step53\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nGridOutDefinition grid_out.h:993\\nGridOut::write_vtuvoid write_vtu(const Triangulation< dim, spacedim > &tria, std::ostream &out) constDefinition grid_out.cc:3544\\n The main function\\nFinally, the main function, which follows the same scheme used in all tutorial programs starting with step-6. There isn't much to do here, only to call the single run() function.\\n\\u00a0 int main()\\n\\u00a0 {\\n\\u00a0   try\\n\\u00a0     {\\n\\u00a0       Step53::run();\\n\\u00a0     }\\n\\u00a0   catch (std::exception &exc)\\n\\u00a0     {\\n\\u00a0       std::cerr << std::endl\\n\\u00a0                 << std::endl\\n\\u00a0                 << \\\"----------------------------------------------------\\\"\\n\\u00a0                 << std::endl;\\n\\u00a0       std::cerr << \\\"Exception on processing: \\\" << std::endl\\n\\u00a0                 << exc.what() << std::endl\\n\\u00a0                 << \\\"Aborting!\\\" << std::endl\\n\\u00a0                 << \\\"----------------------------------------------------\\\"\\n\\u00a0                 << std::endl;\\n\\u00a0 \\n\\u00a0       return 1;\\n\\u00a0     }\\n\\u00a0   catch (...)\\n\\u00a0     {\\n\\u00a0       std::cerr << std::endl\\n\\u00a0                 << std::endl\\n\\u00a0                 << \\\"----------------------------------------------------\\\"\\n\\u00a0                 << std::endl;\\n\\u00a0       std::cerr << \\\"Unknown exception!\\\" << std::endl\\n\\u00a0                 << \\\"Aborting!\\\" << std::endl\\n\\u00a0                 << \\\"----------------------------------------------------\\\"\\n\\u00a0                 << std::endl;\\n\\u00a0       return 1;\\n\\u00a0     }\\n\\u00a0 }\\n Results\\nRunning the program produces a mesh file mesh.vtu that we can visualize with any of the usual visualization programs that can read the VTU file format. If one just looks at the mesh itself, it is actually very difficult to see anything that doesn't just look like a perfectly round piece of a sphere (though if one modified the program so that it does produce a sphere and looked at them at the same time, the difference between the overall sphere and WGS 84 shape is quite apparent). Apparently, Earth is actually quite a flat place. Of course we already know this from satellite pictures. However, we can tease out something more by coloring cells by their volume. This both produces slight variations in hue along the top surface and something for the visualization programs to apply their shading algorithms to (because the top surfaces of the cells are now no longer just tangential to a sphere but tilted):\\n\\nYet, at least as far as visualizations are concerned, this is still not too impressive. Rather, let us visualize things in a way so that we show the actual elevation along the top surface. In other words, we want a picture like this, with an incredible amount of detail:\\n\\nA zoom-in of this picture shows the vertical displacement quite clearly (here, looking from the West-Northwest over the rift valley, the triple peaks of Mount Stanley, Mount Speke, and Mount Baker in the Rwenzori Range, Lake George and toward the great flatness of Lake Victoria):\\n\\nThese image were produced with three small modifications: \\n\\nAn additional seventh mesh refinement towards the top surface for the first of these two pictures, and a total of nine for the second. In the second image, the horizontal mesh size is approximately 1.5km, and just under 1km in vertical direction. (The picture was also created using a more resolved data set; however, it is too big to distribute as part of the tutorial.)\\n\\n\\n\\nThe addition of the following function that, given a point x computes the elevation by converting the point to reference WGS 84 coordinates and only keeping the depth variable (the function is, consequently, a simplified version of the AfricaGeometry::pull_back_wgs84() function):\\n#include <deal.II/fe/fe_q.h>\\n#include <deal.II/dofs/dof_handler.h>\\n#include <deal.II/numerics/data_out.h>\\n#include <deal.II/numerics/vector_tools.h>\\n \\n \\ndouble get_elevation (const Point<3> &x)\\n  {\\n const double R           = 6378137;\\n const double ellipticity = 8.1819190842622e-2;\\n \\n const double b     = std::sqrt(R * R * (1 - ellipticity * ellipticity));\\n const double ep    = std::sqrt((R * R - b * b) / (b * b));\\n const double p     = std::sqrt(x(0) * x(0) + x(1) * x(1));\\n const double th    = std::atan2(R * x(2), b * p);\\n const double theta = std::atan2((x(2) + ep * ep * b * std::sin(th) * std::sin(th) * std::sin(th)),\\n                                      (p - (ellipticity * ellipticity * R  * (std::cos(th) * std::cos(th) * std::cos(th)))));\\n const double R_bar = R / (std::sqrt(1 - ellipticity * ellipticity * std::sin(theta) * std::sin(theta)));\\n const double R_plus_d = p / std::cos(theta);\\n \\n return R_plus_d - R_bar;\\n  }\\ndof_handler.h\\nfe_q.h\\ndata_out.h\\nvector_tools.h\\n\\n\\n\\nAdding the following piece to the bottom of the run() function:\\nFE_Q<3>       fe(1);\\nDoFHandler<3> dof_handler (triangulation);\\ndof_handler.distribute_dofs(fe);\\n \\nVector<double> elevation (dof_handler.n_dofs());\\n{\\n  std::map<unsigned int,double> boundary_values;\\n VectorTools::interpolate_boundary_values(dof_handler,\\n                                           5,\\n ScalarFunctionFromFunctionObject<3>(get_elevation),\\n                                           boundary_values);\\n for (std::map<unsigned int,double>::const_iterator p = boundary_values.begin();\\n       p!=boundary_values.end(); ++p)\\n    elevation[p->first] = p->second;\\n}\\n \\nDataOut<3>    data_out;\\ndata_out.attach_dof_handler(dof_handler);\\ndata_out.add_data_vector (elevation, \\\"elevation\\\");\\ndata_out.build_patches();\\n \\nstd::ofstream out (\\\"data.vtu\\\");\\ndata_out.write_vtu (out);\\nDataOutInterface::write_vtuvoid write_vtu(std::ostream &out) constDefinition data_out_base.cc:7692\\nDataOut_DoFData::attach_dof_handlervoid attach_dof_handler(const DoFHandler< dim, spacedim > &)\\nDataOut_DoFData::add_data_vectorvoid add_data_vector(const VectorType &data, const std::vector< std::string > &names, const DataVectorType type=type_automatic, const std::vector< DataComponentInterpretation::DataComponentInterpretation > &data_component_interpretation={})Definition data_out_dof_data.h:1069\\nDataOutDefinition data_out.h:147\\nDataOut::build_patchesvirtual void build_patches(const unsigned int n_subdivisions=0)Definition data_out.cc:1062\\nDoFHandlerDefinition dof_handler.h:317\\nFE_QDefinition fe_q.h:554\\nScalarFunctionFromFunctionObjectDefinition function.h:803\\nVectorDefinition vector.h:120\\nVectorTools::interpolate_boundary_valuesvoid interpolate_boundary_values(const Mapping< dim, spacedim > &mapping, const DoFHandler< dim, spacedim > &dof, const std::map< types::boundary_id, const Function< spacedim, number > * > &function_map, std::map< types::global_dof_index, number > &boundary_values, const ComponentMask &component_mask={})\\n \\n\\nThis last piece of code first creates a \\\\(Q_1\\\\) finite element space on the mesh. It then (ab)uses VectorTools::interpolate_boundary_values() to evaluate the elevation function for every node at the top boundary (the one with boundary indicator 5). We here wrap the call to get_elevation() with the ScalarFunctionFromFunctionObject class to make a regular C++ function look like an object of a class derived from the Function class that we want to use in VectorTools::interpolate_boundary_values(). Having so gotten a list of degrees of freedom located at the top boundary and corresponding elevation values, we just go down this list and set these elevations in the elevation vector (leaving all interior degrees of freedom at their original zero value). This vector is then output using DataOut as usual and can be visualized as shown above.\\nIssues with adaptively refined meshes generated this way\\nIf you zoomed in on the mesh shown above and looked closely enough, you would find that at hanging nodes, the two small edges connecting to the hanging nodes are not in exactly the same location as the large edge of the neighboring cell. This can be shown more clearly by using a different surface description in which we enlarge the vertical topography to enhance the effect (courtesy of Alexander Grayver):\\n\\nSo what is happening here? Partly, this is only a result of visualization, but there is an underlying real cause as well:\\n\\n\\nWhen you visualize a mesh using any of the common visualization programs, what they really show you is just a set of edges that are plotted as straight lines in three-dimensional space. This is so because almost all data file formats for visualizing data only describe hexahedral cells as a collection of eight vertices in 3d space, and do not allow to any more complicated descriptions. (This is the main reason why DataOut::build_patches() takes an argument that can be set to something larger than one.) These linear edges may be the edges of the cell you do actual computations on, or they may not, depending on what kind of mapping you use when you do your integrations using FEValues. By default, of course, FEValues uses a linear mapping (i.e., an object of class MappingQ1) and in that case a 3d cell is indeed described exclusively by its 8 vertices and the volume it fills is a trilinear interpolation between these points, resulting in linear edges. But, you could also have used tri-quadratic, tri-cubic, or even higher order mappings and in these cases the volume of each cell will be bounded by quadratic, cubic or higher order polynomial curves. Yet, you only get to see these with linear edges in the visualization program because, as mentioned, file formats do not allow to describe the real geometry of cells.\\n\\n\\n\\nThat said, let us for simplicity assume that you are indeed using a trilinear mapping, then the image shown above is a faithful representation of the cells on which you form your integrals. In this case, indeed the small cells at a hanging nodes do not, in general, snugly fit against the large cell but leave a gap or may intersect the larger cell. Why is this? Because when the triangulation needs a new vertex on an edge it wants to refine, it asks the manifold description where this new vertex is supposed to be, and the manifold description duly returns such a point by (in the case of a geometry derived from ChartManifold) pulling the adjacent points of the line back to the reference domain, averaging their locations, and pushing forward this new location to the real domain. But this new location is not usually along a straight line (in real space) between the adjacent vertices and consequently the two small straight lines forming the refined edge do not lie exactly on the one large straight line forming the unrefined side of the hanging node. \\n\\nThe situation is slightly more complicated if you use a higher order mapping using the MappingQ class, but not fundamentally different. Let's take a quadratic mapping for the moment (nothing fundamental changes with even higher order mappings). Then you need to imagine each edge of the cells you integrate on as a quadratic curve despite the fact that you will never actually see it plotted that way by a visualization program. But imagine it that way for a second. So which quadratic curve does MappingQ take? It is the quadratic curve that goes through the two vertices at the end of the edge as well as a point in the middle that it queries from the manifold. In the case of the long edge on the unrefined side, that's of course exactly the location of the hanging node, so the quadratic curve describing the long edge does go through the hanging node, unlike in the case of the linear mapping. But the two small edges are also quadratic curves; for example, the left small edge will go through the left vertex of the long edge and the hanging node, plus a point it queries halfway in between from the manifold. Because, as before, the point the manifold returns halfway along the left small edge is rarely exactly on the quadratic curve describing the long edge, the quadratic short edge will typically not coincide with the left half of the quadratic long edge, and the same is true for the right short edge. In other words, again, the geometries of the large cell and its smaller neighbors at hanging nodes do not touch snuggly.\\nThis all begs two questions: first, does it matter, and second, could this be fixed. Let us discuss these in the following:\\n\\n\\nDoes it matter? It is almost certainly true that this depends on the equation you are solving. For example, it is known that solving the Euler equations of gas dynamics on complex geometries requires highly accurate boundary descriptions to ensure convergence of quantities that are measure the flow close to the boundary. On the other hand, equations with elliptic components (e.g., the Laplace or Stokes equations) are typically rather forgiving of these issues: one does quadrature anyway to approximate integrals, and further approximating the geometry may not do as much harm as one could fear given that the volume of the overlaps or gaps at every hanging node is only \\\\({\\\\cal O}(h^d)\\\\) even with a linear mapping and  \\\\({\\\\cal\\n  O}(h^{d+p-1})\\\\) for a mapping of degree \\\\(p\\\\). (You can see this by considering that in 2d the gap/overlap is a triangle with base \\\\(h\\\\) and height  \\\\({\\\\cal\\n  O}(h)\\\\); in 3d, it is a pyramid-like structure with base area \\\\(h^2\\\\) and height \\\\({\\\\cal O}(h)\\\\). Similar considerations apply for higher order mappings where the height of the gaps/overlaps is \\\\({\\\\cal O}(h^p)\\\\).) In other words, if you use a linear mapping with linear elements, the error in the volume you integrate over is already at the same level as the integration error using the usual Gauss quadrature. Of course, for higher order elements one would have to choose matching mapping objects.\\nAnother point of view on why it is probably not worth worrying too much about the issue is that there is certainly no narrative in the community of numerical analysts that these issues are a major concern one needs to watch out for when using complex geometries. If it does not seem to be discussed often among practitioners, if ever at all, then it is at least not something people have identified as a common problem.\\nThis issue is not dissimilar to having hanging nodes at curved boundaries where the geometry description of the boundary typically pulls a hanging node onto the boundary whereas the large edge remains straight, making the adjacent small and large cells not match each other. Although this behavior existed in deal.II since its beginning, 15 years before manifold descriptions became available, it did not ever come up in mailing list discussions or conversations with colleagues.\\n\\n\\n\\nCould it be fixed? In principle, yes, but it's a complicated issue. Let's assume for the moment that we would only ever use the MappingQ1 class, i.e., linear mappings. In that case, whenever the triangulation class requires a new vertex along an edge that would become a hanging node, it would just take the mean value of the adjacent vertices in real space, i.e., without asking the manifold description. This way, the point lies on the long straight edge and the two short straight edges would match the one long edge. Only when all adjacent cells have been refined and the point is no longer a hanging node would we replace its coordinates by coordinates we get by a manifold. This may be awkward to implement, but it would certainly be possible.\\nThe more complicated issue arises because people may want to use a higher order MappingQ object. In that case, the Triangulation class may freely choose the location of the hanging node (because the quadratic curve for the long edge can be chosen in such a way that it goes through the hanging node) but the MappingQ class, when determining the location of mid-edge points must make sure that if the edge is one half of a long edge of a neighboring coarser cell, then the midpoint cannot be obtained from the manifold but must be chosen along the long quadratic edge. For cubic (and all other odd) mappings, the matter is again a bit complicated because one typically arranges the cubic edge to go through points 1/3 and 2/3 along the edge, and thus necessarily through the hanging node, but this could probably be worked out. In any case, even then, there are two problems with this:\\n\\nWhen refining the triangulation, the Triangulation class can not know what mapping will be used. In fact it is not uncommon for a triangulation to be used differently in different contexts within the same program. If the mapping used determines whether we can freely choose a point or not, how, then, should the triangulation locate new vertices?\\nMappings are purely local constructs: they only work on a cell in isolation, and this is one of the important features of the finite element method. Having to ask whether one of the vertices of an edge is a hanging node requires querying the neighborhood of a cell; furthermore, such a query does not just involve the 6 face neighbors of a cell in 3d, but may require traversing a possibly very large number of other cells that connect to an edge. Even if it can be done, one still needs to do different things depending on how the neighborhood looks like, producing code that is likely very complex, hard to maintain, and possibly slow.\\n\\nConsequently, at least for the moment, none of these ideas are implemented. This leads to the undesirable consequence of discontinuous geometries, but, as discussed above, the effects of this do not appear to pose problem in actual practice.\\n\\n\\n\\n The plain program\\n/* ------------------------------------------------------------------------\\n *\\n * SPDX-License-Identifier: LGPL-2.1-or-later\\n * Copyright (C) 2014 - 2024 by the deal.II authors\\n *\\n * This file is part of the deal.II library.\\n *\\n * Part of the source code is dual licensed under Apache-2.0 WITH\\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\\n * governing the source code and code contributions can be found in\\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\\n *\\n * ------------------------------------------------------------------------\\n *\\n * Authors: Wolfgang Bangerth, Texas A&M University, 2014\\n *          Luca Heltai, SISSA, 2014\\n *          D. Sarah Stamps, MIT, 2014\\n */\\n \\n#include <deal.II/grid/tria.h>\\n#include <deal.II/grid/grid_generator.h>\\n#include <deal.II/grid/grid_out.h>\\n#include <deal.II/grid/manifold.h>\\n#include <deal.II/grid/grid_tools.h>\\n \\n#include <deal.II/base/function_lib.h>\\n \\n#include <boost/iostreams/filtering_stream.hpp>\\n#include <boost/iostreams/filter/gzip.hpp>\\n#include <boost/iostreams/device/file.hpp>\\n \\n#include <fstream>\\n#include <iostream>\\n#include <memory>\\n \\n \\nnamespace Step53\\n{\\n using namespace dealii;\\n \\n \\n class AfricaTopography\\n  {\\n public:\\n    AfricaTopography();\\n \\n double value(const double lon, const double lat) const;\\n \\n private:\\n const Functions::InterpolatedUniformGridData<2> topography_data;\\n \\n static std::vector<double> get_data();\\n  };\\n \\n \\n  AfricaTopography::AfricaTopography()\\n    : topography_data({{std::make_pair(-6.983333, 11.966667),\\n                        std::make_pair(25, 35.95)}},\\n                      {{379, 219}},\\n Table<2, double>(380, 220, get_data().begin()))\\n  {}\\n \\n \\n double AfricaTopography::value(const double lon, const double lat) const\\n {\\n return topography_data.value(\\n Point<2>(-lat * 180 / numbers::PI, lon * 180 / numbers::PI));\\n  }\\n \\n \\n  std::vector<double> AfricaTopography::get_data()\\n  {\\n    std::vector<double> data;\\n \\n    boost::iostreams::filtering_istream in;\\n    in.push(boost::iostreams::basic_gzip_decompressor<>());\\n    in.push(boost::iostreams::file_source(\\\"topography.txt.gz\\\"));\\n \\n for (unsigned int line = 0; line < 83600; ++line)\\n      {\\n try\\n          {\\n double lat, lon, elevation;\\n            in >> lat >> lon >> elevation;\\n \\n            data.push_back(elevation);\\n          }\\n catch (...)\\n          {\\n AssertThrow(false,\\n                        ExcMessage(\\\"Could not read all 83,600 data points \\\"\\n \\\"from the file <topography.txt.gz>!\\\"));\\n          }\\n      }\\n \\n return data;\\n  }\\n \\n \\n class AfricaGeometry : public ChartManifold<3, 3>\\n  {\\n public:\\n virtual Point<3> pull_back(const Point<3> &space_point) const override;\\n \\n virtual Point<3> push_forward(const Point<3> &chart_point) const override;\\n \\n virtual std::unique_ptr<Manifold<3, 3>> clone() const override;\\n \\n private:\\n static const double R;\\n static const double ellipticity;\\n \\n const AfricaTopography topography;\\n \\n Point<3> push_forward_wgs84(const Point<3> &phi_theta_d) const;\\n Point<3> pull_back_wgs84(const Point<3> &x) const;\\n \\n Point<3> push_forward_topo(const Point<3> &phi_theta_d_hat) const;\\n Point<3> pull_back_topo(const Point<3> &phi_theta_d) const;\\n  };\\n \\n \\n const double AfricaGeometry::R           = 6378137;\\n const double AfricaGeometry::ellipticity = 8.1819190842622e-2;\\n \\n \\n Point<3> AfricaGeometry::pull_back(const Point<3> &space_point) const\\n {\\n return pull_back_topo(pull_back_wgs84(space_point));\\n  }\\n \\n Point<3> AfricaGeometry::push_forward(const Point<3> &chart_point) const\\n {\\n return push_forward_wgs84(push_forward_topo(chart_point));\\n  }\\n \\n \\n  std::unique_ptr<Manifold<3, 3>> AfricaGeometry::clone() const\\n {\\n return std::make_unique<AfricaGeometry>();\\n  }\\n \\n \\n Point<3> AfricaGeometry::push_forward_wgs84(const Point<3> &phi_theta_d) const\\n {\\n const double phi   = phi_theta_d[0];\\n const double theta = phi_theta_d[1];\\n const double d     = phi_theta_d[2];\\n \\n const double R_bar = R / std::sqrt(1 - (ellipticity * ellipticity *\\n std::sin(theta) * std::sin(theta)));\\n \\n return {(R_bar + d) * std::cos(phi) * std::cos(theta),\\n            (R_bar + d) * std::sin(phi) * std::cos(theta),\\n            ((1 - ellipticity * ellipticity) * R_bar + d) * std::sin(theta)};\\n  }\\n \\n Point<3> AfricaGeometry::pull_back_wgs84(const Point<3> &x) const\\n {\\n const double b   = std::sqrt(R * R * (1 - ellipticity * ellipticity));\\n const double ep  = std::sqrt((R * R - b * b) / (b * b));\\n const double p   = std::sqrt(x[0] * x[0] + x[1] * x[1]);\\n const double th  = std::atan2(R * x[2], b * p);\\n const double phi = std::atan2(x[1], x[0]);\\n const double theta =\\n      std::atan2(x[2] + ep * ep * b * Utilities::fixed_power<3>(std::sin(th)),\\n                 (p - (ellipticity * ellipticity * R *\\n Utilities::fixed_power<3>(std::cos(th)))));\\n const double R_bar =\\n      R / (std::sqrt(1 - ellipticity * ellipticity * std::sin(theta) *\\n std::sin(theta)));\\n const double R_plus_d = p / std::cos(theta);\\n \\n Point<3> phi_theta_d;\\n if (phi < 0)\\n      phi_theta_d[0] = phi + 2 * numbers::PI;\\n else if (phi > 2 * numbers::PI)\\n      phi_theta_d[0] = phi - 2 * numbers::PI;\\n else\\n      phi_theta_d[0] = phi;\\n    phi_theta_d[1] = theta;\\n    phi_theta_d[2] = R_plus_d - R_bar;\\n return phi_theta_d;\\n  }\\n \\n \\n Point<3>\\n  AfricaGeometry::push_forward_topo(const Point<3> &phi_theta_d_hat) const\\n {\\n const double d_hat = phi_theta_d_hat[2];\\n const double h = topography.value(phi_theta_d_hat[0], phi_theta_d_hat[1]);\\n const double d = d_hat + (d_hat + 500000) / 500000 * h;\\n return {phi_theta_d_hat[0], phi_theta_d_hat[1], d};\\n  }\\n \\n Point<3> AfricaGeometry::pull_back_topo(const Point<3> &phi_theta_d) const\\n {\\n const double d     = phi_theta_d[2];\\n const double h     = topography.value(phi_theta_d[0], phi_theta_d[1]);\\n const double d_hat = 500000 * (d - h) / (500000 + h);\\n return {phi_theta_d[0], phi_theta_d[1], d_hat};\\n  }\\n \\n \\n void run()\\n  {\\n    AfricaGeometry   geometry;\\n Triangulation<3> triangulation;\\n \\n    {\\n const Point<3> corner_points[2] = {\\n Point<3>(26 * numbers::PI / 180, -10 * numbers::PI / 180, -500000),\\n Point<3>(35 * numbers::PI / 180, 5 * numbers::PI / 180, 0)};\\n      std::vector<unsigned int> subdivisions(3);\\n      subdivisions[0] = 1;\\n      subdivisions[1] = 2;\\n      subdivisions[2] = 1;\\n GridGenerator::subdivided_hyper_rectangle(\\n triangulation, subdivisions, corner_points[0], corner_points[1], true);\\n \\n GridTools::transform(\\n        [&geometry](const Point<3> &chart_point) {\\n return geometry.push_forward(chart_point);\\n        },\\n triangulation);\\n    }\\n \\n triangulation.set_manifold(0, geometry);\\n for (const auto &cell : triangulation.active_cell_iterators())\\n      cell->set_all_manifold_ids(0);\\n \\n for (unsigned int i = 0; i < 6; ++i)\\n      {\\n for (const auto &cell : triangulation.active_cell_iterators())\\n          for (const auto &face : cell->face_iterators())\\n            if (face->boundary_id() == 5)\\n              {\\n                cell->set_refine_flag();\\n break;\\n              }\\n triangulation.execute_coarsening_and_refinement();\\n \\n        std::cout << \\\"Refinement step \\\" << i + 1 << \\\": \\\"\\n                  << triangulation.n_active_cells() << \\\" cells, \\\"\\n                  << GridTools::minimal_cell_diameter(triangulation) / 1000\\n                  << \\\"km minimal cell diameter\\\" << std::endl;\\n      }\\n \\n const std::string filename = \\\"mesh.vtu\\\";\\n    std::ofstream     out(filename);\\n GridOut           grid_out;\\n    grid_out.write_vtu(triangulation, out);\\n  }\\n} // namespace Step53\\n \\n \\n \\n \\nint main()\\n{\\n try\\n    {\\n      Step53::run();\\n    }\\n catch (std::exception &exc)\\n    {\\n      std::cerr << std::endl\\n                << std::endl\\n                << \\\"----------------------------------------------------\\\"\\n                << std::endl;\\n      std::cerr << \\\"Exception on processing: \\\" << std::endl\\n                << exc.what() << std::endl\\n                << \\\"Aborting!\\\" << std::endl\\n                << \\\"----------------------------------------------------\\\"\\n                << std::endl;\\n \\n return 1;\\n    }\\n catch (...)\\n    {\\n      std::cerr << std::endl\\n                << std::endl\\n                << \\\"----------------------------------------------------\\\"\\n                << std::endl;\\n      std::cerr << \\\"Unknown exception!\\\" << std::endl\\n                << \\\"Aborting!\\\" << std::endl\\n                << \\\"----------------------------------------------------\\\"\\n                << std::endl;\\n return 1;\\n    }\\n}\\nfunction_lib.h\\ntria.h\\ngrid_generator.h\\ngrid_out.h\\ngrid_tools.h\\nmanifold.h\\nWorkStream::internal::tbb_no_coloring::runvoid run(const Iterator &begin, const std_cxx20::type_identity_t< Iterator > &end, Worker worker, Copier copier, const ScratchData &sample_scratch_data, const CopyData &sample_copy_data, const unsigned int queue_length, const unsigned int chunk_size)Definition work_stream.h:471\\ntypes::boundary_idunsigned int boundary_idDefinition types.h:144\\n \\n\\n\\n\\n\\nGenerated by\\u00a0 1.11.0\\n\\n\\n\\n\\n\", \"type\": \"Document\"}}]"