"[{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"document\", \"Document\"], \"kwargs\": {\"metadata\": {\"source\": \"https://dealii.org/current/doxygen/deal.II/step_66.html\", \"content_type\": \"text/html\", \"title\": \"The deal.II Library: The step-66 tutorial program\", \"language\": \"en-US\"}, \"page_content\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\nThe deal.II Library: The step-66 tutorial program\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\u00a0Reference documentation for deal.II version 9.6.0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\\(\\\\newcommand{\\\\dealvcentcolon}{\\\\mathrel{\\\\mathop{:}}}\\\\)\\n\\\\(\\\\newcommand{\\\\dealcoloneq}{\\\\dealvcentcolon\\\\mathrel{\\\\mkern-1.2mu}=}\\\\)\\n\\\\(\\\\newcommand{\\\\jump}[1]{\\\\left[\\\\!\\\\left[ #1 \\\\right]\\\\!\\\\right]}\\\\)\\n\\\\(\\\\newcommand{\\\\average}[1]{\\\\left\\\\{\\\\!\\\\left\\\\{ #1 \\\\right\\\\}\\\\!\\\\right\\\\}}\\\\)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLoading...\\nSearching...\\nNo Matches\\n\\n\\n\\n\\n\\n\\n\\nThe step-66 tutorial program\\n\\n\\nThis tutorial depends on step-15, step-37.\\n\\n\\nTable of contents\\n\\n\\n Introduction\\n\\nProblem formulation\\nDiscretization with finite elements\\nNumerical linear algebra\\nTriangulation\\n\\n The commented program\\n\\nMatrix-free JacobianOperator\\n\\nEvaluation of the old Newton step\\nNonlinear matrix-free operator application\\nDiagonal of the JacobianOperator\\n\\nGelfandProblem class\\n\\nGelfandProblem::make_grid\\nGelfandProblem::setup_system\\nGelfandProblem::evaluate_residual\\nGelfandProblem::local_evaluate_residual\\nGelfandProblem::assemble_rhs\\nGelfandProblem::compute_residual\\nGelfandProblem::compute_update\\nGelfandProblem::solve\\nGelfandProblem::compute_solution_norm\\nGelfandProblem::output_results\\nGelfandProblem::run\\n\\nThe main function\\n\\n\\n Results\\n\\nProgram output\\nNewton solver\\nPossibilities for extensions\\n\\nMore sophisticated Newton iteration\\nParallel scalability and thread parallelism\\nComparison to matrix-based methods\\nEigenvalue problem\\n\\n\\n The plain program\\n   \\n\\n\\n This program was contributed by Fabian Castelli.\\nA version of this code was presented and discussed in [54] G.F. Castelli: Numerical Investigation of Cahn-Hilliard-Type Phase-Field Models for Battery Active Particles, PhD thesis, Karlsruhe Institute of Technology (KIT), 2021.\\nFabian Castelli acknowledges financial support by the German Research Foundation (DFG) through the Research Training Group 2218 SiMET \\u2013 Simulation of mechano-electro-thermal processes in lithium-ion batteries, project number 281041241.\\nFinally Fabian Castelli would like to thank Timo Heister for the encouragement and advice in writing this tutorial. \\n Introduction\\nThe aim of this tutorial program is to demonstrate how to solve a nonlinear problem using Newton's method within the matrix-free framework. This tutorial combines several techniques already introduced in step-15, step-16, step-37, step-48 and others.\\nProblem formulation\\nOn the unit circle \\\\(\\\\Omega = \\\\bigl\\\\{ x \\\\in \\\\mathbb{R}^2 : \\\\|x\\\\| \\\\leq 1 \\\\bigr\\\\}\\\\) we consider the following nonlinear elliptic boundary value problem subject to a homogeneous Dirichlet boundary condition: Find a function \\\\(u\\\\colon\\\\Omega\\\\to\\\\mathbb{R}\\\\) such that it holds:    \\n\\\\begin{align*}\\n    - \\\\Delta u &= \\\\exp(u) & \\\\quad & \\\\text{in } \\\\Omega,\\\\\\\\\\n             u &= 0       & \\\\quad & \\\\text{on } \\\\partial\\\\Omega.\\n\\\\end{align*}\\n\\n This problem is also called the Gelfand problem and is a typical example for problems from combustion theory, see for example [18].\\nDiscretization with finite elements\\nAs usual, we first derive the weak formulation for this problem by multiplying with a smooth test function \\\\(v\\\\colon\\\\Omega\\\\to\\\\mathbb{R}\\\\) respecting the boundary condition and integrating over the domain \\\\(\\\\Omega\\\\). Integration by parts and putting the term from the right hand side to the left yields the weak formulation: Find a function \\\\(u\\\\colon\\\\Omega\\\\to\\\\mathbb{R}\\\\) such that for all test functions \\\\(v\\\\) it holds:       \\n\\\\begin{align*}\\n \\\\int_\\\\Omega \\\\nabla v \\\\cdot \\\\nabla u \\\\,\\\\mathrm{d}x\\n -\\n \\\\int_\\\\Omega v \\\\exp(u) \\\\,\\\\mathrm{d}x\\n =\\n 0.\\n\\\\end{align*}\\n\\nChoosing the Lagrangian finite element space   \\\\(V_h \\\\dealcoloneq\\n\\\\bigl\\\\{ v \\\\in C(\\\\overline{\\\\Omega}) : v|_Q \\\\in \\\\mathbb{Q}_p \\\\text{ for all }\\nQ \\\\in \\\\mathcal{T}_h \\\\bigr\\\\} \\\\cap H_0^1(\\\\Omega)\\\\), which directly incorporates the homogeneous Dirichlet boundary condition, we can define a basis \\\\(\\\\{\\\\varphi_i\\\\}_{i=1,\\\\dots,N}\\\\) and thus it suffices to test only with those basis functions. So the discrete problem reads as follows: Find \\\\(u_h\\\\in V_h\\\\) such that for all \\\\(i=1,\\\\dots,N\\\\) it holds:       \\n\\\\begin{align*}\\n F(u_h)\\n \\\\dealcoloneq\\n \\\\int_\\\\Omega \\\\nabla \\\\varphi_i \\\\cdot \\\\nabla u_h \\\\,\\\\mathrm{d}x\\n -\\n \\\\int_\\\\Omega \\\\varphi_i \\\\exp(u_h) \\\\,\\\\mathrm{d}x \\\\stackrel{!}{=} 0.\\n\\\\end{align*}\\n\\n As each finite element function is a linear combination of the basis functions \\\\(\\\\{\\\\varphi_i\\\\}_{i=1,\\\\dots,N}\\\\), we can identify the finite element solution by a vector from \\\\(\\\\mathbb{R}^N\\\\) consisting of the unknown values in each degree of freedom (DOF). Thus, we define the nonlinear function \\\\(F\\\\colon\\\\mathbb{R}^N\\\\to\\\\mathbb{R}^N\\\\) representing the discrete nonlinear problem.\\nTo solve this nonlinear problem we use Newton's method. So given an initial guess \\\\(u_h^0\\\\in V_h\\\\), which already fulfills the Dirichlet boundary condition, we determine a sequence of Newton steps \\\\(\\\\bigl( u_h^n \\\\bigr)_n\\\\) by successively applying the following scheme:    \\n\\\\begin{align*}\\n &\\\\text{Solve for } s_h^n\\\\in V_h: \\\\quad & F'(u_h^n)[s_h^n] &= -F(u_h^n),\\\\\\\\\\n &\\\\text{Update: }                       & u_h^{n+1} &= u_h^n + s_h^n.\\n\\\\end{align*}\\n\\n So in each Newton step we have to solve a linear problem \\\\(A\\\\,x = b\\\\), where the system matrix \\\\(A\\\\) is represented by the Jacobian \\\\(F'(u_h^n)[\\\\,\\\\cdot\\\\,]\\\\colon\\\\mathbb{R}^N\\\\to\\\\mathbb{R}^N\\\\) and the right hand side \\\\(b\\\\) by the negative residual \\\\(-F(u_h^n)\\\\). The solution vector \\\\(x\\\\) is in that case the Newton update of the \\\\(n\\\\)-th Newton step. Note, that we assume an initial guess \\\\(u_h^0\\\\), which already fulfills the Dirichlet boundary conditions of the problem formulation (in fact this could also be an inhomogeneous Dirichlet boundary condition) and thus the Newton updates \\\\(s_h\\\\) satisfy a homogeneous Dirichlet condition.\\nUntil now we only tested with the basis functions, however, we can also represent any function of \\\\(V_h\\\\) as linear combination of basis functions. More mathematically this means, that every element of \\\\(V_h\\\\) can be identified with a vector \\\\(U\\\\in\\\\mathbb{R}^N\\\\) via the representation formula: \\\\(u_h = \\\\sum_{i=1}^N U_i \\\\varphi_i\\\\). So using this we can give an expression for the discrete Jacobian and the residual:            \\n\\\\begin{align*}\\n A_{ij} = \\\\bigl( F'(u_h^n) \\\\bigr)_{ij}\\n &=\\n \\\\int_\\\\Omega \\\\nabla\\\\varphi_i \\\\cdot \\\\nabla \\\\varphi_j \\\\,\\\\mathrm{d} x\\n -\\n \\\\int_\\\\Omega \\\\varphi_i \\\\, \\\\exp( u_h^n ) \\\\varphi_j \\\\,\\\\mathrm{d} x,\\\\\\\\\\n b_{i} = \\\\bigl( F(u_h^n) \\\\bigr)_{i}\\n &=\\n \\\\int_\\\\Omega \\\\nabla\\\\varphi_i \\\\cdot \\\\nabla u_h^n \\\\,\\\\mathrm{d} x\\n -\\n \\\\int_\\\\Omega \\\\varphi_i \\\\, \\\\exp( u_h^n ) \\\\,\\\\mathrm{d} x.\\n\\\\end{align*}\\n\\n Compared to step-15 we could also have formed the Fr\\u00e9chet derivative of the nonlinear function corresponding to the strong formulation of the problem and discretized it afterwards. However, in the end we would get the same set of discrete equations.\\nNumerical linear algebra\\nNote, how the system matrix, actually the Jacobian, depends on the previous Newton step \\\\(A = F'(u^n)\\\\). Hence we need to tell the function that computes the system matrix about the solution at the last Newton step. In an implementation with a classical assemble_system() function we would gather this information from the last Newton step during assembly by the use of the member functions FEValuesBase::get_function_values() and FEValuesBase::get_function_gradients(). This is how step-15, for example, does things. The assemble_system() function would then look like: template <int dim>\\nvoid GelfandProblem<dim>::assemble_system()\\n{\\n  system_matrix = 0;\\n  system_rhs    = 0;\\n \\n const QGauss<dim> quadrature_formula(fe.degree + 1);\\n FEValues<dim>     fe_values(fe,\\n                          quadrature_formula,\\n update_values | update_gradients | update_JxW_values);\\n \\n const unsigned int n_q_points    = fe_values.n_quadrature_points;\\n const unsigned int dofs_per_cell = fe_values.dofs_per_cell;\\n \\n FullMatrix<double>                   cell_matrix(dofs_per_cell);\\n Vector<double>                       cell_rhs(dofs_per_cell);\\n  std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\\n \\n  std::vector<Tensor<1, dim>> newton_step_gradients(n_q_points);\\n  std::vector<double>         newton_step_values(n_q_points);\\n \\n \\n for (const auto &cell : dof_handler.active_cell_iterators())\\n    {\\n      cell_matrix = 0.0;\\n      cell_rhs    = 0.0;\\n \\n      fe_values.reinit(cell);\\n \\n      fe_values.get_function_values(solution, newton_step_values);\\n      fe_values.get_function_gradients(solution, newton_step_gradients);\\n \\n for (unsigned int q = 0; q < n_q_points; ++q)\\n        {\\n const double nonlinearity = std::exp(newton_step_values[q]);\\n const double dx           = fe_values.JxW(q);\\n \\n for (unsigned int i = 0; i < dofs_per_cell; ++i)\\n            {\\n const double         phi_i      = fe_values.shape_value(i, q);\\n const Tensor<1, dim> grad_phi_i = fe_values.shape_grad(i, q);\\n \\n for (unsigned int j = 0; j < dofs_per_cell; ++j)\\n                {\\n const double         phi_j      = fe_values.shape_value(j, q);\\n const Tensor<1, dim> grad_phi_j = fe_values.shape_grad(j, q);\\n \\n                  cell_matrix(i, j) +=\\n                    (grad_phi_i * grad_phi_j - phi_i * nonlinearity * phi_j) *\\n                    dx;\\n                }\\n \\n              cell_rhs(i) += (-grad_phi_i * newton_step_gradients[q] +\\n                              phi_i * nonlinearity) *\\n                             dx;\\n            }\\n        }\\n \\n      cell->get_dof_indices(local_dof_indices);\\n \\n      constraints.distribute_local_to_global(\\n        cell_matrix, cell_rhs, local_dof_indices, system_matrix, system_rhs);\\n    }\\n}\\nFEValuesDefinition fe_values.h:63\\nFullMatrixDefinition full_matrix.h:79\\nQGaussDefinition quadrature_lib.h:40\\nTensorDefinition tensor.h:471\\nVectorDefinition vector.h:120\\nupdate_values@ update_valuesShape function values.Definition fe_update_flags.h:75\\nupdate_JxW_values@ update_JxW_valuesTransformed quadrature weights.Definition fe_update_flags.h:134\\nupdate_gradients@ update_gradientsShape function gradients.Definition fe_update_flags.h:81\\nstd::exp::VectorizedArray< Number, width > exp(const ::VectorizedArray< Number, width > &)Definition vectorization.h:6829\\nSince we want to solve this problem without storing a matrix, we need to tell the matrix-free operator this information before we use it. Therefore in the derived class JacobianOperator we will implement a function called evaluate_newton_step, which will process the information of the last Newton step prior to the usage of the matrix-vector implementation. Furthermore we want to use a geometric multigrid (GMG) preconditioner for the linear solver, so in order to apply the multilevel operators we need to pass the last Newton step also to these operators. This is kind of a tricky task, since the vector containing the last Newton step has to be interpolated to all levels of the triangulation. In the code this task will be done by the function MGTransferMatrixFree::interpolate_to_mg(). Note, a fundamental difference to the previous cases, where we set up and used a geometric multigrid preconditioner, is the fact, that we can reuse the MGTransferMatrixFree object for the computation of all Newton steps. So we can save some work here by defining a class variable and using an already set up MGTransferMatrixFree object mg_transfer that was initialized in the setup_system() function. template <int dim, int fe_degree>\\nvoid GelfandProblem<dim, fe_degree>::compute_update()\\n{\\n TimerOutput::Scope t(computing_timer, \\\"compute update\\\");\\n \\n  solution.update_ghost_values();\\n \\n  system_matrix.evaluate_newton_step(solution);\\n \\n  mg_transfer.interpolate_to_mg(dof_handler, mg_solution, solution);\\n \\n \\n // Set up options for the multilevel preconditioner\\n // ...\\n \\n for (unsigned int level = 0; level < triangulation.n_global_levels(); ++level)\\n    {\\n      mg_matrices[level].evaluate_newton_step(mg_solution[level]);\\n    }\\n \\n // Define the actual preconditioner\\n // ...\\n \\n // Solve the linear system\\n // ...\\n}\\nTimerOutput::ScopeDefinition timer.h:557\\nparallel::TriangulationBase::n_global_levelsvirtual unsigned int n_global_levels() const overrideDefinition tria_base.cc:141\\nlevelunsigned int levelDefinition grid_out.cc:4626\\ntriangulationconst ::parallel::distributed::Triangulation< dim, spacedim > * triangulationDefinition p4est_wrappers.cc:68\\nThe function evaluating the nonlinearity works basically in the same way as the function evaluate_coefficient from step-37 evaluating a coefficient function. The idea is to use an FEEvaluation object to evaluate the Newton step and store the expression in a table for all cells and all quadrature points: template <int dim, int fe_degree, typename number>\\nvoid JacobianOperator<dim, fe_degree, number>::evaluate_newton_step(\\n const LinearAlgebra::distributed::Vector<number> &newton_step)\\n{\\n const unsigned int n_cells = this->data->n_cell_batches();\\n \\n FEEvaluation<dim, fe_degree, fe_degree + 1, 1, number> phi(*this->data);\\n \\n  nonlinear_values.reinit(n_cells, phi.n_q_points);\\n \\n for (unsigned int cell = 0; cell < n_cells; ++cell)\\n    {\\n      phi.reinit(cell);\\n      phi.read_dof_values_plain(newton_step);\\n      phi.evaluate(EvaluationFlags::values);\\n \\n for (const unsigned int q : phi.quadrature_point_indices())\\n        {\\n          nonlinear_values(cell, q) = std::exp(phi.get_value(q));\\n        }\\n    }\\n}\\nFEEvaluationDefinition fe_evaluation.h:1355\\nLinearAlgebra::distributed::VectorDefinition la_parallel_vector.h:250\\nEvaluationFlags::values@ valuesDefinition evaluation_flags.h:50\\nTriangulation\\nAs said in step-37, the matrix-free method gets more efficient if we choose a higher order finite element space. Since we want to solve the problem on the \\\\(d\\\\)-dimensional unit ball, it would be good to have an appropriate boundary approximation to overcome convergence issues. For this reason we use an isoparametric approach with the MappingQ class to recover the smooth boundary as well as the mapping for inner cells. In addition, to get a good triangulation in total we make use of the TransfiniteInterpolationManifold.\\n The commented program\\nFirst we include the typical headers of the deal.II library needed for this tutorial:\\n\\u00a0 #include <deal.II/base/function.h>\\n\\u00a0 #include <deal.II/base/quadrature_lib.h>\\n\\u00a0 #include <deal.II/base/timer.h>\\n\\u00a0 #include <deal.II/base/vectorization.h>\\n\\u00a0 \\n\\u00a0 #include <deal.II/dofs/dof_accessor.h>\\n\\u00a0 #include <deal.II/dofs/dof_handler.h>\\n\\u00a0 #include <deal.II/dofs/dof_tools.h>\\n\\u00a0 \\n\\u00a0 #include <deal.II/fe/fe_q.h>\\n\\u00a0 #include <deal.II/fe/mapping_q.h>\\n\\u00a0 \\n\\u00a0 #include <deal.II/grid/grid_generator.h>\\n\\u00a0 #include <deal.II/grid/grid_out.h>\\n\\u00a0 #include <deal.II/grid/manifold_lib.h>\\n\\u00a0 #include <deal.II/grid/tria.h>\\n\\u00a0 #include <deal.II/grid/tria_accessor.h>\\n\\u00a0 #include <deal.II/grid/tria_iterator.h>\\n\\u00a0 \\n\\u00a0 #include <deal.II/lac/affine_constraints.h>\\n\\u00a0 #include <deal.II/lac/precondition.h>\\n\\u00a0 #include <deal.II/lac/solver_cg.h>\\n\\u00a0 #include <deal.II/lac/vector.h>\\n\\u00a0 \\n\\u00a0 #include <deal.II/numerics/data_out.h>\\n\\u00a0 #include <deal.II/numerics/vector_tools.h>\\n\\u00a0 \\nIn particular, we need to include the headers for the matrix-free framework:\\n\\u00a0 #include <deal.II/matrix_free/fe_evaluation.h>\\n\\u00a0 #include <deal.II/matrix_free/matrix_free.h>\\n\\u00a0 #include <deal.II/matrix_free/operators.h>\\n\\u00a0 #include <deal.II/matrix_free/tools.h>\\n\\u00a0 \\nAnd since we want to use a geometric multigrid preconditioner, we need also the multilevel headers:\\n\\u00a0 #include <deal.II/multigrid/mg_coarse.h>\\n\\u00a0 #include <deal.II/multigrid/mg_constrained_dofs.h>\\n\\u00a0 #include <deal.II/multigrid/mg_matrix.h>\\n\\u00a0 #include <deal.II/multigrid/mg_smoother.h>\\n\\u00a0 #include <deal.II/multigrid/mg_tools.h>\\n\\u00a0 #include <deal.II/multigrid/mg_transfer_matrix_free.h>\\n\\u00a0 #include <deal.II/multigrid/multigrid.h>\\n\\u00a0 \\n\\u00a0 \\nFinally some common C++ headers for in and output:\\n\\u00a0 #include <fstream>\\n\\u00a0 #include <iostream>\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0 namespace Step66\\n\\u00a0 {\\n\\u00a0   using namespace dealii;\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\ndealiiDefinition namespace_dealii.h:25\\n Matrix-free JacobianOperator\\nIn the beginning we define the matrix-free operator for the Jacobian. As a guideline we follow the tutorials step-37 and step-48, where the precise interface of the MatrixFreeOperators::Base class was extensively documented.\\nSince we want to use the Jacobian as system matrix and pass it to the linear solver as well as to the multilevel preconditioner classes, we derive the JacobianOperator class from the MatrixFreeOperators::Base class, such that we have already the right interface. The two functions we need to override from the base class are the MatrixFreeOperators::Base::apply_add() and the MatrixFreeOperators::Base::compute_diagonal() function. To allow preconditioning with float precision we define the number type as template argument.\\nAs mentioned already in the introduction, we need to evaluate the Jacobian \\\\(F'\\\\) at the last Newton step \\\\(u_h^n\\\\) for the computation of the Newton update \\\\(s_h^n\\\\). To get the information of the last Newton step \\\\(u_h^n\\\\) we do pretty much the same as in step-37, where we stored the values of a coefficient function in a table nonlinear_values once before we use the matrix-free operator. Instead of a function evaluate_coefficient(), we here implement a function evaluate_newton_step().\\nAs additional private member functions of the JacobianOperator we implement the local_apply() and the local_compute_diagonal() function. The first one is the actual worker function for the matrix-vector application, which we pass to the MatrixFree::cell_loop() in the apply_add() function. The later one is the worker function to compute the diagonal, which we pass to the MatrixFreeTools::compute_diagonal() function.\\nFor better readability of the source code we further define an alias for the FEEvaluation object.\\n\\u00a0   template <int dim, int fe_degree, typename number>\\n\\u00a0   class JacobianOperator\\n\\u00a0     : public MatrixFreeOperators::\\n\\u00a0         Base<dim, LinearAlgebra::distributed::Vector<number>>\\n\\u00a0   {\\n\\u00a0   public:\\n\\u00a0     using value_type = number;\\n\\u00a0 \\n\\u00a0     using FECellIntegrator =\\n\\u00a0       FEEvaluation<dim, fe_degree, fe_degree + 1, 1, number>;\\n\\u00a0 \\n\\u00a0     JacobianOperator();\\n\\u00a0 \\n\\u00a0     virtual void clear() override;\\n\\u00a0 \\n\\u00a0     void evaluate_newton_step(\\n\\u00a0       const LinearAlgebra::distributed::Vector<number> &newton_step);\\n\\u00a0 \\n\\u00a0     virtual void compute_diagonal() override;\\n\\u00a0 \\n\\u00a0   private:\\n\\u00a0     virtual void apply_add(\\n\\u00a0       LinearAlgebra::distributed::Vector<number>       &dst,\\n\\u00a0       const LinearAlgebra::distributed::Vector<number> &src) const override;\\n\\u00a0 \\n\\u00a0     void\\n\\u00a0     local_apply(const MatrixFree<dim, number>                    &data,\\n\\u00a0                 LinearAlgebra::distributed::Vector<number>       &dst,\\n\\u00a0                 const LinearAlgebra::distributed::Vector<number> &src,\\n\\u00a0                 const std::pair<unsigned int, unsigned int> &cell_range) const;\\n\\u00a0 \\n\\u00a0     void local_compute_diagonal(FECellIntegrator &integrator) const;\\n\\u00a0 \\n\\u00a0     Table<2, VectorizedArray<number>> nonlinear_values;\\n\\u00a0   };\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nMatrixFreeDefinition matrix_free.h:113\\nTableDefinition array_view.h:39\\nMatrixFreeOperatorsDefinition operators.h:41\\nThe constructor of the JacobianOperator just calls the constructor of the base class MatrixFreeOperators::Base, which is itself derived from the Subscriptor class.\\n\\u00a0   template <int dim, int fe_degree, typename number>\\n\\u00a0   JacobianOperator<dim, fe_degree, number>::JacobianOperator()\\n\\u00a0     : MatrixFreeOperators::Base<dim,\\n\\u00a0                                 LinearAlgebra::distributed::Vector<number>>()\\n\\u00a0   {}\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nLinearAlgebraDefinition template_constraints.h:615\\nThe clear() function resets the table holding the values for the nonlinearity and call the clear() function of the base class.\\n\\u00a0   template <int dim, int fe_degree, typename number>\\n\\u00a0   void JacobianOperator<dim, fe_degree, number>::clear()\\n\\u00a0   {\\n\\u00a0     nonlinear_values.reinit(0, 0);\\n\\u00a0     MatrixFreeOperators::Base<dim, LinearAlgebra::distributed::Vector<number>>::\\n\\u00a0       clear();\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nMatrixFreeOperators::BaseDefinition operators.h:188\\n Evaluation of the old Newton step\\nThe following evaluate_newton_step() function is based on the evaluate_coefficient() function from step-37. However, it does not evaluate a function object, but evaluates a vector representing a finite element function, namely the last Newton step needed for the Jacobian. Therefore we set up a FEEvaluation object and evaluate the finite element function in the quadrature points with the FEEvaluation::read_dof_values_plain() and FEEvaluation::evaluate() functions. We store the evaluated values of the finite element function directly in the nonlinear_values table.\\nThis will work well and in the local_apply() function we can use the values stored in the table to apply the matrix-vector product. However, we can also optimize the implementation of the Jacobian at this stage. We can directly evaluate the nonlinear function std::exp(newton_step[q]) and store these values in the table. This skips all evaluations of the nonlinearity in each call of the vmult() function.\\nNote that we need to manually call the functions to exchange the ghost data here, by calling LinearAlgebra::distributed::Vector::update_ghost_values(), to ensure all data from neighboring processes is available for evaluating the finite-element interpolation on cells. In the other functions of this tutorial program, MatrixFree::cell_loop() made sure to call this function. Note that we clear the ghost state again at the end of the function, in order to avoid mixing ghosted and non-ghosted vectors in other parts of the solver.\\n\\u00a0   template <int dim, int fe_degree, typename number>\\n\\u00a0   void JacobianOperator<dim, fe_degree, number>::evaluate_newton_step(\\n\\u00a0     const LinearAlgebra::distributed::Vector<number> &newton_step)\\n\\u00a0   {\\n\\u00a0     const unsigned int n_cells = this->data->n_cell_batches();\\n\\u00a0     FECellIntegrator   phi(*this->data);\\n\\u00a0 \\n\\u00a0     newton_step.update_ghost_values();\\n\\u00a0 \\n\\u00a0     nonlinear_values.reinit(n_cells, phi.n_q_points);\\n\\u00a0 \\n\\u00a0     for (unsigned int cell = 0; cell < n_cells; ++cell)\\n\\u00a0       {\\n\\u00a0         phi.reinit(cell);\\n\\u00a0         phi.read_dof_values_plain(newton_step);\\n\\u00a0         phi.evaluate(EvaluationFlags::values);\\n\\u00a0 \\n\\u00a0         for (const unsigned int q : phi.quadrature_point_indices())\\n\\u00a0           {\\n\\u00a0             nonlinear_values(cell, q) = std::exp(phi.get_value(q));\\n\\u00a0           }\\n\\u00a0       }\\n\\u00a0     newton_step.zero_out_ghost_values();\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nstdSTL namespace.\\n Nonlinear matrix-free operator application\\nNow in the local_apply() function, which actually implements the cell wise action of the system matrix, we can use the information of the last Newton step stored in the table nonlinear_values. The rest of this function is basically the same as in step-37. We set up the FEEvaluation object, gather and evaluate the values and gradients of the input vector src, submit the values and gradients according to the form of the Jacobian and finally call FEEvaluation::integrate_scatter() to perform the cell integration and distribute the local contributions into the global vector  dst.\\n\\u00a0   template <int dim, int fe_degree, typename number>\\n\\u00a0   void JacobianOperator<dim, fe_degree, number>::local_apply(\\n\\u00a0     const MatrixFree<dim, number>                    &data,\\n\\u00a0     LinearAlgebra::distributed::Vector<number>       &dst,\\n\\u00a0     const LinearAlgebra::distributed::Vector<number> &src,\\n\\u00a0     const std::pair<unsigned int, unsigned int>      &cell_range) const\\n\\u00a0   {\\n\\u00a0     FECellIntegrator phi(data);\\n\\u00a0 \\n\\u00a0     for (unsigned int cell = cell_range.first; cell < cell_range.second; ++cell)\\n\\u00a0       {\\n\\u00a0         AssertDimension(nonlinear_values.size(0),\\n\\u00a0                         phi.get_matrix_free().n_cell_batches());\\n\\u00a0         AssertDimension(nonlinear_values.size(1), phi.n_q_points);\\n\\u00a0 \\n\\u00a0 \\n\\u00a0         phi.reinit(cell);\\n\\u00a0 \\n\\u00a0         phi.gather_evaluate(src,\\n\\u00a0                             EvaluationFlags::values |\\n\\u00a0                               EvaluationFlags::gradients);\\n\\u00a0 \\n\\u00a0         for (const unsigned int q : phi.quadrature_point_indices())\\n\\u00a0           {\\n\\u00a0             phi.submit_value(-nonlinear_values(cell, q) * phi.get_value(q), q);\\n\\u00a0             phi.submit_gradient(phi.get_gradient(q), q);\\n\\u00a0           }\\n\\u00a0 \\n\\u00a0         phi.integrate_scatter(EvaluationFlags::values |\\n\\u00a0                                 EvaluationFlags::gradients,\\n\\u00a0                               dst);\\n\\u00a0       }\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nAssertDimension#define AssertDimension(dim1, dim2)Definition exceptions.h:1985\\nEvaluationFlags::gradients@ gradientsDefinition evaluation_flags.h:54\\nNext we use MatrixFree::cell_loop() to perform the actual loop over all cells computing the cell contribution to the matrix-vector product.\\n\\u00a0   template <int dim, int fe_degree, typename number>\\n\\u00a0   void JacobianOperator<dim, fe_degree, number>::apply_add(\\n\\u00a0     LinearAlgebra::distributed::Vector<number>       &dst,\\n\\u00a0     const LinearAlgebra::distributed::Vector<number> &src) const\\n\\u00a0   {\\n\\u00a0     this->data->cell_loop(&JacobianOperator::local_apply, this, dst, src);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n Diagonal of the JacobianOperator\\nThe internal worker function local_compute_diagonal() for the computation of the diagonal is similar to the above worker function local_apply(). However, as major difference we do not read values from a input vector or distribute any local results to an output vector. Instead the only input argument is the used FEEvaluation object.\\n\\u00a0   template <int dim, int fe_degree, typename number>\\n\\u00a0   void JacobianOperator<dim, fe_degree, number>::local_compute_diagonal(\\n\\u00a0     FECellIntegrator &phi) const\\n\\u00a0   {\\n\\u00a0     AssertDimension(nonlinear_values.size(0),\\n\\u00a0                     phi.get_matrix_free().n_cell_batches());\\n\\u00a0     AssertDimension(nonlinear_values.size(1), phi.n_q_points);\\n\\u00a0 \\n\\u00a0     const unsigned int cell = phi.get_current_cell_index();\\n\\u00a0 \\n\\u00a0     phi.evaluate(EvaluationFlags::values | EvaluationFlags::gradients);\\n\\u00a0 \\n\\u00a0     for (const unsigned int q : phi.quadrature_point_indices())\\n\\u00a0       {\\n\\u00a0         phi.submit_value(-nonlinear_values(cell, q) * phi.get_value(q), q);\\n\\u00a0         phi.submit_gradient(phi.get_gradient(q), q);\\n\\u00a0       }\\n\\u00a0 \\n\\u00a0     phi.integrate(EvaluationFlags::values | EvaluationFlags::gradients);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nFinally we override the MatrixFreeOperators::Base::compute_diagonal() function of the base class of the JacobianOperator. Although the name of the function suggests just the computation of the diagonal, this function does a bit more. Because we only really need the inverse of the matrix diagonal elements for the Chebyshev smoother of the multigrid preconditioner, we compute the diagonal and store the inverse elements. Therefore we first initialize the inverse_diagonal_entries. Then we compute the diagonal by passing the worker function local_compute_diagonal() to the MatrixFreeTools::compute_diagonal() function. In the end we loop over the diagonal and invert the elements by hand. Note, that during this loop we catch the constrained DOFs and set them manually to one.\\n\\u00a0   template <int dim, int fe_degree, typename number>\\n\\u00a0   void JacobianOperator<dim, fe_degree, number>::compute_diagonal()\\n\\u00a0   {\\n\\u00a0     this->inverse_diagonal_entries.reset(\\n\\u00a0       new DiagonalMatrix<LinearAlgebra::distributed::Vector<number>>());\\n\\u00a0     LinearAlgebra::distributed::Vector<number> &inverse_diagonal =\\n\\u00a0       this->inverse_diagonal_entries->get_vector();\\n\\u00a0     this->data->initialize_dof_vector(inverse_diagonal);\\n\\u00a0 \\n\\u00a0     MatrixFreeTools::compute_diagonal(*this->data,\\n\\u00a0                                       inverse_diagonal,\\n\\u00a0                                       &JacobianOperator::local_compute_diagonal,\\n\\u00a0                                       this);\\n\\u00a0 \\n\\u00a0     for (auto &diagonal_element : inverse_diagonal)\\n\\u00a0       {\\n\\u00a0         diagonal_element = (std::abs(diagonal_element) > 1.0e-10) ?\\n\\u00a0                              (1.0 / diagonal_element) :\\n\\u00a0                              1.0;\\n\\u00a0       }\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nDiagonalMatrixDefinition diagonal_matrix.h:62\\nMatrixFreeTools::compute_diagonalvoid compute_diagonal(const MatrixFree< dim, Number, VectorizedArrayType > &matrix_free, VectorType &diagonal_global, const std::function< void(FEEvaluation< dim, fe_degree, n_q_points_1d, n_components, Number, VectorizedArrayType > &)> &cell_operation, const unsigned int dof_no=0, const unsigned int quad_no=0, const unsigned int first_selected_component=0)\\n GelfandProblem class\\nAfter implementing the matrix-free operators we can now define the solver class for the Gelfand problem. This class is based on the common structure of all previous tutorial programs, in particular it is based on step-15, solving also a nonlinear problem. Since we are using the matrix-free framework, we no longer need an assemble_system function any more, instead the information of the matrix is rebuilt in every call of the vmult() function. However, for the application of the Newton scheme we need to assemble the right hand side of the linearized problems and compute the residuals. Therefore, we implement an additional function evaluate_residual(), which we later call in the assemble_rhs() and the compute_residual() function. Finally, the typical solve() function here implements the Newton method, whereas the solution of the linearized system is computed in the function compute_update(). As the MatrixFree framework handles the polynomial degree of the Lagrangian finite element method as a template parameter, we declare it also as a template parameter for the problem solver class.\\n\\u00a0   template <int dim, int fe_degree>\\n\\u00a0   class GelfandProblem\\n\\u00a0   {\\n\\u00a0   public:\\n\\u00a0     GelfandProblem();\\n\\u00a0 \\n\\u00a0     void run();\\n\\u00a0 \\n\\u00a0   private:\\n\\u00a0     void make_grid();\\n\\u00a0 \\n\\u00a0     void setup_system();\\n\\u00a0 \\n\\u00a0     void evaluate_residual(\\n\\u00a0       LinearAlgebra::distributed::Vector<double>       &dst,\\n\\u00a0       const LinearAlgebra::distributed::Vector<double> &src) const;\\n\\u00a0 \\n\\u00a0     void local_evaluate_residual(\\n\\u00a0       const MatrixFree<dim, double>                    &data,\\n\\u00a0       LinearAlgebra::distributed::Vector<double>       &dst,\\n\\u00a0       const LinearAlgebra::distributed::Vector<double> &src,\\n\\u00a0       const std::pair<unsigned int, unsigned int>      &cell_range) const;\\n\\u00a0 \\n\\u00a0     void assemble_rhs();\\n\\u00a0 \\n\\u00a0     double compute_residual(const double alpha);\\n\\u00a0 \\n\\u00a0     void compute_update();\\n\\u00a0 \\n\\u00a0     void solve();\\n\\u00a0 \\n\\u00a0     double compute_solution_norm() const;\\n\\u00a0 \\n\\u00a0     void output_results(const unsigned int cycle) const;\\n\\u00a0 \\n\\u00a0 \\nFor the parallel computation we define a parallel::distributed::Triangulation. As the computational domain is a circle in 2d and a ball in 3d, we assign in addition to the SphericalManifold for boundary cells a TransfiniteInterpolationManifold object for the mapping of the inner cells, which takes care of the inner cells. In this example we use an isoparametric finite element approach and thus use the MappingQ class. For further details you may read the detailed description of this class.\\n\\u00a0     parallel::distributed::Triangulation<dim> triangulation;\\n\\u00a0     const MappingQ<dim>                       mapping;\\n\\u00a0 \\n\\u00a0 \\nMappingQDefinition mapping_q.h:110\\nparallel::distributed::TriangulationDefinition tria.h:268\\nAs usual we then define the Lagrangian finite elements FE_Q and a DoFHandler.\\n\\u00a0     const FE_Q<dim> fe;\\n\\u00a0     DoFHandler<dim> dof_handler;\\n\\u00a0 \\n\\u00a0 \\nDoFHandlerDefinition dof_handler.h:317\\nFE_QDefinition fe_q.h:554\\nFor the linearized discrete system we define an AffineConstraints objects and the system_matrix, which is in this example represented as a matrix-free operator.\\n\\u00a0     AffineConstraints<double> constraints;\\n\\u00a0     using SystemMatrixType = JacobianOperator<dim, fe_degree, double>;\\n\\u00a0     SystemMatrixType system_matrix;\\n\\u00a0 \\n\\u00a0 \\nAffineConstraintsDefinition affine_constraints.h:507\\nThe multilevel object is also based on the matrix-free operator for the Jacobian. Since we need to evaluate the Jacobian with the last Newton step, we also need to evaluate the level operator with the last Newton step for the preconditioner. Thus in addition to mg_matrices, we also need a MGLevelObject to store the interpolated solution vector on each level. As in step-37 we use float precision for the preconditioner. Moreover, we define the MGTransferMatrixFree object as a class variable, since we need to set it up only once when the triangulation has changed and can then use it again in each Newton step.\\n\\u00a0     MGConstrainedDoFs mg_constrained_dofs;\\n\\u00a0     using LevelMatrixType = JacobianOperator<dim, fe_degree, float>;\\n\\u00a0     MGLevelObject<LevelMatrixType>                           mg_matrices;\\n\\u00a0     MGLevelObject<LinearAlgebra::distributed::Vector<float>> mg_solution;\\n\\u00a0     MGTransferMatrixFree<dim, float>                         mg_transfer;\\n\\u00a0 \\n\\u00a0 \\nMGConstrainedDoFsDefinition mg_constrained_dofs.h:45\\nMGLevelObjectDefinition mg_level_object.h:49\\nMGTransferMatrixFreeDefinition mg_transfer_matrix_free.h:57\\nOf course we also need vectors holding the solution, the newton_update and the system_rhs. In that way we can always store the last Newton step in the solution vector and just add the update to get the next Newton step.\\n\\u00a0     LinearAlgebra::distributed::Vector<double> solution;\\n\\u00a0     LinearAlgebra::distributed::Vector<double> newton_update;\\n\\u00a0     LinearAlgebra::distributed::Vector<double> system_rhs;\\n\\u00a0 \\n\\u00a0 \\nFinally we have a variable for the number of iterations of the linear solver.\\n\\u00a0     unsigned int linear_iterations;\\n\\u00a0 \\n\\u00a0 \\nFor the output in programs running in parallel with MPI, we use the ConditionalOStream class to avoid multiple output of the same data by different MPI ranks.\\n\\u00a0     ConditionalOStream pcout;\\n\\u00a0 \\n\\u00a0 \\nConditionalOStreamDefinition conditional_ostream.h:80\\nFinally for the time measurement we use a TimerOutput object, which prints the elapsed CPU and wall times for each function in a nicely formatted table after the program has finished.\\n\\u00a0     TimerOutput computing_timer;\\n\\u00a0   };\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nTimerOutputDefinition timer.h:549\\nThe constructor of the GelfandProblem initializes the class variables. In particular, we set up the multilevel support for the parallel::distributed::Triangulation, set the mapping degree equal to the finite element degree, initialize the ConditionalOStream and tell the TimerOutput that we want to see the wall times only on demand.\\n\\u00a0   template <int dim, int fe_degree>\\n\\u00a0   GelfandProblem<dim, fe_degree>::GelfandProblem()\\n\\u00a0     : triangulation(MPI_COMM_WORLD,\\n\\u00a0                     Triangulation<dim>::limit_level_difference_at_vertices,\\n\\u00a0                     parallel::distributed::Triangulation<\\n\\u00a0                       dim>::construct_multigrid_hierarchy)\\n\\u00a0     , mapping(fe_degree)\\n\\u00a0     , fe(fe_degree)\\n\\u00a0     , dof_handler(triangulation)\\n\\u00a0     , pcout(std::cout, Utilities::MPI::this_mpi_process(MPI_COMM_WORLD) == 0)\\n\\u00a0     , computing_timer(MPI_COMM_WORLD,\\n\\u00a0                       pcout,\\n\\u00a0                       TimerOutput::never,\\n\\u00a0                       TimerOutput::wall_times)\\n\\u00a0   {}\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nTriangulationDefinition tria.h:1323\\nInitializeLibrary::MPI@ MPI\\nUtilitiesDefinition communication_pattern_base.h:30\\nparallelDefinition distributed.h:424\\n GelfandProblem::make_grid\\nAs the computational domain we use the dim-dimensional unit ball. We follow the instructions for the TransfiniteInterpolationManifold class and also assign a SphericalManifold for the boundary. Finally, we refine the initial mesh 3 - dim times globally.\\n\\u00a0   template <int dim, int fe_degree>\\n\\u00a0   void GelfandProblem<dim, fe_degree>::make_grid()\\n\\u00a0   {\\n\\u00a0     TimerOutput::Scope t(computing_timer, \\\"make grid\\\");\\n\\u00a0 \\n\\u00a0     SphericalManifold<dim>                boundary_manifold;\\n\\u00a0     TransfiniteInterpolationManifold<dim> inner_manifold;\\n\\u00a0 \\n\\u00a0     GridGenerator::hyper_ball(triangulation);\\n\\u00a0 \\n\\u00a0     triangulation.set_all_manifold_ids(1);\\n\\u00a0     triangulation.set_all_manifold_ids_on_boundary(0);\\n\\u00a0 \\n\\u00a0     triangulation.set_manifold(0, boundary_manifold);\\n\\u00a0 \\n\\u00a0     inner_manifold.initialize(triangulation);\\n\\u00a0     triangulation.set_manifold(1, inner_manifold);\\n\\u00a0 \\n\\u00a0     triangulation.refine_global(3 - dim);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nSphericalManifoldDefinition manifold_lib.h:263\\nTransfiniteInterpolationManifoldDefinition manifold_lib.h:1057\\nTriangulation::refine_globalvoid refine_global(const unsigned int times=1)\\nTriangulation::set_all_manifold_ids_on_boundaryvoid set_all_manifold_ids_on_boundary(const types::manifold_id number)\\nTriangulation::set_manifoldvoid set_manifold(const types::manifold_id number, const Manifold< dim, spacedim > &manifold_object)\\nTriangulation::set_all_manifold_idsvoid set_all_manifold_ids(const types::manifold_id number)\\nGridGenerator::hyper_ballvoid hyper_ball(Triangulation< dim > &tria, const Point< dim > &center=Point< dim >(), const double radius=1., const bool attach_spherical_manifold_on_boundary_cells=false)\\n GelfandProblem::setup_system\\nThe setup_system() function is quasi identical to the one in step-37. The only differences are obviously the time measurement with only one TimerOutput::Scope instead of measuring each part individually, and more importantly the initialization of the MGLevelObject for the interpolated solution vector of the previous Newton step. Another important change is the setup of the MGTransferMatrixFree object, which we can reuse in each Newton step as the triangulation will not be not changed.\\nNote how we can use the same MatrixFree object twice, for the JacobianOperator and the multigrid preconditioner.\\n\\u00a0   template <int dim, int fe_degree>\\n\\u00a0   void GelfandProblem<dim, fe_degree>::setup_system()\\n\\u00a0   {\\n\\u00a0     TimerOutput::Scope t(computing_timer, \\\"setup system\\\");\\n\\u00a0 \\n\\u00a0     system_matrix.clear();\\n\\u00a0     mg_matrices.clear_elements();\\n\\u00a0 \\n\\u00a0     dof_handler.distribute_dofs(fe);\\n\\u00a0     dof_handler.distribute_mg_dofs();\\n\\u00a0 \\n\\u00a0     constraints.clear();\\n\\u00a0     constraints.reinit(dof_handler.locally_owned_dofs(),\\n\\u00a0                        DoFTools::extract_locally_relevant_dofs(dof_handler));\\n\\u00a0     DoFTools::make_hanging_node_constraints(dof_handler, constraints);\\n\\u00a0     VectorTools::interpolate_boundary_values(dof_handler,\\n\\u00a0                                              0,\\n\\u00a0                                              Functions::ZeroFunction<dim>(),\\n\\u00a0                                              constraints);\\n\\u00a0     constraints.close();\\n\\u00a0 \\n\\u00a0     {\\n\\u00a0       typename MatrixFree<dim, double>::AdditionalData additional_data;\\n\\u00a0       additional_data.tasks_parallel_scheme =\\n\\u00a0         MatrixFree<dim, double>::AdditionalData::partition_color;\\n\\u00a0       additional_data.mapping_update_flags =\\n\\u00a0         (update_values | update_gradients | update_JxW_values |\\n\\u00a0          update_quadrature_points);\\n\\u00a0       auto system_mf_storage = std::make_shared<MatrixFree<dim, double>>();\\n\\u00a0       system_mf_storage->reinit(mapping,\\n\\u00a0                                 dof_handler,\\n\\u00a0                                 constraints,\\n\\u00a0                                 QGauss<1>(fe.degree + 1),\\n\\u00a0                                 additional_data);\\n\\u00a0 \\n\\u00a0       system_matrix.initialize(system_mf_storage);\\n\\u00a0     }\\n\\u00a0 \\n\\u00a0     system_matrix.initialize_dof_vector(solution);\\n\\u00a0     system_matrix.initialize_dof_vector(newton_update);\\n\\u00a0     system_matrix.initialize_dof_vector(system_rhs);\\n\\u00a0 \\n\\u00a0 \\n\\u00a0     const unsigned int nlevels = triangulation.n_global_levels();\\n\\u00a0     mg_matrices.resize(0, nlevels - 1);\\n\\u00a0     mg_solution.resize(0, nlevels - 1);\\n\\u00a0 \\n\\u00a0     const std::set<types::boundary_id> dirichlet_boundary_ids = {0};\\n\\u00a0     mg_constrained_dofs.initialize(dof_handler);\\n\\u00a0     mg_constrained_dofs.make_zero_boundary_constraints(dof_handler,\\n\\u00a0                                                        dirichlet_boundary_ids);\\n\\u00a0 \\n\\u00a0     mg_transfer.initialize_constraints(mg_constrained_dofs);\\n\\u00a0     mg_transfer.build(dof_handler);\\n\\u00a0 \\n\\u00a0     for (unsigned int level = 0; level < nlevels; ++level)\\n\\u00a0       {\\n\\u00a0         AffineConstraints<double> level_constraints(\\n\\u00a0           dof_handler.locally_owned_mg_dofs(level),\\n\\u00a0           DoFTools::extract_locally_relevant_level_dofs(dof_handler, level));\\n\\u00a0 \\n\\u00a0         for (const types::global_dof_index dof_index :\\n\\u00a0              mg_constrained_dofs.get_boundary_indices(level))\\n\\u00a0           level_constraints.constrain_dof_to_zero(dof_index);\\n\\u00a0         level_constraints.close();\\n\\u00a0 \\n\\u00a0         typename MatrixFree<dim, float>::AdditionalData additional_data;\\n\\u00a0         additional_data.tasks_parallel_scheme =\\n\\u00a0           MatrixFree<dim, float>::AdditionalData::partition_color;\\n\\u00a0         additional_data.mapping_update_flags =\\n\\u00a0           (update_values | update_gradients | update_JxW_values |\\n\\u00a0            update_quadrature_points);\\n\\u00a0         additional_data.mg_level = level;\\n\\u00a0         auto mg_mf_storage_level = std::make_shared<MatrixFree<dim, float>>();\\n\\u00a0         mg_mf_storage_level->reinit(mapping,\\n\\u00a0                                     dof_handler,\\n\\u00a0                                     level_constraints,\\n\\u00a0                                     QGauss<1>(fe.degree + 1),\\n\\u00a0                                     additional_data);\\n\\u00a0 \\n\\u00a0         mg_matrices[level].initialize(mg_mf_storage_level,\\n\\u00a0                                       mg_constrained_dofs,\\n\\u00a0                                       level);\\n\\u00a0         mg_matrices[level].initialize_dof_vector(mg_solution[level]);\\n\\u00a0       }\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nFunctions::ZeroFunctionDefinition function.h:510\\nunsigned int\\nDoFTools::make_hanging_node_constraintsvoid make_hanging_node_constraints(const DoFHandler< dim, spacedim > &dof_handler, AffineConstraints< number > &constraints)Definition dof_tools_constraints.cc:3073\\nupdate_quadrature_points@ update_quadrature_pointsTransformed quadrature points.Definition fe_update_flags.h:127\\nDoFTools::extract_locally_relevant_dofsIndexSet extract_locally_relevant_dofs(const DoFHandler< dim, spacedim > &dof_handler)Definition dof_tools.cc:1164\\nDoFTools::extract_locally_relevant_level_dofsIndexSet extract_locally_relevant_level_dofs(const DoFHandler< dim, spacedim > &dof_handler, const unsigned int level)Definition dof_tools.cc:1212\\nVectorTools::interpolate_boundary_valuesvoid interpolate_boundary_values(const Mapping< dim, spacedim > &mapping, const DoFHandler< dim, spacedim > &dof, const std::map< types::boundary_id, const Function< spacedim, number > * > &function_map, std::map< types::global_dof_index, number > &boundary_values, const ComponentMask &component_mask={})\\nMatrixFree::AdditionalDataDefinition matrix_free.h:184\\nMatrixFree::AdditionalData::tasks_parallel_schemeTasksParallelScheme tasks_parallel_schemeDefinition matrix_free.h:347\\n GelfandProblem::evaluate_residual\\nNext we implement a function which evaluates the nonlinear discrete residual for a given input vector ( \\\\(\\\\texttt{dst} = F(\\\\texttt{src})\\\\)). This function is then used for the assembly of the right hand side of the linearized system and later for the computation of the residual of the next Newton step to check if we already reached the error tolerance. As this function should not affect any class variable we define it as a constant function. Internally we exploit the fast finite element evaluation through the FEEvaluation class and the MatrixFree::cell_loop(), similar to apply_add() function of the JacobianOperator.\\nFirst we create a pointer to the MatrixFree object, which is stored in the system_matrix. Then we pass the worker function local_evaluate_residual() for the cell wise evaluation of the residual together with the input and output vector to the MatrixFree::cell_loop(). In addition, we enable the zero out of the output vector in the loop, which is more efficient than calling dst = 0.0 separately before.\\nNote that with this approach we do not have to take care about the MPI related data exchange, since all the bookkeeping is done by the MatrixFree::cell_loop().\\n\\u00a0   template <int dim, int fe_degree>\\n\\u00a0   void GelfandProblem<dim, fe_degree>::evaluate_residual(\\n\\u00a0     LinearAlgebra::distributed::Vector<double>       &dst,\\n\\u00a0     const LinearAlgebra::distributed::Vector<double> &src) const\\n\\u00a0   {\\n\\u00a0     auto matrix_free = system_matrix.get_matrix_free();\\n\\u00a0 \\n\\u00a0     matrix_free->cell_loop(\\n\\u00a0       &GelfandProblem::local_evaluate_residual, this, dst, src, true);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n GelfandProblem::local_evaluate_residual\\nThis is the internal worker function for the evaluation of the residual. Essentially it has the same structure as the local_apply() function of the JacobianOperator and evaluates the residual for the input vector src on the given set of cells cell_range. The difference to the above mentioned local_apply() function is, that we split the FEEvaluation::gather_evaluate() function into FEEvaluation::read_dof_values_plain() and FEEvaluation::evaluate(), since the input vector might have constrained DOFs.\\n\\u00a0   template <int dim, int fe_degree>\\n\\u00a0   void GelfandProblem<dim, fe_degree>::local_evaluate_residual(\\n\\u00a0     const MatrixFree<dim, double>                    &data,\\n\\u00a0     LinearAlgebra::distributed::Vector<double>       &dst,\\n\\u00a0     const LinearAlgebra::distributed::Vector<double> &src,\\n\\u00a0     const std::pair<unsigned int, unsigned int>      &cell_range) const\\n\\u00a0   {\\n\\u00a0     FEEvaluation<dim, fe_degree, fe_degree + 1, 1, double> phi(data);\\n\\u00a0 \\n\\u00a0     for (unsigned int cell = cell_range.first; cell < cell_range.second; ++cell)\\n\\u00a0       {\\n\\u00a0         phi.reinit(cell);\\n\\u00a0 \\n\\u00a0         phi.read_dof_values_plain(src);\\n\\u00a0         phi.evaluate(EvaluationFlags::values | EvaluationFlags::gradients);\\n\\u00a0 \\n\\u00a0         for (const unsigned int q : phi.quadrature_point_indices())\\n\\u00a0           {\\n\\u00a0             phi.submit_value(-std::exp(phi.get_value(q)), q);\\n\\u00a0             phi.submit_gradient(phi.get_gradient(q), q);\\n\\u00a0           }\\n\\u00a0 \\n\\u00a0         phi.integrate_scatter(EvaluationFlags::values |\\n\\u00a0                                 EvaluationFlags::gradients,\\n\\u00a0                               dst);\\n\\u00a0       }\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n GelfandProblem::assemble_rhs\\nUsing the above function evaluate_residual() to evaluate the nonlinear residual, the assembly of the right hand side of the linearized system becomes now a very easy task. We just call the evaluate_residual() function and multiply the result with minus one.\\nExperiences show that using the FEEvaluation class is much faster than a classical implementation with FEValues and co.\\n\\u00a0   template <int dim, int fe_degree>\\n\\u00a0   void GelfandProblem<dim, fe_degree>::assemble_rhs()\\n\\u00a0   {\\n\\u00a0     TimerOutput::Scope t(computing_timer, \\\"assemble right hand side\\\");\\n\\u00a0 \\n\\u00a0     evaluate_residual(system_rhs, solution);\\n\\u00a0 \\n\\u00a0     system_rhs *= -1.0;\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n GelfandProblem::compute_residual\\nAccording to step-15 the following function computes the norm of the nonlinear residual for the solution \\\\(u_h^n + \\\\alpha s_h^n\\\\) with the help of the evaluate_residual() function. The Newton step length \\\\(\\\\alpha\\\\) becomes important if we would use an adaptive version of the Newton method. Then for example we would compute the residual for different step lengths and compare the residuals. However, for our problem the full Newton step with \\\\(\\\\alpha=1\\\\) is the best we can do. An adaptive version of Newton's method becomes interesting if we have no good initial value. Note that in theory Newton's method converges with quadratic order, but only if we have an appropriate initial value. For unsuitable initial values the Newton method diverges even with quadratic order. A common way is then to use a damped version \\\\(\\\\alpha<1\\\\) until the Newton step is good enough and the full Newton step can be performed. This was also discussed in step-15.\\n\\u00a0   template <int dim, int fe_degree>\\n\\u00a0   double GelfandProblem<dim, fe_degree>::compute_residual(const double alpha)\\n\\u00a0   {\\n\\u00a0     TimerOutput::Scope t(computing_timer, \\\"compute residual\\\");\\n\\u00a0 \\n\\u00a0     LinearAlgebra::distributed::Vector<double> residual;\\n\\u00a0     LinearAlgebra::distributed::Vector<double> evaluation_point;\\n\\u00a0 \\n\\u00a0     system_matrix.initialize_dof_vector(residual);\\n\\u00a0     system_matrix.initialize_dof_vector(evaluation_point);\\n\\u00a0 \\n\\u00a0     evaluation_point = solution;\\n\\u00a0     if (alpha > 1e-12)\\n\\u00a0       {\\n\\u00a0         evaluation_point.add(alpha, newton_update);\\n\\u00a0       }\\n\\u00a0 \\n\\u00a0     evaluate_residual(residual, evaluation_point);\\n\\u00a0 \\n\\u00a0     return residual.l2_norm();\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nLinearAlgebra::distributed::Vector::addvoid add(const Number a)\\n GelfandProblem::compute_update\\nIn order to compute the Newton updates in each Newton step we solve the linear system with the CG algorithm together with a geometric multigrid preconditioner. For this we first set up the PreconditionMG object with a Chebyshev smoother like we did in step-37.\\n\\u00a0   template <int dim, int fe_degree>\\n\\u00a0   void GelfandProblem<dim, fe_degree>::compute_update()\\n\\u00a0   {\\n\\u00a0     TimerOutput::Scope t(computing_timer, \\\"compute update\\\");\\n\\u00a0 \\nWe remember that the Jacobian depends on the last Newton step stored in the solution vector. So we update the ghost values of the Newton step and pass it to the JacobianOperator to store the information.\\n\\u00a0     solution.update_ghost_values();\\n\\u00a0 \\n\\u00a0     system_matrix.evaluate_newton_step(solution);\\n\\u00a0 \\n\\u00a0 \\nNext we also have to pass the last Newton step to the multilevel operators. Therefore, we need to interpolate the Newton step to all levels of the triangulation. This is done with the MGTransferMatrixFree::interpolate_to_mg().\\n\\u00a0     mg_transfer.interpolate_to_mg(dof_handler, mg_solution, solution);\\n\\u00a0 \\n\\u00a0 \\nNow we can set up the preconditioner. We define the smoother and pass the interpolated vectors of the Newton step to the multilevel operators.\\n\\u00a0     using SmootherType =\\n\\u00a0       PreconditionChebyshev<LevelMatrixType,\\n\\u00a0                             LinearAlgebra::distributed::Vector<float>>;\\n\\u00a0     mg::SmootherRelaxation<SmootherType,\\n\\u00a0                            LinearAlgebra::distributed::Vector<float>>\\n\\u00a0                                                          mg_smoother;\\n\\u00a0     MGLevelObject<typename SmootherType::AdditionalData> smoother_data;\\n\\u00a0     smoother_data.resize(0, triangulation.n_global_levels() - 1);\\n\\u00a0     for (unsigned int level = 0; level < triangulation.n_global_levels();\\n\\u00a0          ++level)\\n\\u00a0       {\\n\\u00a0         if (level > 0)\\n\\u00a0           {\\n\\u00a0             smoother_data[level].smoothing_range     = 15.;\\n\\u00a0             smoother_data[level].degree              = 4;\\n\\u00a0             smoother_data[level].eig_cg_n_iterations = 10;\\n\\u00a0           }\\n\\u00a0         else\\n\\u00a0           {\\n\\u00a0             smoother_data[0].smoothing_range = 1e-3;\\n\\u00a0             smoother_data[0].degree          = numbers::invalid_unsigned_int;\\n\\u00a0             smoother_data[0].eig_cg_n_iterations = mg_matrices[0].m();\\n\\u00a0           }\\n\\u00a0 \\n\\u00a0         mg_matrices[level].evaluate_newton_step(mg_solution[level]);\\n\\u00a0         mg_matrices[level].compute_diagonal();\\n\\u00a0 \\n\\u00a0         smoother_data[level].preconditioner =\\n\\u00a0           mg_matrices[level].get_matrix_diagonal_inverse();\\n\\u00a0       }\\n\\u00a0     mg_smoother.initialize(mg_matrices, smoother_data);\\n\\u00a0 \\n\\u00a0     MGCoarseGridApplySmoother<LinearAlgebra::distributed::Vector<float>>\\n\\u00a0       mg_coarse;\\n\\u00a0     mg_coarse.initialize(mg_smoother);\\n\\u00a0 \\n\\u00a0     mg::Matrix<LinearAlgebra::distributed::Vector<float>> mg_matrix(\\n\\u00a0       mg_matrices);\\n\\u00a0 \\n\\u00a0     MGLevelObject<MatrixFreeOperators::MGInterfaceOperator<LevelMatrixType>>\\n\\u00a0       mg_interface_matrices;\\n\\u00a0     mg_interface_matrices.resize(0, triangulation.n_global_levels() - 1);\\n\\u00a0     for (unsigned int level = 0; level < triangulation.n_global_levels();\\n\\u00a0          ++level)\\n\\u00a0       {\\n\\u00a0         mg_interface_matrices[level].initialize(mg_matrices[level]);\\n\\u00a0       }\\n\\u00a0     mg::Matrix<LinearAlgebra::distributed::Vector<float>> mg_interface(\\n\\u00a0       mg_interface_matrices);\\n\\u00a0 \\n\\u00a0     Multigrid<LinearAlgebra::distributed::Vector<float>> mg(\\n\\u00a0       mg_matrix, mg_coarse, mg_transfer, mg_smoother, mg_smoother);\\n\\u00a0     mg.set_edge_matrices(mg_interface, mg_interface);\\n\\u00a0 \\n\\u00a0     PreconditionMG<dim,\\n\\u00a0                    LinearAlgebra::distributed::Vector<float>,\\n\\u00a0                    MGTransferMatrixFree<dim, float>>\\n\\u00a0       preconditioner(dof_handler, mg, mg_transfer);\\n\\u00a0 \\n\\u00a0 \\nMGCoarseGridApplySmootherDefinition mg_coarse.h:40\\nMGCoarseGridApplySmoother::initializevoid initialize(const MGSmootherBase< VectorType > &coarse_smooth)\\nMGLevelObject::resizevoid resize(const unsigned int new_minlevel, const unsigned int new_maxlevel, Args &&...args)Definition mg_level_object.h:256\\nMultigridDefinition multigrid.h:163\\nPreconditionChebyshevDefinition precondition.h:2105\\nPreconditionMGDefinition multigrid.h:501\\nmg::MatrixDefinition mg_matrix.h:46\\nmg::SmootherRelaxationDefinition mg_smoother.h:186\\nmgDefinition mg.h:81\\nnumbers::invalid_unsigned_intstatic const unsigned int invalid_unsigned_intDefinition types.h:220\\nFinally we set up the SolverControl and the SolverCG to solve the linearized problem for the current Newton update. An important fact of the implementation of SolverCG or also SolverGMRES is, that the vector holding the solution of the linear system (here newton_update) can be used to pass a starting value. In order to start the iterative solver always with a zero vector we reset the newton_update explicitly before calling SolverCG::solve(). Afterwards we distribute the Dirichlet boundary conditions stored in constraints and store the number of iteration steps for the later output.\\n\\u00a0     SolverControl solver_control(100, 1.e-12);\\n\\u00a0     SolverCG<LinearAlgebra::distributed::Vector<double>> cg(solver_control);\\n\\u00a0 \\n\\u00a0     newton_update = 0.0;\\n\\u00a0 \\n\\u00a0     cg.solve(system_matrix, newton_update, system_rhs, preconditioner);\\n\\u00a0 \\n\\u00a0     constraints.distribute(newton_update);\\n\\u00a0 \\n\\u00a0     linear_iterations = solver_control.last_step();\\n\\u00a0 \\n\\u00a0 \\nSolverCGDefinition solver_cg.h:179\\nSolverControlDefinition solver_control.h:67\\nThen for bookkeeping we zero out the ghost values.\\n\\u00a0     solution.zero_out_ghost_values();\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n GelfandProblem::solve\\nNow we implement the actual Newton solver for the nonlinear problem.\\n\\u00a0   template <int dim, int fe_degree>\\n\\u00a0   void GelfandProblem<dim, fe_degree>::solve()\\n\\u00a0   {\\n\\u00a0     TimerOutput::Scope t(computing_timer, \\\"solve\\\");\\n\\u00a0 \\n\\u00a0 \\nWe define a maximal number of Newton steps and tolerances for the convergence criterion. Usually, with good starting values, the Newton method converges in three to six steps, so maximal ten steps should be totally sufficient. As tolerances we use  \\\\(\\\\|F(u^n_h)\\\\|<\\\\text{TOL}_f =\\n   10^{-12}\\\\) for the norm of the residual and  \\\\(\\\\|s_h^n\\\\| < \\\\text{TOL}_x =\\n   10^{-10}\\\\) for the norm of the Newton update. This seems a bit over the top, but we will see that, for our example, we will achieve these tolerances after a few steps.\\n\\u00a0     const unsigned int itmax = 10;\\n\\u00a0     const double       TOLf  = 1e-12;\\n\\u00a0     const double       TOLx  = 1e-10;\\n\\u00a0 \\n\\u00a0 \\n\\u00a0     Timer solver_timer;\\n\\u00a0     solver_timer.start();\\n\\u00a0 \\n\\u00a0 \\nTimerDefinition timer.h:117\\nTimer::startvoid start()Definition timer.cc:176\\nNow we start the actual Newton iteration.\\n\\u00a0     for (unsigned int newton_step = 1; newton_step <= itmax; ++newton_step)\\n\\u00a0       {\\nWe assemble the right hand side of the linearized problem and compute the Newton update.\\n\\u00a0         assemble_rhs();\\n\\u00a0         compute_update();\\n\\u00a0 \\n\\u00a0 \\nThen we compute the errors, namely the norm of the Newton update and the residual. Note that at this point one could incorporate a step size control for the Newton method by varying the input parameter \\\\(\\\\alpha\\\\) for the compute_residual function. However, here we just use \\\\(\\\\alpha\\\\) equal to one for a plain Newton iteration.\\n\\u00a0         const double ERRx = newton_update.l2_norm();\\n\\u00a0         const double ERRf = compute_residual(1.0);\\n\\u00a0 \\n\\u00a0 \\nNext we advance the Newton step by adding the Newton update to the current Newton step.\\n\\u00a0         solution.add(1.0, newton_update);\\n\\u00a0 \\n\\u00a0 \\nA short output will inform us on the current Newton step.\\n\\u00a0         pcout << \\\"   Nstep \\\" << newton_step << \\\", errf = \\\" << ERRf\\n\\u00a0               << \\\", errx = \\\" << ERRx << \\\", it = \\\" << linear_iterations\\n\\u00a0               << std::endl;\\n\\u00a0 \\n\\u00a0 \\nAfter each Newton step we check the convergence criteria. If at least one of those is fulfilled we are done and end the loop. If we haven't found a satisfying solution after the maximal amount of Newton iterations, we inform the user about this shortcoming.\\n\\u00a0         if (ERRf < TOLf || ERRx < TOLx)\\n\\u00a0           {\\n\\u00a0             solver_timer.stop();\\n\\u00a0 \\n\\u00a0             pcout << \\\"Convergence step \\\" << newton_step << \\\" value \\\" << ERRf\\n\\u00a0                   << \\\" (used wall time: \\\" << solver_timer.wall_time() << \\\" s)\\\"\\n\\u00a0                   << std::endl;\\n\\u00a0 \\n\\u00a0             break;\\n\\u00a0           }\\n\\u00a0         else if (newton_step == itmax)\\n\\u00a0           {\\n\\u00a0             solver_timer.stop();\\n\\u00a0             pcout << \\\"WARNING: No convergence of Newton's method after \\\"\\n\\u00a0                   << newton_step << \\\" steps.\\\" << std::endl;\\n\\u00a0 \\n\\u00a0             break;\\n\\u00a0           }\\n\\u00a0       }\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n GelfandProblem::compute_solution_norm\\nThe computation of the H1-seminorm of the solution can be done in the same way as in step-59. We update the ghost values and use the function VectorTools::integrate_difference(). In the end we gather all computations from all MPI ranks and return the norm.\\n\\u00a0   template <int dim, int fe_degree>\\n\\u00a0   double GelfandProblem<dim, fe_degree>::compute_solution_norm() const\\n\\u00a0   {\\n\\u00a0     solution.update_ghost_values();\\n\\u00a0 \\n\\u00a0     Vector<float> norm_per_cell(triangulation.n_active_cells());\\n\\u00a0 \\n\\u00a0     VectorTools::integrate_difference(mapping,\\n\\u00a0                                       dof_handler,\\n\\u00a0                                       solution,\\n\\u00a0                                       Functions::ZeroFunction<dim>(),\\n\\u00a0                                       norm_per_cell,\\n\\u00a0                                       QGauss<dim>(fe.degree + 2),\\n\\u00a0                                       VectorTools::H1_seminorm);\\n\\u00a0 \\n\\u00a0     solution.zero_out_ghost_values();\\n\\u00a0 \\n\\u00a0     return VectorTools::compute_global_error(triangulation,\\n\\u00a0                                              norm_per_cell,\\n\\u00a0                                              VectorTools::H1_seminorm);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nTriangulation::n_active_cellsunsigned int n_active_cells() const\\nVectorTools::compute_global_errordouble compute_global_error(const Triangulation< dim, spacedim > &tria, const InVector &cellwise_error, const NormType &norm, const double exponent=2.)\\nVectorTools::H1_seminorm@ H1_seminormDefinition vector_tools_common.h:164\\nVectorTools::integrate_differencevoid integrate_difference(const Mapping< dim, spacedim > &mapping, const DoFHandler< dim, spacedim > &dof, const ReadVector< Number > &fe_function, const Function< spacedim, Number > &exact_solution, OutVector &difference, const Quadrature< dim > &q, const NormType &norm, const Function< spacedim, double > *weight=nullptr, const double exponent=2.)\\n GelfandProblem::output_results\\nWe generate the graphical output files in vtu format together with a pvtu master file at once by calling the DataOut::write_vtu_with_pvtu_record() function in the same way as in step-37. In addition, as in step-40, we query the types::subdomain_id of each cell and write the distribution of the triangulation among the MPI ranks into the output file. Finally, we generate the patches of the solution by calling DataOut::build_patches(). However, since we have a computational domain with a curved boundary, we additionally pass the mapping and the finite element degree as number of subdivision. But this is still not enough for the correct representation of the solution, for example in ParaView, because we attached a TransfiniteInterpolationManifold to the inner cells, which results in curved cells in the interior. Therefore we pass as third argument the DataOut::curved_inner_cells option, such that also the inner cells use the corresponding manifold description to build the patches.\\nNote that we could handle the higher order elements with the flag DataOutBase::VtkFlags::write_higher_order_cells. However, due to the limited compatibility to previous version of ParaView and the missing support by VisIt, we left this option for a future version.\\n\\u00a0   template <int dim, int fe_degree>\\n\\u00a0   void\\n\\u00a0   GelfandProblem<dim, fe_degree>::output_results(const unsigned int cycle) const\\n\\u00a0   {\\n\\u00a0     if (triangulation.n_global_active_cells() > 1e6)\\n\\u00a0       return;\\n\\u00a0 \\n\\u00a0     solution.update_ghost_values();\\n\\u00a0 \\n\\u00a0     DataOut<dim> data_out;\\n\\u00a0     data_out.attach_dof_handler(dof_handler);\\n\\u00a0     data_out.add_data_vector(solution, \\\"solution\\\");\\n\\u00a0 \\n\\u00a0     Vector<float> subdomain(triangulation.n_active_cells());\\n\\u00a0     for (unsigned int i = 0; i < subdomain.size(); ++i)\\n\\u00a0       {\\n\\u00a0         subdomain(i) = triangulation.locally_owned_subdomain();\\n\\u00a0       }\\n\\u00a0     data_out.add_data_vector(subdomain, \\\"subdomain\\\");\\n\\u00a0 \\n\\u00a0     data_out.build_patches(mapping,\\n\\u00a0                            fe.degree,\\n\\u00a0                            DataOut<dim>::curved_inner_cells);\\n\\u00a0 \\n\\u00a0     DataOutBase::VtkFlags flags;\\n\\u00a0     flags.compression_level = DataOutBase::CompressionLevel::best_speed;\\n\\u00a0     data_out.set_flags(flags);\\n\\u00a0     data_out.write_vtu_with_pvtu_record(\\n\\u00a0       \\\"./\\\", \\\"solution_\\\" + std::to_string(dim) + \\\"d\\\", cycle, MPI_COMM_WORLD, 3);\\n\\u00a0 \\n\\u00a0     solution.zero_out_ghost_values();\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nDataOut_DoFData::attach_dof_handlervoid attach_dof_handler(const DoFHandler< dim, spacedim > &)\\nDataOutDefinition data_out.h:147\\nparallel::TriangulationBase::n_global_active_cellsvirtual types::global_cell_index n_global_active_cells() const overrideDefinition tria_base.cc:151\\nparallel::TriangulationBase::locally_owned_subdomaintypes::subdomain_id locally_owned_subdomain() const overrideDefinition tria_base.cc:345\\nDataOutBase::CompressionLevel::best_speed@ best_speed\\nDataOutBase::VtkFlagsDefinition data_out_base.h:1127\\nDataOutBase::VtkFlags::compression_levelDataOutBase::CompressionLevel compression_levelDefinition data_out_base.h:1182\\n GelfandProblem::run\\nThe last missing function of the solver class for the Gelfand problem is the run function. In the beginning we print information about the system specifications and the finite element space we use. The problem is solved several times on a successively refined mesh.\\n\\u00a0   template <int dim, int fe_degree>\\n\\u00a0   void GelfandProblem<dim, fe_degree>::run()\\n\\u00a0   {\\n\\u00a0     {\\n\\u00a0       const unsigned int n_ranks =\\n\\u00a0         Utilities::MPI::n_mpi_processes(MPI_COMM_WORLD);\\n\\u00a0       const unsigned int n_vect_doubles = VectorizedArray<double>::size();\\n\\u00a0       const unsigned int n_vect_bits    = 8 * sizeof(double) * n_vect_doubles;\\n\\u00a0 \\n\\u00a0       std::string DAT_header = \\\"START DATE: \\\" + Utilities::System::get_date() +\\n\\u00a0                                \\\", TIME: \\\" + Utilities::System::get_time();\\n\\u00a0       std::string MPI_header = \\\"Running with \\\" + std::to_string(n_ranks) +\\n\\u00a0                                \\\" MPI process\\\" + (n_ranks > 1 ? \\\"es\\\" : \\\"\\\");\\n\\u00a0       std::string VEC_header =\\n\\u00a0         \\\"Vectorization over \\\" + std::to_string(n_vect_doubles) +\\n\\u00a0         \\\" doubles = \\\" + std::to_string(n_vect_bits) + \\\" bits (\\\" +\\n\\u00a0         Utilities::System::get_current_vectorization_level() +\\n\\u00a0         \\\"), VECTORIZATION_LEVEL=\\\" +\\n\\u00a0         std::to_string(DEAL_II_COMPILER_VECTORIZATION_LEVEL);\\n\\u00a0       std::string SOL_header = \\\"Finite element space: \\\" + fe.get_name();\\n\\u00a0 \\n\\u00a0       pcout << std::string(80, '=') << std::endl;\\n\\u00a0       pcout << DAT_header << std::endl;\\n\\u00a0       pcout << std::string(80, '-') << std::endl;\\n\\u00a0 \\n\\u00a0       pcout << MPI_header << std::endl;\\n\\u00a0       pcout << VEC_header << std::endl;\\n\\u00a0       pcout << SOL_header << std::endl;\\n\\u00a0 \\n\\u00a0       pcout << std::string(80, '=') << std::endl;\\n\\u00a0     }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0     for (unsigned int cycle = 0; cycle < 9 - dim; ++cycle)\\n\\u00a0       {\\n\\u00a0         pcout << std::string(80, '-') << std::endl;\\n\\u00a0         pcout << \\\"Cycle \\\" << cycle << std::endl;\\n\\u00a0         pcout << std::string(80, '-') << std::endl;\\n\\u00a0 \\n\\u00a0 \\nVectorizedArrayBase< VectorizedArray< Number, width >, 1 >::sizestatic constexpr std::size_t size()Definition vectorization.h:285\\nDEAL_II_COMPILER_VECTORIZATION_LEVEL#define DEAL_II_COMPILER_VECTORIZATION_LEVELDefinition config.h:138\\nUtilities::MPI::n_mpi_processesunsigned int n_mpi_processes(const MPI_Comm mpi_communicator)Definition mpi.cc:92\\nUtilities::System::get_timestd::string get_time()Definition utilities.cc:1013\\nUtilities::System::get_current_vectorization_levelstd::string get_current_vectorization_level()Definition utilities.cc:938\\nUtilities::System::get_datestd::string get_date()Definition utilities.cc:1029\\nThe first task in actually solving the problem is to generate or refine the triangulation.\\n\\u00a0         if (cycle == 0)\\n\\u00a0           {\\n\\u00a0             make_grid();\\n\\u00a0           }\\n\\u00a0         else\\n\\u00a0           {\\n\\u00a0             triangulation.refine_global(1);\\n\\u00a0           }\\n\\u00a0 \\n\\u00a0 \\nNow we set up the system and solve the problem. These steps are accompanied by time measurement and textual output.\\n\\u00a0         Timer timer;\\n\\u00a0 \\n\\u00a0         pcout << \\\"Set up system...\\\" << std::endl;\\n\\u00a0         setup_system();\\n\\u00a0 \\n\\u00a0         pcout << \\\"   Triangulation: \\\" << triangulation.n_global_active_cells()\\n\\u00a0               << \\\" cells\\\" << std::endl;\\n\\u00a0         pcout << \\\"   DoFHandler:    \\\" << dof_handler.n_dofs() << \\\" DoFs\\\"\\n\\u00a0               << std::endl;\\n\\u00a0         pcout << std::endl;\\n\\u00a0 \\n\\u00a0 \\n\\u00a0         pcout << \\\"Solve using Newton's method...\\\" << std::endl;\\n\\u00a0         solve();\\n\\u00a0         pcout << std::endl;\\n\\u00a0 \\n\\u00a0 \\n\\u00a0         timer.stop();\\n\\u00a0         pcout << \\\"Time for setup+solve (CPU/Wall) \\\" << timer.cpu_time() << '/'\\n\\u00a0               << timer.wall_time() << \\\" s\\\" << std::endl;\\n\\u00a0         pcout << std::endl;\\n\\u00a0 \\n\\u00a0 \\nAfter the problem was solved we compute the norm of the solution and generate the graphical output files.\\n\\u00a0         pcout << \\\"Output results...\\\" << std::endl;\\n\\u00a0         const double norm = compute_solution_norm();\\n\\u00a0         output_results(cycle);\\n\\u00a0 \\n\\u00a0         pcout << \\\"  H1 seminorm: \\\" << norm << std::endl;\\n\\u00a0         pcout << std::endl;\\n\\u00a0 \\n\\u00a0 \\nFinally after each cycle we print the timing information.\\n\\u00a0         computing_timer.print_summary();\\n\\u00a0         computing_timer.reset();\\n\\u00a0       }\\n\\u00a0   }\\n\\u00a0 } // namespace Step66\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n The main function\\nAs typical for programs running in parallel with MPI we set up the MPI framework and disable shared-memory parallelization by limiting the number of threads to one. Finally to run the solver for the Gelfand problem we create an object of the GelfandProblem class and call the run function. Exemplarily we solve the problem once in 2d and once in 3d each with fourth-order Lagrangian finite elements.\\n\\u00a0 int main(int argc, char *argv[])\\n\\u00a0 {\\n\\u00a0   try\\n\\u00a0     {\\n\\u00a0       using namespace Step66;\\n\\u00a0 \\n\\u00a0       Utilities::MPI::MPI_InitFinalize mpi_init(argc, argv, 1);\\n\\u00a0 \\n\\u00a0       {\\n\\u00a0         GelfandProblem<2, 4> gelfand_problem;\\n\\u00a0         gelfand_problem.run();\\n\\u00a0       }\\n\\u00a0 \\n\\u00a0       {\\n\\u00a0         GelfandProblem<3, 4> gelfand_problem;\\n\\u00a0         gelfand_problem.run();\\n\\u00a0       }\\n\\u00a0     }\\n\\u00a0   catch (std::exception &exc)\\n\\u00a0     {\\n\\u00a0       std::cerr << std::endl\\n\\u00a0                 << std::endl\\n\\u00a0                 << \\\"----------------------------------------------------\\\"\\n\\u00a0                 << std::endl;\\n\\u00a0       std::cerr << \\\"Exception on processing: \\\" << std::endl\\n\\u00a0                 << exc.what() << std::endl\\n\\u00a0                 << \\\"Aborting!\\\" << std::endl\\n\\u00a0                 << \\\"----------------------------------------------------\\\"\\n\\u00a0                 << std::endl;\\n\\u00a0       return 1;\\n\\u00a0     }\\n\\u00a0   catch (...)\\n\\u00a0     {\\n\\u00a0       std::cerr << std::endl\\n\\u00a0                 << std::endl\\n\\u00a0                 << \\\"----------------------------------------------------\\\"\\n\\u00a0                 << std::endl;\\n\\u00a0       std::cerr << \\\"Unknown exception!\\\" << std::endl\\n\\u00a0                 << \\\"Aborting!\\\" << std::endl\\n\\u00a0                 << \\\"----------------------------------------------------\\\"\\n\\u00a0                 << std::endl;\\n\\u00a0       return 1;\\n\\u00a0     }\\n\\u00a0 \\n\\u00a0   return 0;\\n\\u00a0 }\\nUtilities::MPI::MPI_InitFinalizeDefinition mpi.h:1081\\n Results\\nThe aim of this tutorial step was to demonstrate the solution of a nonlinear PDE with the matrix-free framework.\\nProgram output\\nRunning the program on two processes in release mode via cmake . && make release && make && mpirun -n 2 ./step-66\\n gives the following output on the console ================================================================================\\nSTART DATE: 2021/5/18, TIME: 16:25:48\\n--------------------------------------------------------------------------------\\nRunning with 2 MPI processes\\nVectorization over 4 doubles = 256 bits (AVX), VECTORIZATION_LEVEL=2\\nFinite element space: FE_Q<2>(4)\\n================================================================================\\n--------------------------------------------------------------------------------\\nCycle 0\\n--------------------------------------------------------------------------------\\nSet up system...\\n Triangulation: 20 cells\\n DoFHandler:    337 DoFs\\n \\nSolve using Newton's method...\\n   Nstep 1, errf = 0.00380835, errx = 3.61904, it = 7\\n   Nstep 2, errf = 3.80167e-06, errx = 0.104353, it = 6\\n   Nstep 3, errf = 3.97939e-12, errx = 0.00010511, it = 4\\n   Nstep 4, errf = 2.28859e-13, errx = 1.07726e-10, it = 1\\nConvergence step 4 value 2.28859e-13 (used wall time: 0.0096409 s)\\n \\nTime for setup+solve (CPU/Wall) 0.015617/0.0156447 s\\n \\nOutput results...\\n  H1 seminorm: 0.773426\\n \\n \\n \\n+---------------------------------------------+------------+------------+\\n| Total wallclock time elapsed since start    |    0.0286s |            |\\n|                                             |            |            |\\n| Section                         | no. calls |  wall time | % of total |\\n+---------------------------------+-----------+------------+------------+\\n| assemble right hand side        |         4 |  9.71e-05s |      0.34% |\\n| compute residual                |         4 |  0.000137s |      0.48% |\\n| compute update                  |         4 |   0.00901s |        32% |\\n| make grid                       |         1 |   0.00954s |        33% |\\n| setup system                    |         1 |   0.00585s |        20% |\\n| solve                           |         1 |   0.00966s |        34% |\\n+---------------------------------+-----------+------------+------------+\\n \\n.\\n.\\n.\\n \\n--------------------------------------------------------------------------------\\nCycle 6\\n--------------------------------------------------------------------------------\\nSet up system...\\n   Triangulation: 81920 cells\\n   DoFHandler:    1311745 DoFs\\n \\nSolve using Newton's method...\\n   Nstep 1, errf = 5.90478e-05, errx = 231.427, it = 9\\n   Nstep 2, errf = 5.89991e-08, errx = 6.67102, it = 6\\n   Nstep 3, errf = 4.28813e-13, errx = 0.0067188, it = 4\\nConvergence step 3 value 4.28813e-13 (used wall time: 4.82953 s)\\n \\nTime for setup+solve (CPU/Wall) 6.25094/6.37174 s\\n \\nOutput results...\\n  H1 seminorm: 0.773426\\n \\n \\n \\n+---------------------------------------------+------------+------------+\\n| Total wallclock time elapsed since start    |      9.04s |            |\\n|                                             |            |            |\\n| Section                         | no. calls |  wall time | % of total |\\n+---------------------------------+-----------+------------+------------+\\n| assemble right hand side        |         3 |    0.0827s |      0.91% |\\n| compute residual                |         3 |    0.0909s |         1% |\\n| compute update                  |         3 |      4.65s |        51% |\\n| setup system                    |         1 |      1.54s |        17% |\\n| solve                           |         1 |      4.83s |        53% |\\n+---------------------------------+-----------+------------+------------+\\n \\n================================================================================\\nSTART DATE: 2021/5/18, TIME: 16:26:00\\n--------------------------------------------------------------------------------\\nRunning with 2 MPI processes\\nVectorization over 4 doubles = 256 bits (AVX), VECTORIZATION_LEVEL=2\\nFinite element space: FE_Q<3>(4)\\n================================================================================\\n \\n.\\n.\\n.\\n \\n--------------------------------------------------------------------------------\\nCycle 5\\n--------------------------------------------------------------------------------\\nSet up system...\\n Triangulation: 229376 cells\\n DoFHandler:    14729857 DoFs\\n \\nSolve using Newton's method...\\n   Nstep 1, errf = 6.30096e-06, errx = 481.74, it = 8\\n   Nstep 2, errf = 4.25607e-10, errx = 4.14315, it = 6\\n   Nstep 3, errf = 7.29563e-13, errx = 0.000321775, it = 2\\nConvergence step 3 value 7.29563e-13 (used wall time: 133.793 s)\\n \\nTime for setup+solve (CPU/Wall) 226.809/232.615 s\\n \\nOutput results...\\n  H1 seminorm: 0.588667\\n \\n \\n \\n+---------------------------------------------+------------+------------+\\n| Total wallclock time elapsed since start    |       390s |            |\\n|                                             |            |            |\\n| Section                         | no. calls |  wall time | % of total |\\n+---------------------------------+-----------+------------+------------+\\n| assemble right hand side        |         3 |      2.06s |      0.53% |\\n| compute residual                |         3 |      2.46s |      0.63% |\\n| compute update                  |         3 |       129s |        33% |\\n| setup system                    |         1 |      98.8s |        25% |\\n| solve                           |         1 |       134s |        34% |\\n+---------------------------------+-----------+------------+------------+\\nWe show the solution for the two- and three-dimensional problem in the following figure.\\n       Newton solver\\nIn the program output above we find some interesting information about the Newton iterations. The terminal output in each refinement cycle presents detailed diagnostics of the Newton method, which show first of all the number of Newton steps and for each step the norm of the residual \\\\(\\\\|F(u_h^{n+1})\\\\|\\\\), the norm of the Newton update \\\\(\\\\|s_h^n\\\\|\\\\), and the number of CG iterations it.\\nWe observe that for all cases the Newton method converges in approximately three to four steps, which shows the quadratic convergence of the Newton method with a full step length \\\\(\\\\alpha = 1\\\\). However, be aware that for a badly chosen initial guess \\\\(u_h^0\\\\), the Newton method will also diverge quadratically. Usually if you do not have an appropriate initial guess, you try a few damped Newton steps with a reduced step length \\\\(\\\\alpha < 1\\\\) until the Newton step is again in the quadratic convergence domain. This damping and relaxation of the Newton step length truly requires a more sophisticated implementation of the Newton method, which we designate to you as a possible extension of the tutorial.\\nFurthermore, we see that the number of CG iterations is approximately constant with successive mesh refinements and an increasing number of DoFs. This is of course due to the geometric multigrid preconditioner and similar to the observations made in other tutorials that use this method, e.g., step-16 and step-37. Just to give an example, in the three-dimensional case after five refinements, we have approximately 14.7 million distributed DoFs with fourth-order Lagrangian finite elements, but the number of CG iterations is still less than ten.\\nIn addition, there is one more very useful optimization that we applied and that should be mentioned here. In the compute_update() function we explicitly reset the vector holding the Newton update before passing it as the output vector to the solver. In that case we use a starting value of zero for the CG method, which is more suitable than the previous Newton update, the actual content of the newton_update before resetting, and thus reduces the number of CG iterations by a few steps.\\nPossibilities for extensions\\nA couple of possible extensions are available concerning minor updates to the present code as well as a deeper numerical investigation of the Gelfand problem.\\nMore sophisticated Newton iteration\\nBeside a step size controlled version of the Newton iteration as mentioned already in step-15 (and actually implemented, with many more bells and whistles, in step-77), one could also implement a more flexible stopping criterion for the Newton iteration. For example one could replace the fixed tolerances for the residual TOLf and for the Newton updated TOLx and implement a mixed error control with a given absolute and relative tolerance, such that the Newton iteration exits with success as, e.g.,   \\n\\\\begin{align*}\\n  \\\\|F(u_h^{n+1})\\\\| \\\\leq \\\\texttt{RelTol} \\\\|u_h^{n+1}\\\\| + \\\\texttt{AbsTol}.\\n\\\\end{align*}\\n\\n For more advanced applications with many nonlinear systems to solve, for example at each time step for a time-dependent problem, it turns out that it is not necessary to set up and assemble the Jacobian anew at every single Newton step or even for each time step. Instead, the existing Jacobian from a previous step can be used for the Newton iteration. The Jacobian is then only rebuilt if, for example, the Newton iteration converges too slowly. Such an idea yields a quasi-Newton method. Admittedly, when using the matrix-free framework, the assembly of the Jacobian is omitted anyway, but with in this way one can try to optimize the reassembly of the geometric multigrid preconditioner. Remember that each time the solution from the old Newton step must be distributed to all levels and the mutligrid preconditioner must be reinitialized.\\nParallel scalability and thread parallelism\\nIn the results section of step-37 and others, the parallel scalability of the matrix-free framework on a large number of processors has already been demonstrated very impressively. In the nonlinear case we consider here, we note that one of the bottlenecks could become the transfer and evaluation of the matrix-free Jacobi operator and its multistage operators in the previous Newton step, since we need to transfer the old solution at all stages in each step. A first parallel scalability analysis in [54] shows quite good strong scalability when the problem size is large enough. However, a more detailed analysis needs to be performed for reliable results. Moreover, the problem has been solved only with MPI so far, without using the possibilities of shared memory parallelization with threads. Therefore, for this example, you could try hybrid parallelization with MPI and threads, such as described in step-48.\\nComparison to matrix-based methods\\nAnalogously to step-50 and the mentioned possible extension of step-75, you can convince yourself which method is faster.\\nEigenvalue problem\\nOne can consider the corresponding eigenvalue problem, which is called Bratu problem. For example, if we define a fixed eigenvalue \\\\(\\\\lambda\\\\in[0,6]\\\\), we can compute the corresponding discrete eigenfunction. You will notice that the number of Newton steps will increase with increasing \\\\(\\\\lambda\\\\). To reduce the number of Newton steps you can use the following trick: start from a certain \\\\(\\\\lambda\\\\), compute the eigenfunction, increase  \\\\(\\\\lambda=\\\\lambda +\\n\\\\delta_\\\\lambda\\\\), and then use the previous solution as an initial guess for the Newton iteration \\u2013 this approach is called a \\\"continuation\\nmethod\\\". In the end you can plot the \\\\(H^1(\\\\Omega)\\\\)-norm over the eigenvalue \\\\(\\\\lambda \\\\mapsto \\\\|u_h\\\\|_{H^1(\\\\Omega)}\\\\). What do you observe for further increasing \\\\(\\\\lambda>7\\\\)?\\n The plain program\\n/* ------------------------------------------------------------------------\\n *\\n * SPDX-License-Identifier: LGPL-2.1-or-later\\n * Copyright (C) 2021 - 2024 by the deal.II authors\\n *\\n * This file is part of the deal.II library.\\n *\\n * Part of the source code is dual licensed under Apache-2.0 WITH\\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\\n * governing the source code and code contributions can be found in\\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\\n *\\n * ------------------------------------------------------------------------\\n *\\n * Authors: Fabian Castelli, Karlsruhe Institute of Technology (KIT)\\n */\\n \\n \\n \\n#include <deal.II/base/function.h>\\n#include <deal.II/base/quadrature_lib.h>\\n#include <deal.II/base/timer.h>\\n#include <deal.II/base/vectorization.h>\\n \\n#include <deal.II/dofs/dof_accessor.h>\\n#include <deal.II/dofs/dof_handler.h>\\n#include <deal.II/dofs/dof_tools.h>\\n \\n#include <deal.II/fe/fe_q.h>\\n#include <deal.II/fe/mapping_q.h>\\n \\n#include <deal.II/grid/grid_generator.h>\\n#include <deal.II/grid/grid_out.h>\\n#include <deal.II/grid/manifold_lib.h>\\n#include <deal.II/grid/tria.h>\\n#include <deal.II/grid/tria_accessor.h>\\n#include <deal.II/grid/tria_iterator.h>\\n \\n#include <deal.II/lac/affine_constraints.h>\\n#include <deal.II/lac/precondition.h>\\n#include <deal.II/lac/solver_cg.h>\\n#include <deal.II/lac/vector.h>\\n \\n#include <deal.II/numerics/data_out.h>\\n#include <deal.II/numerics/vector_tools.h>\\n \\n#include <deal.II/matrix_free/fe_evaluation.h>\\n#include <deal.II/matrix_free/matrix_free.h>\\n#include <deal.II/matrix_free/operators.h>\\n#include <deal.II/matrix_free/tools.h>\\n \\n#include <deal.II/multigrid/mg_coarse.h>\\n#include <deal.II/multigrid/mg_constrained_dofs.h>\\n#include <deal.II/multigrid/mg_matrix.h>\\n#include <deal.II/multigrid/mg_smoother.h>\\n#include <deal.II/multigrid/mg_tools.h>\\n#include <deal.II/multigrid/mg_transfer_matrix_free.h>\\n#include <deal.II/multigrid/multigrid.h>\\n \\n \\n#include <fstream>\\n#include <iostream>\\n \\n \\n \\nnamespace Step66\\n{\\n using namespace dealii;\\n \\n \\n \\n \\n template <int dim, int fe_degree, typename number>\\n class JacobianOperator\\n    : public MatrixFreeOperators::\\n        Base<dim, LinearAlgebra::distributed::Vector<number>>\\n  {\\n public:\\n using value_type = number;\\n \\n using FECellIntegrator =\\n FEEvaluation<dim, fe_degree, fe_degree + 1, 1, number>;\\n \\n    JacobianOperator();\\n \\n virtual void clear() override;\\n \\n void evaluate_newton_step(\\n const LinearAlgebra::distributed::Vector<number> &newton_step);\\n \\n virtual void compute_diagonal() override;\\n \\n private:\\n virtual void apply_add(\\n LinearAlgebra::distributed::Vector<number>       &dst,\\n const LinearAlgebra::distributed::Vector<number> &src) const override;\\n \\n void\\n    local_apply(const MatrixFree<dim, number>                    &data,\\n LinearAlgebra::distributed::Vector<number>       &dst,\\n const LinearAlgebra::distributed::Vector<number> &src,\\n const std::pair<unsigned int, unsigned int> &cell_range) const;\\n \\n void local_compute_diagonal(FECellIntegrator &integrator) const;\\n \\n Table<2, VectorizedArray<number>> nonlinear_values;\\n  };\\n \\n \\n \\n template <int dim, int fe_degree, typename number>\\n  JacobianOperator<dim, fe_degree, number>::JacobianOperator()\\n    : MatrixFreeOperators::Base<dim,\\n LinearAlgebra::distributed::Vector<number>>()\\n  {}\\n \\n \\n \\n template <int dim, int fe_degree, typename number>\\n void JacobianOperator<dim, fe_degree, number>::clear()\\n  {\\n    nonlinear_values.reinit(0, 0);\\n MatrixFreeOperators::Base<dim, LinearAlgebra::distributed::Vector<number>>::\\n      clear();\\n  }\\n \\n \\n \\n \\n template <int dim, int fe_degree, typename number>\\n void JacobianOperator<dim, fe_degree, number>::evaluate_newton_step(\\n const LinearAlgebra::distributed::Vector<number> &newton_step)\\n  {\\n const unsigned int n_cells = this->data->n_cell_batches();\\n    FECellIntegrator   phi(*this->data);\\n \\n    newton_step.update_ghost_values();\\n \\n    nonlinear_values.reinit(n_cells, phi.n_q_points);\\n \\n for (unsigned int cell = 0; cell < n_cells; ++cell)\\n      {\\n        phi.reinit(cell);\\n        phi.read_dof_values_plain(newton_step);\\n        phi.evaluate(EvaluationFlags::values);\\n \\n for (const unsigned int q : phi.quadrature_point_indices())\\n          {\\n            nonlinear_values(cell, q) = std::exp(phi.get_value(q));\\n          }\\n      }\\n    newton_step.zero_out_ghost_values();\\n  }\\n \\n \\n \\n \\n template <int dim, int fe_degree, typename number>\\n void JacobianOperator<dim, fe_degree, number>::local_apply(\\n const MatrixFree<dim, number>                    &data,\\n LinearAlgebra::distributed::Vector<number>       &dst,\\n const LinearAlgebra::distributed::Vector<number> &src,\\n const std::pair<unsigned int, unsigned int>      &cell_range) const\\n {\\n    FECellIntegrator phi(data);\\n \\n for (unsigned int cell = cell_range.first; cell < cell_range.second; ++cell)\\n      {\\n AssertDimension(nonlinear_values.size(0),\\n                        phi.get_matrix_free().n_cell_batches());\\n AssertDimension(nonlinear_values.size(1), phi.n_q_points);\\n \\n \\n        phi.reinit(cell);\\n \\n        phi.gather_evaluate(src,\\n EvaluationFlags::values |\\n EvaluationFlags::gradients);\\n \\n for (const unsigned int q : phi.quadrature_point_indices())\\n          {\\n            phi.submit_value(-nonlinear_values(cell, q) * phi.get_value(q), q);\\n            phi.submit_gradient(phi.get_gradient(q), q);\\n          }\\n \\n        phi.integrate_scatter(EvaluationFlags::values |\\n EvaluationFlags::gradients,\\n                              dst);\\n      }\\n  }\\n \\n \\n \\n template <int dim, int fe_degree, typename number>\\n void JacobianOperator<dim, fe_degree, number>::apply_add(\\n LinearAlgebra::distributed::Vector<number>       &dst,\\n const LinearAlgebra::distributed::Vector<number> &src) const\\n {\\n    this->data->cell_loop(&JacobianOperator::local_apply, this, dst, src);\\n  }\\n \\n \\n \\n \\n template <int dim, int fe_degree, typename number>\\n void JacobianOperator<dim, fe_degree, number>::local_compute_diagonal(\\n    FECellIntegrator &phi) const\\n {\\n AssertDimension(nonlinear_values.size(0),\\n                    phi.get_matrix_free().n_cell_batches());\\n AssertDimension(nonlinear_values.size(1), phi.n_q_points);\\n \\n const unsigned int cell = phi.get_current_cell_index();\\n \\n    phi.evaluate(EvaluationFlags::values | EvaluationFlags::gradients);\\n \\n for (const unsigned int q : phi.quadrature_point_indices())\\n      {\\n        phi.submit_value(-nonlinear_values(cell, q) * phi.get_value(q), q);\\n        phi.submit_gradient(phi.get_gradient(q), q);\\n      }\\n \\n    phi.integrate(EvaluationFlags::values | EvaluationFlags::gradients);\\n  }\\n \\n \\n \\n template <int dim, int fe_degree, typename number>\\n void JacobianOperator<dim, fe_degree, number>::compute_diagonal()\\n  {\\n    this->inverse_diagonal_entries.reset(\\n new DiagonalMatrix<LinearAlgebra::distributed::Vector<number>>());\\n LinearAlgebra::distributed::Vector<number> &inverse_diagonal =\\n      this->inverse_diagonal_entries->get_vector();\\n    this->data->initialize_dof_vector(inverse_diagonal);\\n \\n MatrixFreeTools::compute_diagonal(*this->data,\\n                                      inverse_diagonal,\\n                                      &JacobianOperator::local_compute_diagonal,\\n this);\\n \\n for (auto &diagonal_element : inverse_diagonal)\\n      {\\n        diagonal_element = (std::abs(diagonal_element) > 1.0e-10) ?\\n                             (1.0 / diagonal_element) :\\n                             1.0;\\n      }\\n  }\\n \\n \\n \\n \\n template <int dim, int fe_degree>\\n class GelfandProblem\\n  {\\n public:\\n    GelfandProblem();\\n \\n void run();\\n \\n private:\\n void make_grid();\\n \\n void setup_system();\\n \\n void evaluate_residual(\\n LinearAlgebra::distributed::Vector<double>       &dst,\\n const LinearAlgebra::distributed::Vector<double> &src) const;\\n \\n void local_evaluate_residual(\\n const MatrixFree<dim, double>                    &data,\\n LinearAlgebra::distributed::Vector<double>       &dst,\\n const LinearAlgebra::distributed::Vector<double> &src,\\n const std::pair<unsigned int, unsigned int>      &cell_range) const;\\n \\n void assemble_rhs();\\n \\n double compute_residual(const double alpha);\\n \\n void compute_update();\\n \\n void solve();\\n \\n double compute_solution_norm() const;\\n \\n void output_results(const unsigned int cycle) const;\\n \\n \\n parallel::distributed::Triangulation<dim> triangulation;\\n const MappingQ<dim>                       mapping;\\n \\n \\n const FE_Q<dim> fe;\\n DoFHandler<dim> dof_handler;\\n \\n \\n AffineConstraints<double> constraints;\\n using SystemMatrixType = JacobianOperator<dim, fe_degree, double>;\\n    SystemMatrixType system_matrix;\\n \\n \\n MGConstrainedDoFs mg_constrained_dofs;\\n using LevelMatrixType = JacobianOperator<dim, fe_degree, float>;\\n MGLevelObject<LevelMatrixType>                           mg_matrices;\\n MGLevelObject<LinearAlgebra::distributed::Vector<float>> mg_solution;\\n MGTransferMatrixFree<dim, float>                         mg_transfer;\\n \\n \\n LinearAlgebra::distributed::Vector<double> solution;\\n LinearAlgebra::distributed::Vector<double> newton_update;\\n LinearAlgebra::distributed::Vector<double> system_rhs;\\n \\n \\n unsigned int linear_iterations;\\n \\n \\n ConditionalOStream pcout;\\n \\n \\n TimerOutput computing_timer;\\n  };\\n \\n \\n \\n template <int dim, int fe_degree>\\n  GelfandProblem<dim, fe_degree>::GelfandProblem()\\n    : triangulation(MPI_COMM_WORLD,\\n Triangulation<dim>::limit_level_difference_at_vertices,\\n parallel::distributed::Triangulation<\\n                      dim>::construct_multigrid_hierarchy)\\n    , mapping(fe_degree)\\n    , fe(fe_degree)\\n    , dof_handler(triangulation)\\n    , pcout(std::cout, Utilities::MPI::this_mpi_process(MPI_COMM_WORLD) == 0)\\n    , computing_timer(MPI_COMM_WORLD,\\n                      pcout,\\n TimerOutput::never,\\n TimerOutput::wall_times)\\n  {}\\n \\n \\n \\n \\n template <int dim, int fe_degree>\\n void GelfandProblem<dim, fe_degree>::make_grid()\\n  {\\n TimerOutput::Scope t(computing_timer, \\\"make grid\\\");\\n \\n SphericalManifold<dim>                boundary_manifold;\\n TransfiniteInterpolationManifold<dim> inner_manifold;\\n \\n GridGenerator::hyper_ball(triangulation);\\n \\n triangulation.set_all_manifold_ids(1);\\n triangulation.set_all_manifold_ids_on_boundary(0);\\n \\n triangulation.set_manifold(0, boundary_manifold);\\n \\n    inner_manifold.initialize(triangulation);\\n triangulation.set_manifold(1, inner_manifold);\\n \\n triangulation.refine_global(3 - dim);\\n  }\\n \\n \\n \\n \\n template <int dim, int fe_degree>\\n void GelfandProblem<dim, fe_degree>::setup_system()\\n  {\\n TimerOutput::Scope t(computing_timer, \\\"setup system\\\");\\n \\n    system_matrix.clear();\\n    mg_matrices.clear_elements();\\n \\n    dof_handler.distribute_dofs(fe);\\n    dof_handler.distribute_mg_dofs();\\n \\n    constraints.clear();\\n    constraints.reinit(dof_handler.locally_owned_dofs(),\\n DoFTools::extract_locally_relevant_dofs(dof_handler));\\n DoFTools::make_hanging_node_constraints(dof_handler, constraints);\\n VectorTools::interpolate_boundary_values(dof_handler,\\n                                             0,\\n Functions::ZeroFunction<dim>(),\\n                                             constraints);\\n    constraints.close();\\n \\n    {\\n typename MatrixFree<dim, double>::AdditionalData additional_data;\\n      additional_data.tasks_parallel_scheme =\\n MatrixFree<dim, double>::AdditionalData::partition_color;\\n      additional_data.mapping_update_flags =\\n        (update_values | update_gradients | update_JxW_values |\\n update_quadrature_points);\\n auto system_mf_storage = std::make_shared<MatrixFree<dim, double>>();\\n      system_mf_storage->reinit(mapping,\\n                                dof_handler,\\n                                constraints,\\n QGauss<1>(fe.degree + 1),\\n                                additional_data);\\n \\n      system_matrix.initialize(system_mf_storage);\\n    }\\n \\n    system_matrix.initialize_dof_vector(solution);\\n    system_matrix.initialize_dof_vector(newton_update);\\n    system_matrix.initialize_dof_vector(system_rhs);\\n \\n \\n const unsigned int nlevels = triangulation.n_global_levels();\\n    mg_matrices.resize(0, nlevels - 1);\\n    mg_solution.resize(0, nlevels - 1);\\n \\n const std::set<types::boundary_id> dirichlet_boundary_ids = {0};\\n    mg_constrained_dofs.initialize(dof_handler);\\n    mg_constrained_dofs.make_zero_boundary_constraints(dof_handler,\\n                                                       dirichlet_boundary_ids);\\n \\n    mg_transfer.initialize_constraints(mg_constrained_dofs);\\n    mg_transfer.build(dof_handler);\\n \\n for (unsigned int level = 0; level < nlevels; ++level)\\n      {\\n AffineConstraints<double> level_constraints(\\n          dof_handler.locally_owned_mg_dofs(level),\\n DoFTools::extract_locally_relevant_level_dofs(dof_handler, level));\\n \\n for (const types::global_dof_index dof_index :\\n             mg_constrained_dofs.get_boundary_indices(level))\\n          level_constraints.constrain_dof_to_zero(dof_index);\\n        level_constraints.close();\\n \\n typename MatrixFree<dim, float>::AdditionalData additional_data;\\n        additional_data.tasks_parallel_scheme =\\n MatrixFree<dim, float>::AdditionalData::partition_color;\\n        additional_data.mapping_update_flags =\\n          (update_values | update_gradients | update_JxW_values |\\n update_quadrature_points);\\n        additional_data.mg_level = level;\\n auto mg_mf_storage_level = std::make_shared<MatrixFree<dim, float>>();\\n        mg_mf_storage_level->reinit(mapping,\\n                                    dof_handler,\\n                                    level_constraints,\\n QGauss<1>(fe.degree + 1),\\n                                    additional_data);\\n \\n        mg_matrices[level].initialize(mg_mf_storage_level,\\n                                      mg_constrained_dofs,\\n level);\\n        mg_matrices[level].initialize_dof_vector(mg_solution[level]);\\n      }\\n  }\\n \\n \\n \\n \\n template <int dim, int fe_degree>\\n void GelfandProblem<dim, fe_degree>::evaluate_residual(\\n LinearAlgebra::distributed::Vector<double>       &dst,\\n const LinearAlgebra::distributed::Vector<double> &src) const\\n {\\n auto matrix_free = system_matrix.get_matrix_free();\\n \\n    matrix_free->cell_loop(\\n      &GelfandProblem::local_evaluate_residual, this, dst, src, true);\\n  }\\n \\n \\n \\n \\n template <int dim, int fe_degree>\\n void GelfandProblem<dim, fe_degree>::local_evaluate_residual(\\n const MatrixFree<dim, double>                    &data,\\n LinearAlgebra::distributed::Vector<double>       &dst,\\n const LinearAlgebra::distributed::Vector<double> &src,\\n const std::pair<unsigned int, unsigned int>      &cell_range) const\\n {\\n FEEvaluation<dim, fe_degree, fe_degree + 1, 1, double> phi(data);\\n \\n for (unsigned int cell = cell_range.first; cell < cell_range.second; ++cell)\\n      {\\n        phi.reinit(cell);\\n \\n        phi.read_dof_values_plain(src);\\n        phi.evaluate(EvaluationFlags::values | EvaluationFlags::gradients);\\n \\n for (const unsigned int q : phi.quadrature_point_indices())\\n          {\\n            phi.submit_value(-std::exp(phi.get_value(q)), q);\\n            phi.submit_gradient(phi.get_gradient(q), q);\\n          }\\n \\n        phi.integrate_scatter(EvaluationFlags::values |\\n EvaluationFlags::gradients,\\n                              dst);\\n      }\\n  }\\n \\n \\n \\n \\n template <int dim, int fe_degree>\\n void GelfandProblem<dim, fe_degree>::assemble_rhs()\\n  {\\n TimerOutput::Scope t(computing_timer, \\\"assemble right hand side\\\");\\n \\n    evaluate_residual(system_rhs, solution);\\n \\n    system_rhs *= -1.0;\\n  }\\n \\n \\n \\n \\n template <int dim, int fe_degree>\\n double GelfandProblem<dim, fe_degree>::compute_residual(const double alpha)\\n  {\\n TimerOutput::Scope t(computing_timer, \\\"compute residual\\\");\\n \\n LinearAlgebra::distributed::Vector<double> residual;\\n LinearAlgebra::distributed::Vector<double> evaluation_point;\\n \\n    system_matrix.initialize_dof_vector(residual);\\n    system_matrix.initialize_dof_vector(evaluation_point);\\n \\n    evaluation_point = solution;\\n if (alpha > 1e-12)\\n      {\\n        evaluation_point.add(alpha, newton_update);\\n      }\\n \\n    evaluate_residual(residual, evaluation_point);\\n \\n return residual.l2_norm();\\n  }\\n \\n \\n \\n \\n template <int dim, int fe_degree>\\n void GelfandProblem<dim, fe_degree>::compute_update()\\n  {\\n TimerOutput::Scope t(computing_timer, \\\"compute update\\\");\\n \\n    solution.update_ghost_values();\\n \\n    system_matrix.evaluate_newton_step(solution);\\n \\n \\n    mg_transfer.interpolate_to_mg(dof_handler, mg_solution, solution);\\n \\n \\n using SmootherType =\\n PreconditionChebyshev<LevelMatrixType,\\n LinearAlgebra::distributed::Vector<float>>;\\n mg::SmootherRelaxation<SmootherType,\\n LinearAlgebra::distributed::Vector<float>>\\n                                                         mg_smoother;\\n MGLevelObject<typename SmootherType::AdditionalData> smoother_data;\\n    smoother_data.resize(0, triangulation.n_global_levels() - 1);\\n for (unsigned int level = 0; level < triangulation.n_global_levels();\\n         ++level)\\n      {\\n if (level > 0)\\n          {\\n            smoother_data[level].smoothing_range     = 15.;\\n            smoother_data[level].degree              = 4;\\n            smoother_data[level].eig_cg_n_iterations = 10;\\n          }\\n else\\n          {\\n            smoother_data[0].smoothing_range = 1e-3;\\n            smoother_data[0].degree          = numbers::invalid_unsigned_int;\\n            smoother_data[0].eig_cg_n_iterations = mg_matrices[0].m();\\n          }\\n \\n        mg_matrices[level].evaluate_newton_step(mg_solution[level]);\\n        mg_matrices[level].compute_diagonal();\\n \\n        smoother_data[level].preconditioner =\\n          mg_matrices[level].get_matrix_diagonal_inverse();\\n      }\\n    mg_smoother.initialize(mg_matrices, smoother_data);\\n \\n MGCoarseGridApplySmoother<LinearAlgebra::distributed::Vector<float>>\\n      mg_coarse;\\n    mg_coarse.initialize(mg_smoother);\\n \\n mg::Matrix<LinearAlgebra::distributed::Vector<float>> mg_matrix(\\n      mg_matrices);\\n \\n MGLevelObject<MatrixFreeOperators::MGInterfaceOperator<LevelMatrixType>>\\n      mg_interface_matrices;\\n    mg_interface_matrices.resize(0, triangulation.n_global_levels() - 1);\\n for (unsigned int level = 0; level < triangulation.n_global_levels();\\n         ++level)\\n      {\\n        mg_interface_matrices[level].initialize(mg_matrices[level]);\\n      }\\n mg::Matrix<LinearAlgebra::distributed::Vector<float>> mg_interface(\\n      mg_interface_matrices);\\n \\n Multigrid<LinearAlgebra::distributed::Vector<float>> mg(\\n      mg_matrix, mg_coarse, mg_transfer, mg_smoother, mg_smoother);\\n mg.set_edge_matrices(mg_interface, mg_interface);\\n \\n PreconditionMG<dim,\\n LinearAlgebra::distributed::Vector<float>,\\n MGTransferMatrixFree<dim, float>>\\n      preconditioner(dof_handler, mg, mg_transfer);\\n \\n \\n SolverControl solver_control(100, 1.e-12);\\n SolverCG<LinearAlgebra::distributed::Vector<double>> cg(solver_control);\\n \\n    newton_update = 0.0;\\n \\n    cg.solve(system_matrix, newton_update, system_rhs, preconditioner);\\n \\n    constraints.distribute(newton_update);\\n \\n    linear_iterations = solver_control.last_step();\\n \\n \\n    solution.zero_out_ghost_values();\\n  }\\n \\n \\n \\n \\n template <int dim, int fe_degree>\\n void GelfandProblem<dim, fe_degree>::solve()\\n  {\\n TimerOutput::Scope t(computing_timer, \\\"solve\\\");\\n \\n \\n const unsigned int itmax = 10;\\n const double       TOLf  = 1e-12;\\n const double       TOLx  = 1e-10;\\n \\n \\n Timer solver_timer;\\n    solver_timer.start();\\n \\n \\n for (unsigned int newton_step = 1; newton_step <= itmax; ++newton_step)\\n      {\\n        assemble_rhs();\\n        compute_update();\\n \\n \\n const double ERRx = newton_update.l2_norm();\\n const double ERRf = compute_residual(1.0);\\n \\n \\n        solution.add(1.0, newton_update);\\n \\n \\n        pcout << \\\"   Nstep \\\" << newton_step << \\\", errf = \\\" << ERRf\\n              << \\\", errx = \\\" << ERRx << \\\", it = \\\" << linear_iterations\\n              << std::endl;\\n \\n \\n if (ERRf < TOLf || ERRx < TOLx)\\n          {\\n            solver_timer.stop();\\n \\n            pcout << \\\"Convergence step \\\" << newton_step << \\\" value \\\" << ERRf\\n                  << \\\" (used wall time: \\\" << solver_timer.wall_time() << \\\" s)\\\"\\n                  << std::endl;\\n \\n break;\\n          }\\n else if (newton_step == itmax)\\n          {\\n            solver_timer.stop();\\n            pcout << \\\"WARNING: No convergence of Newton's method after \\\"\\n                  << newton_step << \\\" steps.\\\" << std::endl;\\n \\n break;\\n          }\\n      }\\n  }\\n \\n \\n \\n \\n template <int dim, int fe_degree>\\n double GelfandProblem<dim, fe_degree>::compute_solution_norm() const\\n {\\n    solution.update_ghost_values();\\n \\n Vector<float> norm_per_cell(triangulation.n_active_cells());\\n \\n VectorTools::integrate_difference(mapping,\\n                                      dof_handler,\\n                                      solution,\\n Functions::ZeroFunction<dim>(),\\n                                      norm_per_cell,\\n QGauss<dim>(fe.degree + 2),\\n VectorTools::H1_seminorm);\\n \\n    solution.zero_out_ghost_values();\\n \\n return VectorTools::compute_global_error(triangulation,\\n                                             norm_per_cell,\\n VectorTools::H1_seminorm);\\n  }\\n \\n \\n \\n \\n template <int dim, int fe_degree>\\n void\\n  GelfandProblem<dim, fe_degree>::output_results(const unsigned int cycle) const\\n {\\n if (triangulation.n_global_active_cells() > 1e6)\\n return;\\n \\n    solution.update_ghost_values();\\n \\n DataOut<dim> data_out;\\n    data_out.attach_dof_handler(dof_handler);\\n    data_out.add_data_vector(solution, \\\"solution\\\");\\n \\n Vector<float> subdomain(triangulation.n_active_cells());\\n for (unsigned int i = 0; i < subdomain.size(); ++i)\\n      {\\n        subdomain(i) = triangulation.locally_owned_subdomain();\\n      }\\n    data_out.add_data_vector(subdomain, \\\"subdomain\\\");\\n \\n    data_out.build_patches(mapping,\\n                           fe.degree,\\n DataOut<dim>::curved_inner_cells);\\n \\n DataOutBase::VtkFlags flags;\\n    flags.compression_level = DataOutBase::CompressionLevel::best_speed;\\n    data_out.set_flags(flags);\\n    data_out.write_vtu_with_pvtu_record(\\n \\\"./\\\", \\\"solution_\\\" + std::to_string(dim) + \\\"d\\\", cycle, MPI_COMM_WORLD, 3);\\n \\n    solution.zero_out_ghost_values();\\n  }\\n \\n \\n \\n \\n template <int dim, int fe_degree>\\n void GelfandProblem<dim, fe_degree>::run()\\n  {\\n    {\\n const unsigned int n_ranks =\\n Utilities::MPI::n_mpi_processes(MPI_COMM_WORLD);\\n const unsigned int n_vect_doubles = VectorizedArray<double>::size();\\n const unsigned int n_vect_bits    = 8 * sizeof(double) * n_vect_doubles;\\n \\n      std::string DAT_header = \\\"START DATE: \\\" + Utilities::System::get_date() +\\n \\\", TIME: \\\" + Utilities::System::get_time();\\n      std::string MPI_header = \\\"Running with \\\" + std::to_string(n_ranks) +\\n \\\" MPI process\\\" + (n_ranks > 1 ? \\\"es\\\" : \\\"\\\");\\n      std::string VEC_header =\\n \\\"Vectorization over \\\" + std::to_string(n_vect_doubles) +\\n \\\" doubles = \\\" + std::to_string(n_vect_bits) + \\\" bits (\\\" +\\n Utilities::System::get_current_vectorization_level() +\\n \\\"), VECTORIZATION_LEVEL=\\\" +\\n        std::to_string(DEAL_II_COMPILER_VECTORIZATION_LEVEL);\\n      std::string SOL_header = \\\"Finite element space: \\\" + fe.get_name();\\n \\n      pcout << std::string(80, '=') << std::endl;\\n      pcout << DAT_header << std::endl;\\n      pcout << std::string(80, '-') << std::endl;\\n \\n      pcout << MPI_header << std::endl;\\n      pcout << VEC_header << std::endl;\\n      pcout << SOL_header << std::endl;\\n \\n      pcout << std::string(80, '=') << std::endl;\\n    }\\n \\n \\n for (unsigned int cycle = 0; cycle < 9 - dim; ++cycle)\\n      {\\n        pcout << std::string(80, '-') << std::endl;\\n        pcout << \\\"Cycle \\\" << cycle << std::endl;\\n        pcout << std::string(80, '-') << std::endl;\\n \\n \\n if (cycle == 0)\\n          {\\n            make_grid();\\n          }\\n else\\n          {\\n triangulation.refine_global(1);\\n          }\\n \\n \\n Timer timer;\\n \\n        pcout << \\\"Set up system...\\\" << std::endl;\\n        setup_system();\\n \\n        pcout << \\\"   Triangulation: \\\" << triangulation.n_global_active_cells()\\n              << \\\" cells\\\" << std::endl;\\n        pcout << \\\"   DoFHandler:    \\\" << dof_handler.n_dofs() << \\\" DoFs\\\"\\n              << std::endl;\\n        pcout << std::endl;\\n \\n \\n        pcout << \\\"Solve using Newton's method...\\\" << std::endl;\\n        solve();\\n        pcout << std::endl;\\n \\n \\n        timer.stop();\\n        pcout << \\\"Time for setup+solve (CPU/Wall) \\\" << timer.cpu_time() << '/'\\n              << timer.wall_time() << \\\" s\\\" << std::endl;\\n        pcout << std::endl;\\n \\n \\n        pcout << \\\"Output results...\\\" << std::endl;\\n const double norm = compute_solution_norm();\\n        output_results(cycle);\\n \\n        pcout << \\\"  H1 seminorm: \\\" << norm << std::endl;\\n        pcout << std::endl;\\n \\n \\n        computing_timer.print_summary();\\n        computing_timer.reset();\\n      }\\n  }\\n} // namespace Step66\\n \\n \\n \\n \\nint main(int argc, char *argv[])\\n{\\n try\\n    {\\n using namespace Step66;\\n \\n Utilities::MPI::MPI_InitFinalize mpi_init(argc, argv, 1);\\n \\n      {\\n        GelfandProblem<2, 4> gelfand_problem;\\n        gelfand_problem.run();\\n      }\\n \\n      {\\n        GelfandProblem<3, 4> gelfand_problem;\\n        gelfand_problem.run();\\n      }\\n    }\\n catch (std::exception &exc)\\n    {\\n      std::cerr << std::endl\\n                << std::endl\\n                << \\\"----------------------------------------------------\\\"\\n                << std::endl;\\n      std::cerr << \\\"Exception on processing: \\\" << std::endl\\n                << exc.what() << std::endl\\n                << \\\"Aborting!\\\" << std::endl\\n                << \\\"----------------------------------------------------\\\"\\n                << std::endl;\\n return 1;\\n    }\\n catch (...)\\n    {\\n      std::cerr << std::endl\\n                << std::endl\\n                << \\\"----------------------------------------------------\\\"\\n                << std::endl;\\n      std::cerr << \\\"Unknown exception!\\\" << std::endl\\n                << \\\"Aborting!\\\" << std::endl\\n                << \\\"----------------------------------------------------\\\"\\n                << std::endl;\\n return 1;\\n    }\\n \\n return 0;\\n}\\naffine_constraints.h\\nDataOutInterface::set_flagsvoid set_flags(const FlagType &flags)Definition data_out_base.cc:8863\\nDataOutInterface::write_vtu_with_pvtu_recordstd::string write_vtu_with_pvtu_record(const std::string &directory, const std::string &filename_without_extension, const unsigned int counter, const MPI_Comm mpi_communicator, const unsigned int n_digits_for_counter=numbers::invalid_unsigned_int, const unsigned int n_groups=0) constDefinition data_out_base.cc:7854\\nDataOut_DoFData::add_data_vectorvoid add_data_vector(const VectorType &data, const std::vector< std::string > &names, const DataVectorType type=type_automatic, const std::vector< DataComponentInterpretation::DataComponentInterpretation > &data_component_interpretation={})Definition data_out_dof_data.h:1069\\nDataOut::build_patchesvirtual void build_patches(const unsigned int n_subdivisions=0)Definition data_out.cc:1062\\nLinearAlgebra::distributed::Vector::zero_out_ghost_valuesvoid zero_out_ghost_values() const\\nLinearAlgebra::distributed::Vector::update_ghost_valuesvoid update_ghost_values() const\\nLinearAlgebra::distributed::Vector::l2_normreal_type l2_norm() const\\nMatrixFree::initialize_dof_vectorvoid initialize_dof_vector(VectorType &vec, const unsigned int dof_handler_index=0) const\\nMatrixFree::cell_loopvoid cell_loop(const std::function< void(const MatrixFree< dim, Number, VectorizedArrayType > &, OutVector &, const InVector &, const std::pair< unsigned int, unsigned int > &)> &cell_operation, OutVector &dst, const InVector &src, const bool zero_dst_vector=false) const\\nTimer::cpu_timedouble cpu_time() constDefinition timer.cc:234\\nTimer::wall_timedouble wall_time() constDefinition timer.cc:262\\nTimer::stopdouble stop()Definition timer.cc:193\\nTransfiniteInterpolationManifold::initializevoid initialize(const Triangulation< dim, spacedim > &triangulation)Definition manifold_lib.cc:1655\\nVector::reinitvirtual void reinit(const size_type N, const bool omit_zeroing_entries=false)\\ndof_accessor.h\\ndof_handler.h\\ndof_tools.h\\nfe_evaluation.h\\nfe_q.h\\nfunction.h\\nmanifold_lib.h\\ntria.h\\ngrid_generator.h\\ngrid_out.h\\nmapping_q.h\\nmatrix_free.h\\nmg_coarse.h\\nmg_constrained_dofs.h\\nmg_matrix.h\\nmg_smoother.h\\nmg_tools.h\\nmg_transfer_matrix_free.h\\nmultigrid.h\\nLocalIntegrators::Divergence::normdouble norm(const FEValuesBase< dim > &fe, const ArrayView< const std::vector< Tensor< 1, dim > > > &Du)Definition divergence.h:471\\nPhysics::Elasticity::Kinematics::eSymmetricTensor< 2, dim, Number > e(const Tensor< 2, dim, Number > &F)\\nTriangulationDescription::construct_multigrid_hierarchy@ construct_multigrid_hierarchyDefinition tria_description.h:319\\nUtilities::MPI::this_mpi_processunsigned int this_mpi_process(const MPI_Comm mpi_communicator)Definition mpi.cc:107\\nWorkStream::internal::tbb_no_coloring::runvoid run(const Iterator &begin, const std_cxx20::type_identity_t< Iterator > &end, Worker worker, Copier copier, const ScratchData &sample_scratch_data, const CopyData &sample_copy_data, const unsigned int queue_length, const unsigned int chunk_size)Definition work_stream.h:471\\ninternal::TriangulationImplementation::n_cellsunsigned int n_cells(const internal::TriangulationImplementation::NumberCache< 1 > &c)Definition tria.cc:14883\\nstd::abs::VectorizedArray< Number, width > abs(const ::VectorizedArray< Number, width > &)Definition vectorization.h:6927\\ndata_out.h\\noperators.h\\nprecondition.h\\nquadrature_lib.h\\nsolver_cg.h\\nMatrixFree::AdditionalData::mg_levelunsigned int mg_levelDefinition matrix_free.h:451\\nMatrixFree::AdditionalData::mapping_update_flagsUpdateFlags mapping_update_flagsDefinition matrix_free.h:373\\ntimer.h\\ntools.h\\ntria_accessor.h\\ntria_iterator.h\\nvector.h\\nvector_tools.h\\nvectorization.h\\n \\n\\n\\n\\n\\nGenerated by\\u00a0 1.11.0\\n\\n\\n\\n\\n\", \"type\": \"Document\"}}]"