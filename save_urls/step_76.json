"[{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"document\", \"Document\"], \"kwargs\": {\"metadata\": {\"source\": \"https://dealii.org/current/doxygen/deal.II/step_76.html\", \"content_type\": \"text/html\", \"title\": \"The deal.II Library: The step-76 tutorial program\", \"language\": \"en-US\"}, \"page_content\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\nThe deal.II Library: The step-76 tutorial program\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\u00a0Reference documentation for deal.II version 9.6.0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\\(\\\\newcommand{\\\\dealvcentcolon}{\\\\mathrel{\\\\mathop{:}}}\\\\)\\n\\\\(\\\\newcommand{\\\\dealcoloneq}{\\\\dealvcentcolon\\\\mathrel{\\\\mkern-1.2mu}=}\\\\)\\n\\\\(\\\\newcommand{\\\\jump}[1]{\\\\left[\\\\!\\\\left[ #1 \\\\right]\\\\!\\\\right]}\\\\)\\n\\\\(\\\\newcommand{\\\\average}[1]{\\\\left\\\\{\\\\!\\\\left\\\\{ #1 \\\\right\\\\}\\\\!\\\\right\\\\}}\\\\)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLoading...\\nSearching...\\nNo Matches\\n\\n\\n\\n\\n\\n\\n\\nThe step-76 tutorial program\\n\\n\\nThis tutorial depends on step-67.\\n\\n\\nTable of contents\\n\\n\\n Introduction\\n\\nShared-memory and hybrid parallelization with MPI-3.0\\n\\nMotivation\\nBasic MPI-3.0 commands\\nMPI-3.0 and LinearAlgebra::distributed::Vector\\nMPI-3.0 and MatrixFree\\n\\nCell-centric loops\\n\\nMotivation: FCL vs. CCL\\nCell-centric loops and MatrixFree\\n\\nProviding lambdas to MatrixFree loops\\nVectorizedArrayType\\n\\n The commented program\\n\\nParameters and utility functions\\nEuler operator using a cell-centric loop and MPI-3.0 shared memory\\n\\n\\n Results\\n\\nPossibilities for extensions\\n\\nExtension to the compressible Navier-Stokes equations\\nBlock Gauss-Seidel-like preconditioners\\n\\n\\n The plain program\\n   \\n\\n\\n\\n This program was contributed by Martin Kronbichler, Peter Munch, and David Schneider. Many of the features shown here have been added to deal.II during and for the development of the deal.II-based, efficient, matrix-free finite-element library for high-dimensional partial differential equations hyper.deal (see https://github.com/hyperdeal/hyperdeal). For more details and for applications of the presented features in slightly different contexts (high-dimensional advection equation and Vlasov-Poisson equations) see the release paper [158].\\nThis work was partly supported by the German Research Foundation (DFG) through the project \\\"High-order discontinuous Galerkin for the exa-scale\\\" (ExaDG) within the priority program \\\"Software for Exascale Computing\\\" (SPPEXA) and by the Bavarian government through the project \\\"High-order matrix-free finite\\nelement implementations with hybrid parallelization and improved data locality\\\" within the KONWIHR program. \\n Introduction\\nThis tutorial program solves the Euler equations of fluid dynamics, using an explicit time integrator with the matrix-free framework applied to a high-order discontinuous Galerkin discretization in space. The numerical approach used here is identical to that used in step-67, however, we utilize different advanced MatrixFree techniques to reach even a higher throughput.\\nThe two main features of this tutorial are:\\nthe usage of shared-memory features from MPI-3.0 and\\nthe usage of cell-centric loops, which allow to write to the global vector only once and, therefore, are ideal for the usage of shared memory.\\n\\nFurther topics we discuss in this tutorial are the usage and benefits of the template argument VectorizedArrayType (instead of simply using VectorizedArray<Number>) as well as the possibility to pass lambdas to MatrixFree loops.\\nFor details on the numerics, we refer to the documentation of step-67. We concentrate here only on the key differences.\\nShared-memory and hybrid parallelization with MPI-3.0\\nMotivation\\nThere exist many shared-memory libraries that are based on threads like TBB, OpenMP, or TaskFlow. Integrating such libraries into existing MPI programs allows one to use shared memory. However, these libraries come with an overhead for the programmer, since all parallelizable code sections have to be found and transformed according to the library used, including the difficulty when some third-party numerical library, like an iterative solver package, only relies on MPI.\\nConsidering a purely MPI-parallelized FEM application, one can identify that the major time and memory benefit of using shared memory would come from accessing the part of the solution vector owned by the processes on the same compute node without the need to make explicit copies and buffering them. Fur this propose, MPI-3.0 provides shared-memory features based on so-called windows, where processes can directly access the data of the neighbors on the same shared-memory domain.\\nBasic MPI-3.0 commands\\nA few relevant MPI-3.0 commands are worth discussing in detail. A new MPI communicator comm_sm, which consists of processes from the communicator comm that have access to the same shared memory, can be created via:\\nMPI_Comm_split_type(comm, MPI_COMM_TYPE_SHARED, rank, MPI_INFO_NULL, &comm_sm);\\ncomm*braid_SplitCommworld & commDefinition parallel_in_time.h:1981\\nThe following code snippet shows the simplified allocation routines of shared memory for the value type T and the size local_size, as well as, how to query pointers to the data belonging to processes in the same shared-memory domain:\\nMPI_Win          win;         // window\\nT *              data_this;   // pointer to locally-owned data\\nstd::vector<T *> data_others; // pointers to shared data\\n \\n// configure shared memory\\nMPI_Info info;\\nMPI_Info_create(&info);\\nMPI_Info_set(info, \\\"alloc_shared_noncontig\\\", \\\"true\\\");\\n \\n// allocate shared memory\\nMPI_Win_allocate_shared(local_size * sizeof(T), sizeof(T), info, comm_sm, &data_this, &win);\\n \\n// get pointers to the shared data owned by the processes in the same sm domain\\ndata_others.resize(size_sm);\\nint disp_unit = 0; // displacement size - an output parameter we don't need right now\\nMPI_Aint ssize = 0; // window size - an output parameter we don't need right now\\nfor (int i = 0; i < size_sm; ++i)\\n  MPI_Win_shared_query(win, i, &ssize, &disp_unit, &data_others[i]);\\n \\nAssert(data_this == data_others[rank_sm], ExcMessage(\\\"Something went wrong!\\\"));\\nAssert#define Assert(cond, exc)Definition exceptions.h:1638\\nOnce the data is not needed anymore, the window has to be freed, which also frees the locally-owned data:\\nMPI_Win_free(&win);\\nMPI-3.0 and LinearAlgebra::distributed::Vector\\nThe commands mentioned in the last section are integrated into LinearAlgebra::distributed::Vector and are used to allocate shared memory if an optional (second) communicator is provided to the reinit()-functions.\\nFor example, a vector can be set up with a partitioner (containing the global communicator) and a sub-communicator (containing the processes on the same compute node): vec.reinit(partitioner, comm_sm);\\nLocally owned values and ghost values can be processed as usual. However, now users also have read access to the values of the shared-memory neighbors via the function: const std::vector<ArrayView<const Number>> &\\nLinearAlgebra::distributed::Vector::shared_vector_data() const;\\nLinearAlgebra::distributed::Vector::shared_vector_dataconst std::vector< ArrayView< const Number > > & shared_vector_data() const\\nMPI-3.0 and MatrixFree\\nWhile LinearAlgebra::distributed::Vector provides the option to allocate shared memory and to access the values of shared memory of neighboring processes in a coordinated way, it does not actually exploit the benefits of the usage of shared memory itself.\\nThe MatrixFree infrastructure, however, does:\\nOn the one hand, within the matrix-free loops MatrixFree::loop(), MatrixFree::cell_loop(), and MatrixFree::loop_cell_centric(), only ghost values that need to be updated are updated. Ghost values from shared-memory neighbors can be accessed directly, making buffering, i.e., copying of the values into the ghost region of a vector possibly redundant. To deal with possible race conditions, necessary synchronizations are performed within MatrixFree. In the case that values have to be buffered, values are copied directly from the neighboring shared-memory process, bypassing more expensive MPI operations based on MPI_ISend and MPI_IRecv.\\nOn the other hand, classes like FEEvaluation and FEFaceEvaluation can read directly from the shared memory, so buffering the values is indeed not necessary in certain cases.\\n\\nTo be able to use the shared-memory capabilities of MatrixFree, MatrixFree has to be appropriately configured by providing the user-created sub-communicator:\\ntypename MatrixFree<dim, Number>::AdditionalData additional_data;\\n \\n// set flags as usual (not shown)\\n \\nadditional_data.communicator_sm = comm_sm;\\n \\ndata.reinit(mapping, dof_handler, constraint, quadrature, additional_data);\\nMatrixFree::AdditionalDataDefinition matrix_free.h:184\\nMatrixFree::AdditionalData::communicator_smMPI_Comm communicator_smDefinition matrix_free.h:553\\nCell-centric loops\\nMotivation: FCL vs. CCL\\n\\\"Face-centric loops\\\" (short FCL) visit cells and faces (inner and boundary ones) in separate loops. As a consequence, each entity is visited only once and fluxes between cells are evaluated only once. How to perform face-centric loops with the help of MatrixFree::loop() by providing three functions (one for the cell integrals, one for the inner, and one for the boundary faces) has been presented in step-59 and step-67.\\n\\\"Cell-centric loops\\\" (short CCL or ECL (for element-centric loops) in the hyper.deal release paper), in contrast, process a cell and in direct succession process all its faces (i.e., visit all faces twice). Their benefit has become clear for modern CPU processor architecture in the literature [135], although this kind of loop implies that fluxes have to be computed twice (for each side of an interior face). CCL has two primary advantages:\\nOn the one hand, entries in the solution vector are written exactly once back to main memory in the case of CCL, while in the case of FCL at least once despite of cache-efficient scheduling of cell and face loops-due to cache capacity misses.\\nOn the other hand, since each entry of the solution vector is accessed exactly once, no synchronization between threads is needed while accessing the solution vector in the case of CCL. This absence of race conditions during writing into the destination vector makes CCL particularly suitable for shared-memory parallelization.\\n\\nOne should also note that although fluxes are computed twice in the case of CCL, this does not automatically translate into doubling of the computation, since values already interpolated to the cell quadrature points can be interpolated to a face with a simple 1D interpolation.\\nCell-centric loops and MatrixFree\\nFor cell-centric loop implementations, the function MatrixFree::loop_cell_centric() can be used, to which the user can pass a function that should be performed on each cell.\\nTo derive an appropriate function, which can be passed in MatrixFree::loop_cell_centric(), one might, in principle, transform/merge the following three functions, which can be passed to a MatrixFree::loop():\\nmatrix_free.template loop<VectorType, VectorType>(\\n  [&](const auto &data, auto &dst, const auto &src, const auto range) {\\n // operation performed on cells\\n \\n FEEvaluation<dim, degree, degree + 1, 1, Number> phi(data);\\n for (unsigned int cell = range.first; cell < range.second; ++cell)\\n      {\\n        phi.reinit(cell);\\n        phi.gather_evaluate(src, cell_evaluation_flags);\\n \\n // some operations on the cell quadrature points\\n \\n        phi.integrate_scatter(cell_evaluation_flags, dst);\\n      }\\n  },\\n  [&](const auto &data, auto &dst, const auto &src, const auto range) {\\n // operation performed inner faces\\n \\n FEFaceEvaluation<dim, degree, degree + 1, 1, Number> phi_m(data, /*is_interior_face=*/true);\\n FEFaceEvaluation<dim, degree, degree + 1, 1, Number> phi_p(data, /*is_interior_face=*/false);\\n \\n for (unsigned int face = range.first; face < range.second; ++face)\\n      {\\n        phi_m.reinit(face);\\n        phi_m.gather_evaluate(src, face_evaluation_flags);\\n        phi_p.reinit(face);\\n        phi_p.gather_evaluate(src, face_evaluation_flags);\\n \\n // some operations on the face quadrature points\\n \\n        phi_m.integrate_scatter(face_evaluation_flags, dst);\\n        phi_p.integrate_scatter(face_evaluation_flags, dst);\\n      }\\n  },\\n  [&](const auto &data, auto &dst, const auto &src, const auto range) {\\n // operation performed boundary faces\\n \\n FEFaceEvaluation<dim, degree, degree + 1, 1, Number> phi_m(data, /*is_interior_face=*/true);\\n \\n for (unsigned int face = range.first; face < range.second; ++face)\\n      {\\n        phi_m.reinit(face);\\n        phi_m.gather_evaluate(src, face_evaluation_flags);\\n \\n // some operations on the face quadrature points\\n \\n        phi_m.integrate_scatter(face_evaluation_flags, dst);\\n      }\\n  },\\n  dst,\\n  src);\\nFEEvaluationDefinition fe_evaluation.h:1355\\nFEFaceEvaluationDefinition fe_evaluation.h:1818\\nin the following way:\\nmatrix_free.template loop_cell_centric<VectorType, VectorType>(\\n  [&](const auto &data, auto &dst, const auto &src, const auto range) {\\n FEEvaluation<dim, degree, degree + 1, 1, Number>     phi(data);\\n FEFaceEvaluation<dim, degree, degree + 1, 1, Number> phi_m(data, /*is_interior_face=*/true);\\n FEFaceEvaluation<dim, degree, degree + 1, 1, Number> phi_p(data, /*is_interior_face=*/false);\\n \\n for (unsigned int cell = range.first; cell < range.second; ++cell)\\n      {\\n        phi.reinit(cell);\\n        phi.gather_evaluate(src, cell_evaluation_flags);\\n \\n // some operations on the cell quadrature points\\n \\n        phi.integrate_scatter(cell_evaluation_flags, dst);\\n \\n // loop over all faces of cell\\n for (unsigned int face = 0; face < GeometryInfo<dim>::faces_per_cell; ++face)\\n          {\\n if (data.get_faces_by_cells_boundary_id(cell, face)[0] ==\\n numbers::internal_face_boundary_id)\\n              {\\n // internal face\\n                phi_m.reinit(cell, face);\\n                phi_m.gather_evaluate(src, face_evaluation_flags);\\n                phi_p.reinit(cell, face);\\n                phi_p.gather_evaluate(src, face_evaluation_flags);\\n \\n // some operations on the face quadrature points\\n \\n                phi_m.integrate_scatter(face_evaluation_flags, dst);\\n              }\\n else\\n              {\\n // boundary face\\n                phi_m.reinit(cell, face);\\n                phi_m.gather_evaluate(src, face_evaluation_flags);\\n \\n // some operations on the face quadrature points\\n \\n                phi_m.integrate_scatter(face_evaluation_flags, dst);\\n              }\\n          }\\n      }\\n  },\\n  dst,\\n  src);\\nnumbers::internal_face_boundary_idconst types::boundary_id internal_face_boundary_idDefinition types.h:312\\nIt should be noted that FEFaceEvaluation is initialized now with two numbers, the cell number and the local face number. The given example only highlights how to transform face-centric loops into cell-centric loops and is by no means efficient, since data is read and written multiple times from and to the global vector as well as computations are performed redundantly. Below, we will discuss advanced techniques that target these issues.\\nTo be able to use MatrixFree::loop_cell_centric(), following flags of MatrixFree::AdditionalData have to be enabled:\\ntypename MatrixFree<dim, Number>::AdditionalData additional_data;\\n \\n// set flags as usual (not shown)\\n \\nadditional_data.hold_all_faces_to_owned_cells       = true;\\nadditional_data.mapping_update_flags_faces_by_cells =\\n  additional_data.mapping_update_flags_inner_faces |\\n  additional_data.mapping_update_flags_boundary_faces;\\n \\ndata.reinit(mapping, dof_handler, constraint, quadrature, additional_data);\\nMatrixFree::AdditionalData::hold_all_faces_to_owned_cellsbool hold_all_faces_to_owned_cellsDefinition matrix_free.h:502\\nMatrixFree::AdditionalData::mapping_update_flags_inner_facesUpdateFlags mapping_update_flags_inner_facesDefinition matrix_free.h:413\\nMatrixFree::AdditionalData::mapping_update_flags_boundary_facesUpdateFlags mapping_update_flags_boundary_facesDefinition matrix_free.h:393\\nMatrixFree::AdditionalData::mapping_update_flags_faces_by_cellsUpdateFlags mapping_update_flags_faces_by_cellsDefinition matrix_free.h:441\\nIn particular, these flags enable that the internal data structures are set up for all faces of the cells.\\nCurrently, cell-centric loops in deal.II only work for uniformly refined meshes and if no constraints are applied (which is the standard case DG is normally used).\\nProviding lambdas to MatrixFree loops\\nThe examples given above have already used lambdas, which have been provided to matrix-free loops. The following short examples present how to transform functions between a version where a class and a pointer to one of its methods are used and a variant where lambdas are utilized.\\nIn the following code, a class and a pointer to one of its methods, which should be interpreted as cell integral, are passed to MatrixFree::loop():\\nvoid\\nlocal_apply_cell(const MatrixFree<dim, Number> &              data,\\n                 VectorType &                                 dst,\\n const VectorType &                           src,\\n const std::pair<unsigned int, unsigned int> &range) const\\n{\\n FEEvaluation<dim, degree, degree + 1, 1, Number> phi(data);\\n for (unsigned int cell = range.first; cell < range.second; ++cell)\\n    {\\n      phi.reinit(cell);\\n      phi.gather_evaluate(src, cell_evaluation_flags);\\n \\n // some operations on the quadrature points\\n \\n      phi.integrate_scatter(cell_evaluation_flags, dst);\\n    }\\n}\\nMatrixFreeDefinition matrix_free.h:113\\nmatrix_free.cell_loop(&Operator::local_apply_cell, this, dst, src);\\nHowever, it is also possible to pass an anonymous function via a lambda function with the same result:\\nmatrix_free.template cell_loop<VectorType, VectorType>(\\n  [&](const auto &data, auto &dst, const auto &src, const auto range) {\\n FEEvaluation<dim, degree, degree + 1, 1, Number> phi(data);\\n for (unsigned int cell = range.first; cell < range.second; ++cell)\\n      {\\n        phi.reinit(cell);\\n        phi.gather_evaluate(src, cell_evaluation_flags);\\n \\n // some operations on the quadrature points\\n \\n        phi.integrate_scatter(cell_evaluation_flags, dst);\\n      }\\n  },\\n  dst,\\n  src);\\nVectorizedArrayType\\nThe class VectorizedArray<Number> is a key component to achieve the high node-level performance of the matrix-free algorithms in deal.II. It is a wrapper class around a short vector of \\\\(n\\\\) entries of type Number and maps arithmetic operations to appropriate single-instruction/multiple-data (SIMD) concepts by intrinsic functions. The length of the vector can be queried by VectorizedArray::size() and its underlying number type by VectorizedArray::value_type.\\nIn the default case (VectorizedArray<Number>), the vector length is set at compile time of the library to match the highest value supported by the given processor architecture. However, also a second optional template argument can be specified as VectorizedArray<Number, size>, where size explicitly controls the vector length within the capabilities of a particular instruction set. A full list of supported vector lengths is presented in the following table:\\n\\n\\ndouble float ISA  \\n\\nVectorizedArray<double, 1> VectorizedArray<float, 1> (auto-vectorization)  \\n\\nVectorizedArray<double, 2> VectorizedArray<float, 4> SSE2/AltiVec  \\n\\nVectorizedArray<double, 4> VectorizedArray<float, 8> AVX/AVX2  \\n\\nVectorizedArray<double, 8> VectorizedArray<float, 16> AVX-512  \\n\\nThis allows users to select the vector length/ISA and, as a consequence, the number of cells to be processed at once in matrix-free operator evaluations, possibly reducing the pressure on the caches, an severe issue for very high degrees (and dimensions).\\nA possible further reason to reduce the number of filled lanes is to simplify debugging: instead of having to look at, e.g., 8 cells, one can concentrate on a single cell.\\nThe interface of VectorizedArray also enables the replacement by any type with a matching interface. Specifically, this prepares deal.II for the std::simd class that is planned to become part of the C++23 standard. The following table compares the deal.II-specific SIMD classes and the equivalent C++23 classes:\\n\\n\\nVectorizedArray (deal.II) std::simd (C++23)  \\n\\nVectorizedArray<Number> std::experimental::native_simd<Number> \\n\\nVectorizedArray<Number, size> std::experimental::fixed_size_simd<Number, size> \\n\\n The commented program\\n Parameters and utility functions\\nThe same includes as in step-67:\\n\\u00a0 #include <deal.II/base/conditional_ostream.h>\\n\\u00a0 #include <deal.II/base/function.h>\\n\\u00a0 #include <deal.II/base/time_stepping.h>\\n\\u00a0 #include <deal.II/base/timer.h>\\n\\u00a0 #include <deal.II/base/utilities.h>\\n\\u00a0 #include <deal.II/base/vectorization.h>\\n\\u00a0 \\n\\u00a0 #include <deal.II/distributed/tria.h>\\n\\u00a0 \\n\\u00a0 #include <deal.II/dofs/dof_handler.h>\\n\\u00a0 \\n\\u00a0 #include <deal.II/fe/fe_dgq.h>\\n\\u00a0 #include <deal.II/fe/fe_system.h>\\n\\u00a0 \\n\\u00a0 #include <deal.II/grid/grid_generator.h>\\n\\u00a0 #include <deal.II/grid/tria.h>\\n\\u00a0 #include <deal.II/grid/tria_accessor.h>\\n\\u00a0 #include <deal.II/grid/tria_iterator.h>\\n\\u00a0 \\n\\u00a0 #include <deal.II/lac/affine_constraints.h>\\n\\u00a0 #include <deal.II/lac/la_parallel_vector.h>\\n\\u00a0 \\n\\u00a0 #include <deal.II/matrix_free/fe_evaluation.h>\\n\\u00a0 #include <deal.II/matrix_free/matrix_free.h>\\n\\u00a0 #include <deal.II/matrix_free/operators.h>\\n\\u00a0 \\n\\u00a0 #include <deal.II/numerics/data_out.h>\\n\\u00a0 \\n\\u00a0 #include <fstream>\\n\\u00a0 #include <iomanip>\\n\\u00a0 #include <iostream>\\n\\u00a0 \\nA new include for categorizing of cells according to their boundary IDs:\\n\\u00a0 #include <deal.II/matrix_free/tools.h>\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0 namespace Euler_DG\\n\\u00a0 {\\n\\u00a0   using namespace dealii;\\n\\u00a0 \\ndealiiDefinition namespace_dealii.h:25\\nThe same input parameters as in step-67:\\n\\u00a0   constexpr unsigned int testcase             = 1;\\n\\u00a0   constexpr unsigned int dimension            = 2;\\n\\u00a0   constexpr unsigned int n_global_refinements = 2;\\n\\u00a0   constexpr unsigned int fe_degree            = 5;\\n\\u00a0   constexpr unsigned int n_q_points_1d        = fe_degree + 2;\\n\\u00a0 \\nThis parameter specifies the size of the shared-memory group. Currently, only the values 1 and numbers::invalid_unsigned_int is possible, leading to the options that the memory features can be turned off or all processes having access to the same shared-memory domain are grouped together.\\n\\u00a0   constexpr unsigned int group_size = numbers::invalid_unsigned_int;\\n\\u00a0 \\n\\u00a0   using Number = double;\\n\\u00a0 \\nnumbers::invalid_unsigned_intstatic const unsigned int invalid_unsigned_intDefinition types.h:220\\nHere, the type of the data structure is chosen for vectorization. In the default case, VectorizedArray<Number> is used, i.e., the highest instruction-set-architecture extension available on the given hardware with the maximum number of vector lanes is used. However, one might reduce the number of filled lanes, e.g., by writing using VectorizedArrayType = VectorizedArray<Number, 4> to only process 4 cells.\\n\\u00a0   using VectorizedArrayType = VectorizedArray<Number>;\\n\\u00a0 \\nVectorizedArrayDefinition vectorization.h:445\\nThe following parameters have not changed:\\n\\u00a0   constexpr double gamma       = 1.4;\\n\\u00a0   constexpr double final_time  = testcase == 0 ? 10 : 2.0;\\n\\u00a0   constexpr double output_tick = testcase == 0 ? 1 : 0.05;\\n\\u00a0 \\n\\u00a0   const double courant_number = 0.15 / std::pow(fe_degree, 1.5);\\n\\u00a0 \\nstd::pow::VectorizedArray< Number, width > pow(const ::VectorizedArray< Number, width > &, const Number p)Definition vectorization.h:6885\\nSpecify max number of time steps useful for performance studies.\\n\\u00a0   constexpr unsigned int max_time_steps = numbers::invalid_unsigned_int;\\n\\u00a0 \\nRunge-Kutta-related functions copied from step-67 and slightly modified with the purpose to minimize global vector access:\\n\\u00a0   enum LowStorageRungeKuttaScheme\\n\\u00a0   {\\n\\u00a0     stage_3_order_3,\\n\\u00a0     stage_5_order_4,\\n\\u00a0     stage_7_order_4,\\n\\u00a0     stage_9_order_5,\\n\\u00a0   };\\n\\u00a0   constexpr LowStorageRungeKuttaScheme lsrk_scheme = stage_5_order_4;\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0   class LowStorageRungeKuttaIntegrator\\n\\u00a0   {\\n\\u00a0   public:\\n\\u00a0     LowStorageRungeKuttaIntegrator(const LowStorageRungeKuttaScheme scheme)\\n\\u00a0     {\\n\\u00a0       TimeStepping::runge_kutta_method lsrk;\\n\\u00a0       switch (scheme)\\n\\u00a0         {\\n\\u00a0           case stage_3_order_3:\\n\\u00a0             lsrk = TimeStepping::LOW_STORAGE_RK_STAGE3_ORDER3;\\n\\u00a0             break;\\n\\u00a0           case stage_5_order_4:\\n\\u00a0             lsrk = TimeStepping::LOW_STORAGE_RK_STAGE5_ORDER4;\\n\\u00a0             break;\\n\\u00a0           case stage_7_order_4:\\n\\u00a0             lsrk = TimeStepping::LOW_STORAGE_RK_STAGE7_ORDER4;\\n\\u00a0             break;\\n\\u00a0           case stage_9_order_5:\\n\\u00a0             lsrk = TimeStepping::LOW_STORAGE_RK_STAGE9_ORDER5;\\n\\u00a0             break;\\n\\u00a0 \\n\\u00a0           default:\\n\\u00a0             AssertThrow(false, ExcNotImplemented());\\n\\u00a0         }\\n\\u00a0       TimeStepping::LowStorageRungeKutta<\\n\\u00a0         LinearAlgebra::distributed::Vector<Number>>\\n\\u00a0                           rk_integrator(lsrk);\\n\\u00a0       std::vector<double> ci; // not used\\n\\u00a0       rk_integrator.get_coefficients(ai, bi, ci);\\n\\u00a0     }\\n\\u00a0 \\n\\u00a0     unsigned int n_stages() const\\n\\u00a0     {\\n\\u00a0       return bi.size();\\n\\u00a0     }\\n\\u00a0 \\n\\u00a0     template <typename VectorType, typename Operator>\\n\\u00a0     void perform_time_step(const Operator &pde_operator,\\n\\u00a0                            const double    current_time,\\n\\u00a0                            const double    time_step,\\n\\u00a0                            VectorType     &solution,\\n\\u00a0                            VectorType     &vec_ri,\\n\\u00a0                            VectorType     &vec_ki) const\\n\\u00a0     {\\n\\u00a0       AssertDimension(ai.size() + 1, bi.size());\\n\\u00a0 \\n\\u00a0       vec_ki.swap(solution);\\n\\u00a0 \\n\\u00a0       double sum_previous_bi = 0;\\n\\u00a0       for (unsigned int stage = 0; stage < bi.size(); ++stage)\\n\\u00a0         {\\n\\u00a0           const double c_i = stage == 0 ? 0 : sum_previous_bi + ai[stage - 1];\\n\\u00a0 \\n\\u00a0           pde_operator.perform_stage(stage,\\n\\u00a0                                      current_time + c_i * time_step,\\n\\u00a0                                      bi[stage] * time_step,\\n\\u00a0                                      (stage == bi.size() - 1 ?\\n\\u00a0                                         0 :\\n\\u00a0                                         ai[stage] * time_step),\\n\\u00a0                                      (stage % 2 == 0 ? vec_ki : vec_ri),\\n\\u00a0                                      (stage % 2 == 0 ? vec_ri : vec_ki),\\n\\u00a0                                      solution);\\n\\u00a0 \\n\\u00a0           if (stage > 0)\\n\\u00a0             sum_previous_bi += bi[stage - 1];\\n\\u00a0         }\\n\\u00a0     }\\n\\u00a0 \\n\\u00a0   private:\\n\\u00a0     std::vector<double> bi;\\n\\u00a0     std::vector<double> ai;\\n\\u00a0   };\\n\\u00a0 \\n\\u00a0 \\nLinearAlgebra::distributed::VectorDefinition la_parallel_vector.h:250\\nTimeStepping::LowStorageRungeKuttaDefinition time_stepping.h:411\\nAssertDimension#define AssertDimension(dim1, dim2)Definition exceptions.h:1985\\nAssertThrow#define AssertThrow(cond, exc)Definition exceptions.h:1739\\nTimeStepping::runge_kutta_methodrunge_kutta_methodDefinition time_stepping.h:60\\nTimeStepping::LOW_STORAGE_RK_STAGE9_ORDER5@ LOW_STORAGE_RK_STAGE9_ORDER5Definition time_stepping.h:100\\nTimeStepping::LOW_STORAGE_RK_STAGE3_ORDER3@ LOW_STORAGE_RK_STAGE3_ORDER3Definition time_stepping.h:85\\nTimeStepping::LOW_STORAGE_RK_STAGE7_ORDER4@ LOW_STORAGE_RK_STAGE7_ORDER4Definition time_stepping.h:95\\nTimeStepping::LOW_STORAGE_RK_STAGE5_ORDER4@ LOW_STORAGE_RK_STAGE5_ORDER4Definition time_stepping.h:90\\nEuler-specific utility functions from step-67:\\n\\u00a0   enum EulerNumericalFlux\\n\\u00a0   {\\n\\u00a0     lax_friedrichs_modified,\\n\\u00a0     harten_lax_vanleer,\\n\\u00a0   };\\n\\u00a0   constexpr EulerNumericalFlux numerical_flux_type = lax_friedrichs_modified;\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim>\\n\\u00a0   class ExactSolution : public Function<dim>\\n\\u00a0   {\\n\\u00a0   public:\\n\\u00a0     ExactSolution(const double time)\\n\\u00a0       : Function<dim>(dim + 2, time)\\n\\u00a0     {}\\n\\u00a0 \\n\\u00a0     virtual double value(const Point<dim>  &p,\\n\\u00a0                          const unsigned int component = 0) const override;\\n\\u00a0   };\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim>\\n\\u00a0   double ExactSolution<dim>::value(const Point<dim>  &x,\\n\\u00a0                                    const unsigned int component) const\\n\\u00a0   {\\n\\u00a0     const double t = this->get_time();\\n\\u00a0 \\n\\u00a0     switch (testcase)\\n\\u00a0       {\\n\\u00a0         case 0:\\n\\u00a0           {\\n\\u00a0             Assert(dim == 2, ExcNotImplemented());\\n\\u00a0             const double beta = 5;\\n\\u00a0 \\n\\u00a0             Point<dim> x0;\\n\\u00a0             x0[0] = 5.;\\n\\u00a0             const double radius_sqr =\\n\\u00a0               (x - x0).norm_square() - 2. * (x[0] - x0[0]) * t + t * t;\\n\\u00a0             const double factor =\\n\\u00a0               beta / (numbers::PI * 2) * std::exp(1. - radius_sqr);\\n\\u00a0             const double density_log = std::log2(\\n\\u00a0               std::abs(1. - (gamma - 1.) / gamma * 0.25 * factor * factor));\\n\\u00a0             const double density = std::exp2(density_log * (1. / (gamma - 1.)));\\n\\u00a0             const double u       = 1. - factor * (x[1] - x0[1]);\\n\\u00a0             const double v       = factor * (x[0] - t - x0[0]);\\n\\u00a0 \\n\\u00a0             if (component == 0)\\n\\u00a0               return density;\\n\\u00a0             else if (component == 1)\\n\\u00a0               return density * u;\\n\\u00a0             else if (component == 2)\\n\\u00a0               return density * v;\\n\\u00a0             else\\n\\u00a0               {\\n\\u00a0                 const double pressure =\\n\\u00a0                   std::exp2(density_log * (gamma / (gamma - 1.)));\\n\\u00a0                 return pressure / (gamma - 1.) +\\n\\u00a0                        0.5 * (density * u * u + density * v * v);\\n\\u00a0               }\\n\\u00a0           }\\n\\u00a0 \\n\\u00a0         case 1:\\n\\u00a0           {\\n\\u00a0             if (component == 0)\\n\\u00a0               return 1.;\\n\\u00a0             else if (component == 1)\\n\\u00a0               return 0.4;\\n\\u00a0             else if (component == dim + 1)\\n\\u00a0               return 3.097857142857143;\\n\\u00a0             else\\n\\u00a0               return 0.;\\n\\u00a0           }\\n\\u00a0 \\n\\u00a0         default:\\n\\u00a0           DEAL_II_NOT_IMPLEMENTED();\\n\\u00a0           return 0.;\\n\\u00a0       }\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim, typename Number>\\n\\u00a0   inline DEAL_II_ALWAYS_INLINE \\n\\u00a0     Tensor<1, dim, Number>\\n\\u00a0     euler_velocity(const Tensor<1, dim + 2, Number> &conserved_variables)\\n\\u00a0   {\\n\\u00a0     const Number inverse_density = Number(1.) / conserved_variables[0];\\n\\u00a0 \\n\\u00a0     Tensor<1, dim, Number> velocity;\\n\\u00a0     for (unsigned int d = 0; d < dim; ++d)\\n\\u00a0       velocity[d] = conserved_variables[1 + d] * inverse_density;\\n\\u00a0 \\n\\u00a0     return velocity;\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0   template <int dim, typename Number>\\n\\u00a0   inline DEAL_II_ALWAYS_INLINE \\n\\u00a0     Number\\n\\u00a0     euler_pressure(const Tensor<1, dim + 2, Number> &conserved_variables)\\n\\u00a0   {\\n\\u00a0     const Tensor<1, dim, Number> velocity =\\n\\u00a0       euler_velocity<dim>(conserved_variables);\\n\\u00a0 \\n\\u00a0     Number rho_u_dot_u = conserved_variables[1] * velocity[0];\\n\\u00a0     for (unsigned int d = 1; d < dim; ++d)\\n\\u00a0       rho_u_dot_u += conserved_variables[1 + d] * velocity[d];\\n\\u00a0 \\n\\u00a0     return (gamma - 1.) * (conserved_variables[dim + 1] - 0.5 * rho_u_dot_u);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0   template <int dim, typename Number>\\n\\u00a0   inline DEAL_II_ALWAYS_INLINE \\n\\u00a0     Tensor<1, dim + 2, Tensor<1, dim, Number>>\\n\\u00a0     euler_flux(const Tensor<1, dim + 2, Number> &conserved_variables)\\n\\u00a0   {\\n\\u00a0     const Tensor<1, dim, Number> velocity =\\n\\u00a0       euler_velocity<dim>(conserved_variables);\\n\\u00a0     const Number pressure = euler_pressure<dim>(conserved_variables);\\n\\u00a0 \\n\\u00a0     Tensor<1, dim + 2, Tensor<1, dim, Number>> flux;\\n\\u00a0     for (unsigned int d = 0; d < dim; ++d)\\n\\u00a0       {\\n\\u00a0         flux[0][d] = conserved_variables[1 + d];\\n\\u00a0         for (unsigned int e = 0; e < dim; ++e)\\n\\u00a0           flux[e + 1][d] = conserved_variables[e + 1] * velocity[d];\\n\\u00a0         flux[d + 1][d] += pressure;\\n\\u00a0         flux[dim + 1][d] =\\n\\u00a0           velocity[d] * (conserved_variables[dim + 1] + pressure);\\n\\u00a0       }\\n\\u00a0 \\n\\u00a0     return flux;\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0   template <int n_components, int dim, typename Number>\\n\\u00a0   inline DEAL_II_ALWAYS_INLINE \\n\\u00a0     Tensor<1, n_components, Number>\\n\\u00a0     operator*(const Tensor<1, n_components, Tensor<1, dim, Number>> &matrix,\\n\\u00a0               const Tensor<1, dim, Number>                          &vector)\\n\\u00a0   {\\n\\u00a0     Tensor<1, n_components, Number> result;\\n\\u00a0     for (unsigned int d = 0; d < n_components; ++d)\\n\\u00a0       result[d] = matrix[d] * vector;\\n\\u00a0     return result;\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0   template <int dim, typename Number>\\n\\u00a0   inline DEAL_II_ALWAYS_INLINE \\n\\u00a0     Tensor<1, dim + 2, Number>\\n\\u00a0     euler_numerical_flux(const Tensor<1, dim + 2, Number> &u_m,\\n\\u00a0                          const Tensor<1, dim + 2, Number> &u_p,\\n\\u00a0                          const Tensor<1, dim, Number>     &normal)\\n\\u00a0   {\\n\\u00a0     const auto velocity_m = euler_velocity<dim>(u_m);\\n\\u00a0     const auto velocity_p = euler_velocity<dim>(u_p);\\n\\u00a0 \\n\\u00a0     const auto pressure_m = euler_pressure<dim>(u_m);\\n\\u00a0     const auto pressure_p = euler_pressure<dim>(u_p);\\n\\u00a0 \\n\\u00a0     const auto flux_m = euler_flux<dim>(u_m);\\n\\u00a0     const auto flux_p = euler_flux<dim>(u_p);\\n\\u00a0 \\n\\u00a0     switch (numerical_flux_type)\\n\\u00a0       {\\n\\u00a0         case lax_friedrichs_modified:\\n\\u00a0           {\\n\\u00a0             const auto lambda =\\n\\u00a0               0.5 * std::sqrt(std::max(velocity_p.norm_square() +\\n\\u00a0                                          gamma * pressure_p * (1. / u_p[0]),\\n\\u00a0                                        velocity_m.norm_square() +\\n\\u00a0                                          gamma * pressure_m * (1. / u_m[0])));\\n\\u00a0 \\n\\u00a0             return 0.5 * (flux_m * normal + flux_p * normal) +\\n\\u00a0                    0.5 * lambda * (u_m - u_p);\\n\\u00a0           }\\n\\u00a0 \\n\\u00a0         case harten_lax_vanleer:\\n\\u00a0           {\\n\\u00a0             const auto avg_velocity_normal =\\n\\u00a0               0.5 * ((velocity_m + velocity_p) * normal);\\n\\u00a0             const auto   avg_c = std::sqrt(std::abs(\\n\\u00a0               0.5 * gamma *\\n\\u00a0               (pressure_p * (1. / u_p[0]) + pressure_m * (1. / u_m[0]))));\\n\\u00a0             const Number s_pos =\\n\\u00a0               std::max(Number(), avg_velocity_normal + avg_c);\\n\\u00a0             const Number s_neg =\\n\\u00a0               std::min(Number(), avg_velocity_normal - avg_c);\\n\\u00a0             const Number inverse_s = Number(1.) / (s_pos - s_neg);\\n\\u00a0 \\n\\u00a0             return inverse_s *\\n\\u00a0                    ((s_pos * (flux_m * normal) - s_neg * (flux_p * normal)) -\\n\\u00a0                     s_pos * s_neg * (u_m - u_p));\\n\\u00a0           }\\n\\u00a0 \\n\\u00a0         default:\\n\\u00a0           {\\n\\u00a0             DEAL_II_NOT_IMPLEMENTED();\\n\\u00a0             return {};\\n\\u00a0           }\\n\\u00a0       }\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nFunctionDefinition function.h:152\\nPointDefinition point.h:111\\nTensorDefinition tensor.h:471\\nTensor::norm_squareconstexpr numbers::NumberTraits< Number >::real_type norm_square() const\\nint\\noperator*std::enable_if_t< std::is_floating_point_v< T > &&std::is_floating_point_v< U >, typename ProductType< std::complex< T >, std::complex< U > >::type > operator*(const std::complex< T > &left, const std::complex< U > &right)Definition complex_overloads.h:42\\nDEAL_II_ALWAYS_INLINE#define DEAL_II_ALWAYS_INLINEDefinition config.h:109\\nDEAL_II_NOT_IMPLEMENTED#define DEAL_II_NOT_IMPLEMENTED()Definition exceptions.h:1814\\nDifferentiation::SD::OptimizerType::lambda@ lambda\\nPhysics::Elasticity::Kinematics::eSymmetricTensor< 2, dim, Number > e(const Tensor< 2, dim, Number > &F)\\nPhysics::Elasticity::Kinematics::dSymmetricTensor< 2, dim, Number > d(const Tensor< 2, dim, Number > &F, const Tensor< 2, dim, Number > &dF_dt)\\nUtilities::System::get_timestd::string get_time()Definition utilities.cc:1013\\ninternal::QGaussLobatto::gammalong double gamma(const unsigned int n)Definition quadrature_lib.cc:103\\nnumbers::PIstatic constexpr double PIDefinition numbers.h:259\\nstd::exp::VectorizedArray< Number, width > exp(const ::VectorizedArray< Number, width > &)Definition vectorization.h:6829\\nstd::min::VectorizedArray< Number, width > min(const ::VectorizedArray< Number, width > &, const ::VectorizedArray< Number, width > &)Definition vectorization.h:6960\\nstd::max::VectorizedArray< Number, width > max(const ::VectorizedArray< Number, width > &, const ::VectorizedArray< Number, width > &)Definition vectorization.h:6943\\nstd::sqrt::VectorizedArray< Number, width > sqrt(const ::VectorizedArray< Number, width > &)Definition vectorization.h:6869\\nstd::abs::VectorizedArray< Number, width > abs(const ::VectorizedArray< Number, width > &)Definition vectorization.h:6927\\nGeneral-purpose utility functions from step-67:\\n\\u00a0   template <int dim, typename VectorizedArrayType>\\n\\u00a0   VectorizedArrayType\\n\\u00a0   evaluate_function(const Function<dim>                   &function,\\n\\u00a0                     const Point<dim, VectorizedArrayType> &p_vectorized,\\n\\u00a0                     const unsigned int                     component)\\n\\u00a0   {\\n\\u00a0     VectorizedArrayType result;\\n\\u00a0     for (unsigned int v = 0; v < VectorizedArrayType::size(); ++v)\\n\\u00a0       {\\n\\u00a0         Point<dim> p;\\n\\u00a0         for (unsigned int d = 0; d < dim; ++d)\\n\\u00a0           p[d] = p_vectorized[d][v];\\n\\u00a0         result[v] = function.value(p, component);\\n\\u00a0       }\\n\\u00a0     return result;\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim, typename VectorizedArrayType, int n_components = dim + 2>\\n\\u00a0   Tensor<1, n_components, VectorizedArrayType>\\n\\u00a0   evaluate_function(const Function<dim>                   &function,\\n\\u00a0                     const Point<dim, VectorizedArrayType> &p_vectorized)\\n\\u00a0   {\\n\\u00a0     AssertDimension(function.n_components, n_components);\\n\\u00a0     Tensor<1, n_components, VectorizedArrayType> result;\\n\\u00a0     for (unsigned int v = 0; v < VectorizedArrayType::size(); ++v)\\n\\u00a0       {\\n\\u00a0         Point<dim> p;\\n\\u00a0         for (unsigned int d = 0; d < dim; ++d)\\n\\u00a0           p[d] = p_vectorized[d][v];\\n\\u00a0         for (unsigned int d = 0; d < n_components; ++d)\\n\\u00a0           result[d][v] = function.value(p, d);\\n\\u00a0       }\\n\\u00a0     return result;\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\nFunction::n_componentsconst unsigned int n_componentsDefinition function.h:163\\nFunction::valuevirtual RangeNumberType value(const Point< dim > &p, const unsigned int component=0) const\\n Euler operator using a cell-centric loop and MPI-3.0 shared memory\\nEuler operator from step-67 with some changes as detailed below:\\n\\u00a0   template <int dim, int degree, int n_points_1d>\\n\\u00a0   class EulerOperator\\n\\u00a0   {\\n\\u00a0   public:\\n\\u00a0     static constexpr unsigned int n_quadrature_points_1d = n_points_1d;\\n\\u00a0 \\n\\u00a0     EulerOperator(TimerOutput &timer_output);\\n\\u00a0 \\n\\u00a0     ~EulerOperator();\\n\\u00a0 \\n\\u00a0     void reinit(const Mapping<dim>    &mapping,\\n\\u00a0                 const DoFHandler<dim> &dof_handler);\\n\\u00a0 \\n\\u00a0     void set_inflow_boundary(const types::boundary_id       boundary_id,\\n\\u00a0                              std::unique_ptr<Function<dim>> inflow_function);\\n\\u00a0 \\n\\u00a0     void set_subsonic_outflow_boundary(\\n\\u00a0       const types::boundary_id       boundary_id,\\n\\u00a0       std::unique_ptr<Function<dim>> outflow_energy);\\n\\u00a0 \\n\\u00a0     void set_wall_boundary(const types::boundary_id boundary_id);\\n\\u00a0 \\n\\u00a0     void set_body_force(std::unique_ptr<Function<dim>> body_force);\\n\\u00a0 \\n\\u00a0     void\\n\\u00a0     perform_stage(const unsigned int                                stage,\\n\\u00a0                   const Number                                      cur_time,\\n\\u00a0                   const Number                                      bi,\\n\\u00a0                   const Number                                      ai,\\n\\u00a0                   const LinearAlgebra::distributed::Vector<Number> &current_ri,\\n\\u00a0                   LinearAlgebra::distributed::Vector<Number>       &vec_ki,\\n\\u00a0                   LinearAlgebra::distributed::Vector<Number> &solution) const;\\n\\u00a0 \\n\\u00a0     void project(const Function<dim>                        &function,\\n\\u00a0                  LinearAlgebra::distributed::Vector<Number> &solution) const;\\n\\u00a0 \\n\\u00a0     std::array<double, 3> compute_errors(\\n\\u00a0       const Function<dim>                              &function,\\n\\u00a0       const LinearAlgebra::distributed::Vector<Number> &solution) const;\\n\\u00a0 \\n\\u00a0     double compute_cell_transport_speed(\\n\\u00a0       const LinearAlgebra::distributed::Vector<Number> &solution) const;\\n\\u00a0 \\n\\u00a0     void\\n\\u00a0     initialize_vector(LinearAlgebra::distributed::Vector<Number> &vector) const;\\n\\u00a0 \\n\\u00a0   private:\\nDoFHandlerDefinition dof_handler.h:317\\nMappingAbstract base class for mapping classes.Definition mapping.h:318\\nTimerOutputDefinition timer.h:549\\nunsigned int\\nInstance of SubCommunicatorWrapper containing the sub-communicator, which we need to pass to MatrixFree::reinit() to be able to exploit MPI-3.0 shared-memory capabilities:\\n\\u00a0     MPI_Comm subcommunicator;\\n\\u00a0 \\n\\u00a0     MatrixFree<dim, Number, VectorizedArrayType> data;\\n\\u00a0 \\n\\u00a0     TimerOutput &timer;\\n\\u00a0 \\n\\u00a0     std::map<types::boundary_id, std::unique_ptr<Function<dim>>>\\n\\u00a0       inflow_boundaries;\\n\\u00a0     std::map<types::boundary_id, std::unique_ptr<Function<dim>>>\\n\\u00a0                                    subsonic_outflow_boundaries;\\n\\u00a0     std::set<types::boundary_id>   wall_boundaries;\\n\\u00a0     std::unique_ptr<Function<dim>> body_force;\\n\\u00a0   };\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nMPI_Comm\\nNew constructor, which creates a sub-communicator. The user can specify the size of the sub-communicator via the global parameter group_size. If the size is set to -1, all MPI processes of a shared-memory domain are combined to a group. The specified size is decisive for the benefit of the shared-memory capabilities of MatrixFree and, therefore, setting the size to -1 is a reasonable choice. By setting, the size to 1 users explicitly disable the MPI-3.0 shared-memory features of MatrixFree and rely completely on MPI-2.0 features, like MPI_Isend and MPI_Irecv.\\n\\u00a0   template <int dim, int degree, int n_points_1d>\\n\\u00a0   EulerOperator<dim, degree, n_points_1d>::EulerOperator(TimerOutput &timer)\\n\\u00a0     : timer(timer)\\n\\u00a0   {\\n\\u00a0 #ifdef DEAL_II_WITH_MPI\\n\\u00a0     if (group_size == 1)\\n\\u00a0       {\\n\\u00a0         this->subcommunicator = MPI_COMM_SELF;\\n\\u00a0       }\\n\\u00a0     else if (group_size == numbers::invalid_unsigned_int)\\n\\u00a0       {\\n\\u00a0         const auto rank = Utilities::MPI::this_mpi_process(MPI_COMM_WORLD);\\n\\u00a0 \\n\\u00a0         MPI_Comm_split_type(MPI_COMM_WORLD,\\n\\u00a0                             MPI_COMM_TYPE_SHARED,\\n\\u00a0                             rank,\\n\\u00a0                             MPI_INFO_NULL,\\n\\u00a0                             &subcommunicator);\\n\\u00a0       }\\n\\u00a0     else\\n\\u00a0       {\\n\\u00a0         DEAL_II_NOT_IMPLEMENTED();\\n\\u00a0       }\\n\\u00a0 #else\\n\\u00a0     (void)subcommunicator;\\n\\u00a0     (void)group_size;\\n\\u00a0     this->subcommunicator = MPI_COMM_SELF;\\n\\u00a0 #endif\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\nUtilities::MPI::this_mpi_processunsigned int this_mpi_process(const MPI_Comm mpi_communicator)Definition mpi.cc:107\\nNew destructor responsible for freeing of the sub-communicator.\\n\\u00a0   template <int dim, int degree, int n_points_1d>\\n\\u00a0   EulerOperator<dim, degree, n_points_1d>::~EulerOperator()\\n\\u00a0   {\\n\\u00a0 #ifdef DEAL_II_WITH_MPI\\n\\u00a0     if (this->subcommunicator != MPI_COMM_SELF)\\n\\u00a0       MPI_Comm_free(&subcommunicator);\\n\\u00a0 #endif\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\nModified reinit() function to set up the internal data structures in MatrixFree in a way that it is usable by the cell-centric loops and the MPI-3.0 shared-memory capabilities are used:\\n\\u00a0   template <int dim, int degree, int n_points_1d>\\n\\u00a0   void EulerOperator<dim, degree, n_points_1d>::reinit(\\n\\u00a0     const Mapping<dim>    &mapping,\\n\\u00a0     const DoFHandler<dim> &dof_handler)\\n\\u00a0   {\\n\\u00a0     const std::vector<const DoFHandler<dim> *> dof_handlers = {&dof_handler};\\n\\u00a0     const AffineConstraints<double>            dummy;\\n\\u00a0     const std::vector<const AffineConstraints<double> *> constraints = {&dummy};\\n\\u00a0     const std::vector<Quadrature<1>> quadratures = {QGauss<1>(n_q_points_1d),\\n\\u00a0                                                     QGauss<1>(fe_degree + 1)};\\n\\u00a0 \\n\\u00a0     typename MatrixFree<dim, Number, VectorizedArrayType>::AdditionalData\\n\\u00a0       additional_data;\\n\\u00a0     additional_data.mapping_update_flags =\\n\\u00a0       (update_gradients | update_JxW_values | update_quadrature_points |\\n\\u00a0        update_values);\\n\\u00a0     additional_data.mapping_update_flags_inner_faces =\\n\\u00a0       (update_JxW_values | update_quadrature_points | update_normal_vectors |\\n\\u00a0        update_values);\\n\\u00a0     additional_data.mapping_update_flags_boundary_faces =\\n\\u00a0       (update_JxW_values | update_quadrature_points | update_normal_vectors |\\n\\u00a0        update_values);\\n\\u00a0     additional_data.tasks_parallel_scheme =\\n\\u00a0       MatrixFree<dim, Number, VectorizedArrayType>::AdditionalData::none;\\n\\u00a0 \\nAffineConstraintsDefinition affine_constraints.h:507\\nQGaussDefinition quadrature_lib.h:40\\nupdate_values@ update_valuesShape function values.Definition fe_update_flags.h:75\\nupdate_normal_vectors@ update_normal_vectorsNormal vectors.Definition fe_update_flags.h:141\\nupdate_JxW_values@ update_JxW_valuesTransformed quadrature weights.Definition fe_update_flags.h:134\\nupdate_gradients@ update_gradientsShape function gradients.Definition fe_update_flags.h:81\\nupdate_quadrature_points@ update_quadrature_pointsTransformed quadrature points.Definition fe_update_flags.h:127\\nMatrixFree::AdditionalData::mapping_update_flagsUpdateFlags mapping_update_flagsDefinition matrix_free.h:373\\nCategorize cells so that all lanes have the same boundary IDs for each face. This is strictly not necessary, however, allows to write simpler code in EulerOperator::perform_stage() without masking, since it is guaranteed that all cells grouped together (in a VectorizedArray) have to perform exactly the same operation also on the faces.\\n\\u00a0     MatrixFreeTools::categorize_by_boundary_ids(dof_handler.get_triangulation(),\\n\\u00a0                                                 additional_data);\\n\\u00a0 \\nMatrixFreeTools::categorize_by_boundary_idsvoid categorize_by_boundary_ids(const Triangulation< dim > &tria, AdditionalData &additional_data)\\nEnable MPI-3.0 shared-memory capabilities within MatrixFree by providing the sub-communicator:\\n\\u00a0     additional_data.communicator_sm = subcommunicator;\\n\\u00a0 \\n\\u00a0     data.reinit(\\n\\u00a0       mapping, dof_handlers, constraints, quadratures, additional_data);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\nMatrixFree::reinitvoid reinit(const MappingType &mapping, const DoFHandler< dim > &dof_handler, const AffineConstraints< number2 > &constraint, const QuadratureType &quad, const AdditionalData &additional_data=AdditionalData())\\nThe following function does an entire stage of a Runge\\u2013Kutta update and is, alongside the slightly modified setup, the heart of this tutorial compared to step-67.\\nIn contrast to step-67, we are not executing the advection step (using MatrixFree::loop()) and the inverse mass-matrix step (using MatrixFree::cell_loop()) in sequence, but evaluate everything in one go inside of MatrixFree::loop_cell_centric(). This function expects a single function that is executed on each locally-owned (macro) cell as parameter so that we need to loop over all faces of that cell and perform needed integration steps on our own.\\nThe following function contains to a large extent copies of the following functions from step-67 so that comments related the evaluation of the weak form are skipped here:\\nEulerDG::EulerOperator::local_apply_cell\\nEulerDG::EulerOperator::local_apply_face\\nEulerDG::EulerOperator::local_apply_boundary_face\\nEulerDG::EulerOperator::local_apply_inverse_mass_matrix\\n\\n\\u00a0   template <int dim, int degree, int n_points_1d>\\n\\u00a0   void EulerOperator<dim, degree, n_points_1d>::perform_stage(\\n\\u00a0     const unsigned int                                stage,\\n\\u00a0     const Number                                      current_time,\\n\\u00a0     const Number                                      bi,\\n\\u00a0     const Number                                      ai,\\n\\u00a0     const LinearAlgebra::distributed::Vector<Number> &current_ri,\\n\\u00a0     LinearAlgebra::distributed::Vector<Number>       &vec_ki,\\n\\u00a0     LinearAlgebra::distributed::Vector<Number>       &solution) const\\n\\u00a0   {\\n\\u00a0     for (auto &i : inflow_boundaries)\\n\\u00a0       i.second->set_time(current_time);\\n\\u00a0     for (auto &i : subsonic_outflow_boundaries)\\n\\u00a0       i.second->set_time(current_time);\\n\\u00a0 \\nsecondPoint< 2 > secondDefinition grid_out.cc:4624\\nRun a cell-centric loop by calling MatrixFree::loop_cell_centric() and providing a lambda containing the effects of the cell, face and boundary-face integrals:\\n\\u00a0     data.template loop_cell_centric<LinearAlgebra::distributed::Vector<Number>,\\n\\u00a0                                     LinearAlgebra::distributed::Vector<Number>>(\\n\\u00a0       [&](const auto &data, auto &dst, const auto &src, const auto cell_range) {\\n\\u00a0         using FECellIntegral = FEEvaluation<dim,\\n\\u00a0                                             degree,\\n\\u00a0                                             n_points_1d,\\n\\u00a0                                             dim + 2,\\n\\u00a0                                             Number,\\n\\u00a0                                             VectorizedArrayType>;\\n\\u00a0         using FEFaceIntegral = FEFaceEvaluation<dim,\\n\\u00a0                                                 degree,\\n\\u00a0                                                 n_points_1d,\\n\\u00a0                                                 dim + 2,\\n\\u00a0                                                 Number,\\n\\u00a0                                                 VectorizedArrayType>;\\n\\u00a0 \\n\\u00a0         FECellIntegral phi(data);\\n\\u00a0         FECellIntegral phi_temp(data);\\n\\u00a0         FEFaceIntegral phi_m(data, true);\\n\\u00a0         FEFaceIntegral phi_p(data, false);\\n\\u00a0 \\n\\u00a0         Tensor<1, dim, VectorizedArrayType>     constant_body_force;\\n\\u00a0         const Functions::ConstantFunction<dim> *constant_function =\\n\\u00a0           dynamic_cast<Functions::ConstantFunction<dim> *>(body_force.get());\\n\\u00a0 \\n\\u00a0         if (constant_function)\\n\\u00a0           constant_body_force =\\n\\u00a0             evaluate_function<dim, VectorizedArrayType, dim>(\\n\\u00a0               *constant_function, Point<dim, VectorizedArrayType>());\\n\\u00a0 \\n\\u00a0         const internal::EvaluatorTensorProduct<\\n\\u00a0           internal::EvaluatorVariant::evaluate_evenodd,\\n\\u00a0           dim,\\n\\u00a0           n_points_1d,\\n\\u00a0           n_points_1d,\\n\\u00a0           VectorizedArrayType,\\n\\u00a0           Number>\\n\\u00a0           eval({},\\n\\u00a0                data.get_shape_info().data[0].shape_gradients_collocation_eo,\\n\\u00a0                {});\\n\\u00a0 \\n\\u00a0         AlignedVector<VectorizedArrayType> buffer(phi.static_n_q_points *\\n\\u00a0                                                   phi.n_components);\\n\\u00a0 \\nAlignedVectorDefinition aligned_vector.h:61\\nFunctions::ConstantFunctionDefinition function.h:410\\ninternal::evaluate_evenodd@ evaluate_evenoddDefinition tensor_product_kernels.h:55\\ninternal::EvaluatorTensorProductDefinition tensor_product_kernels.h:1288\\nLoop over all cell batches:\\n\\u00a0         for (unsigned int cell = cell_range.first; cell < cell_range.second;\\n\\u00a0              ++cell)\\n\\u00a0           {\\n\\u00a0             phi.reinit(cell);\\n\\u00a0 \\n\\u00a0             if (ai != Number())\\n\\u00a0               phi_temp.reinit(cell);\\n\\u00a0 \\nRead values from global vector and compute the values at the quadrature points:\\n\\u00a0             if (ai != Number() && stage == 0)\\n\\u00a0               {\\n\\u00a0                 phi.read_dof_values(src);\\n\\u00a0 \\n\\u00a0                 for (unsigned int i = 0;\\n\\u00a0                      i < phi.static_dofs_per_component * (dim + 2);\\n\\u00a0                      ++i)\\n\\u00a0                   phi_temp.begin_dof_values()[i] = phi.begin_dof_values()[i];\\n\\u00a0 \\n\\u00a0                 phi.evaluate(EvaluationFlags::values);\\n\\u00a0               }\\n\\u00a0             else\\n\\u00a0               {\\n\\u00a0                 phi.gather_evaluate(src, EvaluationFlags::values);\\n\\u00a0               }\\n\\u00a0 \\nEvaluationFlags::values@ valuesDefinition evaluation_flags.h:50\\nBuffer the computed values at the quadrature points, since these are overridden by FEEvaluation::submit_value() in the next step, however, are needed later on for the face integrals:\\n\\u00a0             for (unsigned int i = 0; i < phi.static_n_q_points * (dim + 2); ++i)\\n\\u00a0               buffer[i] = phi.begin_values()[i];\\n\\u00a0 \\nApply the cell integral at the cell quadrature points. See also the function EulerOperator::local_apply_cell() from step-67:\\n\\u00a0             for (const unsigned int q : phi.quadrature_point_indices())\\n\\u00a0               {\\n\\u00a0                 const auto w_q = phi.get_value(q);\\n\\u00a0                 phi.submit_gradient(euler_flux<dim>(w_q), q);\\n\\u00a0                 if (body_force.get() != nullptr)\\n\\u00a0                   {\\n\\u00a0                     const Tensor<1, dim, VectorizedArrayType> force =\\n\\u00a0                       constant_function ?\\n\\u00a0                         constant_body_force :\\n\\u00a0                         evaluate_function<dim, VectorizedArrayType, dim>(\\n\\u00a0                           *body_force, phi.quadrature_point(q));\\n\\u00a0 \\n\\u00a0                     Tensor<1, dim + 2, VectorizedArrayType> forcing;\\n\\u00a0                     for (unsigned int d = 0; d < dim; ++d)\\n\\u00a0                       forcing[d + 1] = w_q[0] * force[d];\\n\\u00a0                     for (unsigned int d = 0; d < dim; ++d)\\n\\u00a0                       forcing[dim + 1] += force[d] * w_q[d + 1];\\n\\u00a0 \\n\\u00a0                     phi.submit_value(forcing, q);\\n\\u00a0                   }\\n\\u00a0               }\\n\\u00a0 \\nTest with the gradient of the test functions in the quadrature points. We skip the interpolation back to the support points of the element, since we first collect all contributions in the cell quadrature points and only perform the interpolation back as the final step.\\n\\u00a0             {\\n\\u00a0               auto *values_ptr   = phi.begin_values();\\n\\u00a0               auto *gradient_ptr = phi.begin_gradients();\\n\\u00a0 \\n\\u00a0               for (unsigned int c = 0; c < dim + 2; ++c)\\n\\u00a0                 {\\n\\u00a0                   if (dim >= 1 && body_force.get() == nullptr)\\n\\u00a0                     eval.template gradients<0, false, false, dim>(gradient_ptr,\\n\\u00a0                                                                   values_ptr);\\n\\u00a0                   else if (dim >= 1)\\n\\u00a0                     eval.template gradients<0, false, true, dim>(gradient_ptr,\\n\\u00a0                                                                  values_ptr);\\n\\u00a0                   if (dim >= 2)\\n\\u00a0                     eval.template gradients<1, false, true, dim>(gradient_ptr +\\n\\u00a0                                                                    1,\\n\\u00a0                                                                  values_ptr);\\n\\u00a0                   if (dim >= 3)\\n\\u00a0                     eval.template gradients<2, false, true, dim>(gradient_ptr +\\n\\u00a0                                                                    2,\\n\\u00a0                                                                  values_ptr);\\n\\u00a0 \\n\\u00a0                   values_ptr += phi.static_n_q_points;\\n\\u00a0                   gradient_ptr += phi.static_n_q_points * dim;\\n\\u00a0                 }\\n\\u00a0             }\\n\\u00a0 \\nLoop over all faces of the current cell:\\n\\u00a0             for (unsigned int face = 0;\\n\\u00a0                  face < GeometryInfo<dim>::faces_per_cell;\\n\\u00a0                  ++face)\\n\\u00a0               {\\nDetermine the boundary ID of the current face. Since we have set up MatrixFree in a way that all filled lanes have guaranteed the same boundary ID, we can select the boundary ID of the first lane.\\n\\u00a0                 const auto boundary_ids =\\n\\u00a0                   data.get_faces_by_cells_boundary_id(cell, face);\\n\\u00a0 \\n\\u00a0                 Assert(std::equal(boundary_ids.begin(),\\n\\u00a0                                   boundary_ids.begin() +\\n\\u00a0                                     data.n_active_entries_per_cell_batch(cell),\\n\\u00a0                                   boundary_ids.begin()),\\n\\u00a0                        ExcMessage(\\\"Boundary IDs of lanes differ.\\\"));\\n\\u00a0 \\n\\u00a0                 const auto boundary_id = boundary_ids[0];\\n\\u00a0 \\n\\u00a0                 phi_m.reinit(cell, face);\\n\\u00a0 \\nInterpolate the values from the cell quadrature points to the quadrature points of the current face via a simple 1d interpolation:\\n\\u00a0                 internal::FEFaceNormalEvaluationImpl<dim,\\n\\u00a0                                                      n_points_1d - 1,\\n\\u00a0                                                      VectorizedArrayType>::\\n\\u00a0                   template interpolate_quadrature<true, false>(\\n\\u00a0                     dim + 2,\\n\\u00a0                     EvaluationFlags::values,\\n\\u00a0                     data.get_shape_info(),\\n\\u00a0                     buffer.data(),\\n\\u00a0                     phi_m.begin_values(),\\n\\u00a0                     face);\\n\\u00a0 \\ninternal::FEFaceNormalEvaluationImplDefinition evaluation_kernels_face.h:856\\nCheck if the face is an internal or a boundary face and select a different code path based on this information:\\n\\u00a0                 if (boundary_id == numbers::internal_face_boundary_id)\\n\\u00a0                   {\\nProcess and internal face. The following lines of code are a copy of the function EulerDG::EulerOperator::local_apply_face from step-67:\\n\\u00a0                     phi_p.reinit(cell, face);\\n\\u00a0                     phi_p.gather_evaluate(src, EvaluationFlags::values);\\n\\u00a0 \\n\\u00a0                     for (const unsigned int q :\\n\\u00a0                          phi_m.quadrature_point_indices())\\n\\u00a0                       {\\n\\u00a0                         const auto numerical_flux =\\n\\u00a0                           euler_numerical_flux<dim>(phi_m.get_value(q),\\n\\u00a0                                                     phi_p.get_value(q),\\n\\u00a0                                                     phi_m.normal_vector(q));\\n\\u00a0                         phi_m.submit_value(-numerical_flux, q);\\n\\u00a0                       }\\n\\u00a0                   }\\n\\u00a0                 else\\n\\u00a0                   {\\nProcess a boundary face. These following lines of code are a copy of the function EulerDG::EulerOperator::local_apply_boundary_face from step-67:\\n\\u00a0                     for (const unsigned int q :\\n\\u00a0                          phi_m.quadrature_point_indices())\\n\\u00a0                       {\\n\\u00a0                         const auto w_m    = phi_m.get_value(q);\\n\\u00a0                         const auto normal = phi_m.normal_vector(q);\\n\\u00a0 \\n\\u00a0                         auto rho_u_dot_n = w_m[1] * normal[0];\\n\\u00a0                         for (unsigned int d = 1; d < dim; ++d)\\n\\u00a0                           rho_u_dot_n += w_m[1 + d] * normal[d];\\n\\u00a0 \\n\\u00a0                         bool at_outflow = false;\\n\\u00a0 \\n\\u00a0                         Tensor<1, dim + 2, VectorizedArrayType> w_p;\\n\\u00a0 \\n\\u00a0                         if (wall_boundaries.find(boundary_id) !=\\n\\u00a0                             wall_boundaries.end())\\n\\u00a0                           {\\n\\u00a0                             w_p[0] = w_m[0];\\n\\u00a0                             for (unsigned int d = 0; d < dim; ++d)\\n\\u00a0                               w_p[d + 1] =\\n\\u00a0                                 w_m[d + 1] - 2. * rho_u_dot_n * normal[d];\\n\\u00a0                             w_p[dim + 1] = w_m[dim + 1];\\n\\u00a0                           }\\n\\u00a0                         else if (inflow_boundaries.find(boundary_id) !=\\n\\u00a0                                  inflow_boundaries.end())\\n\\u00a0                           w_p = evaluate_function(\\n\\u00a0                             *inflow_boundaries.find(boundary_id)->second,\\n\\u00a0                             phi_m.quadrature_point(q));\\n\\u00a0                         else if (subsonic_outflow_boundaries.find(\\n\\u00a0                                    boundary_id) !=\\n\\u00a0                                  subsonic_outflow_boundaries.end())\\n\\u00a0                           {\\n\\u00a0                             w_p = w_m;\\n\\u00a0                             w_p[dim + 1] =\\n\\u00a0                               evaluate_function(*subsonic_outflow_boundaries\\n\\u00a0                                                    .find(boundary_id)\\n\\u00a0                                                    ->second,\\n\\u00a0                                                 phi_m.quadrature_point(q),\\n\\u00a0                                                 dim + 1);\\n\\u00a0                             at_outflow = true;\\n\\u00a0                           }\\n\\u00a0                         else\\n\\u00a0                           AssertThrow(false,\\n\\u00a0                                       ExcMessage(\\n\\u00a0                                         \\\"Unknown boundary id, did \\\"\\n\\u00a0                                         \\\"you set a boundary condition for \\\"\\n\\u00a0                                         \\\"this part of the domain boundary?\\\"));\\n\\u00a0 \\n\\u00a0                         auto flux = euler_numerical_flux<dim>(w_m, w_p, normal);\\n\\u00a0 \\n\\u00a0                         if (at_outflow)\\n\\u00a0                           for (unsigned int v = 0;\\n\\u00a0                                v < VectorizedArrayType::size();\\n\\u00a0                                ++v)\\n\\u00a0                             {\\n\\u00a0                               if (rho_u_dot_n[v] < -1e-12)\\n\\u00a0                                 for (unsigned int d = 0; d < dim; ++d)\\n\\u00a0                                   flux[d + 1][v] = 0.;\\n\\u00a0                             }\\n\\u00a0 \\n\\u00a0                         phi_m.submit_value(-flux, q);\\n\\u00a0                       }\\n\\u00a0                   }\\n\\u00a0 \\nEvaluate local integrals related to cell by quadrature and add into cell contribution via a simple 1d interpolation:\\n\\u00a0                 internal::FEFaceNormalEvaluationImpl<dim,\\n\\u00a0                                                      n_points_1d - 1,\\n\\u00a0                                                      VectorizedArrayType>::\\n\\u00a0                   template interpolate_quadrature<false, true>(\\n\\u00a0                     dim + 2,\\n\\u00a0                     EvaluationFlags::values,\\n\\u00a0                     data.get_shape_info(),\\n\\u00a0                     phi_m.begin_values(),\\n\\u00a0                     phi.begin_values(),\\n\\u00a0                     face);\\n\\u00a0               }\\n\\u00a0 \\nApply inverse mass matrix in the cell quadrature points. See also the function EulerDG::EulerOperator::local_apply_inverse_mass_matrix() from step-67:\\n\\u00a0             for (unsigned int q = 0; q < phi.static_n_q_points; ++q)\\n\\u00a0               {\\n\\u00a0                 const auto factor = VectorizedArrayType(1.0) / phi.JxW(q);\\n\\u00a0                 for (unsigned int c = 0; c < dim + 2; ++c)\\n\\u00a0                   phi.begin_values()[c * phi.static_n_q_points + q] =\\n\\u00a0                     phi.begin_values()[c * phi.static_n_q_points + q] * factor;\\n\\u00a0               }\\n\\u00a0 \\nTransform values from collocation space to the original Gauss-Lobatto space:\\n\\u00a0             internal::FEEvaluationImplBasisChange<\\n\\u00a0               internal::EvaluatorVariant::evaluate_evenodd,\\n\\u00a0               internal::EvaluatorQuantity::hessian,\\n\\u00a0               dim,\\n\\u00a0               degree + 1,\\n\\u00a0               n_points_1d>::do_backward(dim + 2,\\n\\u00a0                                         data.get_shape_info()\\n\\u00a0                                           .data[0]\\n\\u00a0                                           .inverse_shape_values_eo,\\n\\u00a0                                         false,\\n\\u00a0                                         phi.begin_values(),\\n\\u00a0                                         phi.begin_dof_values());\\n\\u00a0 \\ninternal::EvaluatorQuantity::hessian@ hessian\\ninternal::FEEvaluationImplBasisChangeDefinition evaluation_kernels.h:778\\nPerform Runge-Kutta update and write results back to global vectors:\\n\\u00a0             if (ai == Number())\\n\\u00a0               {\\n\\u00a0                 for (unsigned int q = 0; q < phi.static_dofs_per_cell; ++q)\\n\\u00a0                   phi.begin_dof_values()[q] = bi * phi.begin_dof_values()[q];\\n\\u00a0                 phi.distribute_local_to_global(solution);\\n\\u00a0               }\\n\\u00a0             else\\n\\u00a0               {\\n\\u00a0                 if (stage != 0)\\n\\u00a0                   phi_temp.read_dof_values(solution);\\n\\u00a0 \\n\\u00a0                 for (unsigned int q = 0; q < phi.static_dofs_per_cell; ++q)\\n\\u00a0                   {\\n\\u00a0                     const auto K_i = phi.begin_dof_values()[q];\\n\\u00a0 \\n\\u00a0                     phi.begin_dof_values()[q] =\\n\\u00a0                       phi_temp.begin_dof_values()[q] + (ai * K_i);\\n\\u00a0 \\n\\u00a0                     phi_temp.begin_dof_values()[q] += bi * K_i;\\n\\u00a0                   }\\n\\u00a0                 phi.set_dof_values(dst);\\n\\u00a0                 phi_temp.set_dof_values(solution);\\n\\u00a0               }\\n\\u00a0           }\\n\\u00a0       },\\n\\u00a0       vec_ki,\\n\\u00a0       current_ri,\\n\\u00a0       true,\\n\\u00a0       MatrixFree<dim, Number, VectorizedArrayType>::DataAccessOnFaces::values);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\nFrom here, the code of step-67 has not changed.\\n\\u00a0   template <int dim, int degree, int n_points_1d>\\n\\u00a0   void EulerOperator<dim, degree, n_points_1d>::initialize_vector(\\n\\u00a0     LinearAlgebra::distributed::Vector<Number> &vector) const\\n\\u00a0   {\\n\\u00a0     data.initialize_dof_vector(vector);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim, int degree, int n_points_1d>\\n\\u00a0   void EulerOperator<dim, degree, n_points_1d>::set_inflow_boundary(\\n\\u00a0     const types::boundary_id       boundary_id,\\n\\u00a0     std::unique_ptr<Function<dim>> inflow_function)\\n\\u00a0   {\\n\\u00a0     AssertThrow(subsonic_outflow_boundaries.find(boundary_id) ==\\n\\u00a0                     subsonic_outflow_boundaries.end() &&\\n\\u00a0                   wall_boundaries.find(boundary_id) == wall_boundaries.end(),\\n\\u00a0                 ExcMessage(\\\"You already set the boundary with id \\\" +\\n\\u00a0                            std::to_string(static_cast<int>(boundary_id)) +\\n\\u00a0                            \\\" to another type of boundary before now setting \\\" +\\n\\u00a0                            \\\"it as inflow\\\"));\\n\\u00a0     AssertThrow(inflow_function->n_components == dim + 2,\\n\\u00a0                 ExcMessage(\\\"Expected function with dim+2 components\\\"));\\n\\u00a0 \\n\\u00a0     inflow_boundaries[boundary_id] = std::move(inflow_function);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim, int degree, int n_points_1d>\\n\\u00a0   void EulerOperator<dim, degree, n_points_1d>::set_subsonic_outflow_boundary(\\n\\u00a0     const types::boundary_id       boundary_id,\\n\\u00a0     std::unique_ptr<Function<dim>> outflow_function)\\n\\u00a0   {\\n\\u00a0     AssertThrow(inflow_boundaries.find(boundary_id) ==\\n\\u00a0                     inflow_boundaries.end() &&\\n\\u00a0                   wall_boundaries.find(boundary_id) == wall_boundaries.end(),\\n\\u00a0                 ExcMessage(\\\"You already set the boundary with id \\\" +\\n\\u00a0                            std::to_string(static_cast<int>(boundary_id)) +\\n\\u00a0                            \\\" to another type of boundary before now setting \\\" +\\n\\u00a0                            \\\"it as subsonic outflow\\\"));\\n\\u00a0     AssertThrow(outflow_function->n_components == dim + 2,\\n\\u00a0                 ExcMessage(\\\"Expected function with dim+2 components\\\"));\\n\\u00a0 \\n\\u00a0     subsonic_outflow_boundaries[boundary_id] = std::move(outflow_function);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim, int degree, int n_points_1d>\\n\\u00a0   void EulerOperator<dim, degree, n_points_1d>::set_wall_boundary(\\n\\u00a0     const types::boundary_id boundary_id)\\n\\u00a0   {\\n\\u00a0     AssertThrow(inflow_boundaries.find(boundary_id) ==\\n\\u00a0                     inflow_boundaries.end() &&\\n\\u00a0                   subsonic_outflow_boundaries.find(boundary_id) ==\\n\\u00a0                     subsonic_outflow_boundaries.end(),\\n\\u00a0                 ExcMessage(\\\"You already set the boundary with id \\\" +\\n\\u00a0                            std::to_string(static_cast<int>(boundary_id)) +\\n\\u00a0                            \\\" to another type of boundary before now setting \\\" +\\n\\u00a0                            \\\"it as wall boundary\\\"));\\n\\u00a0 \\n\\u00a0     wall_boundaries.insert(boundary_id);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim, int degree, int n_points_1d>\\n\\u00a0   void EulerOperator<dim, degree, n_points_1d>::set_body_force(\\n\\u00a0     std::unique_ptr<Function<dim>> body_force)\\n\\u00a0   {\\n\\u00a0     AssertDimension(body_force->n_components, dim);\\n\\u00a0 \\n\\u00a0     this->body_force = std::move(body_force);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim, int degree, int n_points_1d>\\n\\u00a0   void EulerOperator<dim, degree, n_points_1d>::project(\\n\\u00a0     const Function<dim>                        &function,\\n\\u00a0     LinearAlgebra::distributed::Vector<Number> &solution) const\\n\\u00a0   {\\n\\u00a0     FEEvaluation<dim, degree, degree + 1, dim + 2, Number, VectorizedArrayType>\\n\\u00a0       phi(data, 0, 1);\\n\\u00a0     MatrixFreeOperators::CellwiseInverseMassMatrix<dim,\\n\\u00a0                                                    degree,\\n\\u00a0                                                    dim + 2,\\n\\u00a0                                                    Number,\\n\\u00a0                                                    VectorizedArrayType>\\n\\u00a0       inverse(phi);\\n\\u00a0     solution.zero_out_ghost_values();\\n\\u00a0     for (unsigned int cell = 0; cell < data.n_cell_batches(); ++cell)\\n\\u00a0       {\\n\\u00a0         phi.reinit(cell);\\n\\u00a0         for (const unsigned int q : phi.quadrature_point_indices())\\n\\u00a0           phi.submit_dof_value(evaluate_function(function,\\n\\u00a0                                                  phi.quadrature_point(q)),\\n\\u00a0                                q);\\n\\u00a0         inverse.transform_from_q_points_to_basis(dim + 2,\\n\\u00a0                                                  phi.begin_dof_values(),\\n\\u00a0                                                  phi.begin_dof_values());\\n\\u00a0         phi.set_dof_values(solution);\\n\\u00a0       }\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim, int degree, int n_points_1d>\\n\\u00a0   std::array<double, 3> EulerOperator<dim, degree, n_points_1d>::compute_errors(\\n\\u00a0     const Function<dim>                              &function,\\n\\u00a0     const LinearAlgebra::distributed::Vector<Number> &solution) const\\n\\u00a0   {\\n\\u00a0     TimerOutput::Scope t(timer, \\\"compute errors\\\");\\n\\u00a0     double             errors_squared[3] = {};\\n\\u00a0     FEEvaluation<dim, degree, n_points_1d, dim + 2, Number, VectorizedArrayType>\\n\\u00a0       phi(data, 0, 0);\\n\\u00a0 \\n\\u00a0     for (unsigned int cell = 0; cell < data.n_cell_batches(); ++cell)\\n\\u00a0       {\\n\\u00a0         phi.reinit(cell);\\n\\u00a0         phi.gather_evaluate(solution, EvaluationFlags::values);\\n\\u00a0         VectorizedArrayType local_errors_squared[3] = {};\\n\\u00a0         for (const unsigned int q : phi.quadrature_point_indices())\\n\\u00a0           {\\n\\u00a0             const auto error =\\n\\u00a0               evaluate_function(function, phi.quadrature_point(q)) -\\n\\u00a0               phi.get_value(q);\\n\\u00a0             const auto JxW = phi.JxW(q);\\n\\u00a0 \\n\\u00a0             local_errors_squared[0] += error[0] * error[0] * JxW;\\n\\u00a0             for (unsigned int d = 0; d < dim; ++d)\\n\\u00a0               local_errors_squared[1] += (error[d + 1] * error[d + 1]) * JxW;\\n\\u00a0             local_errors_squared[2] += (error[dim + 1] * error[dim + 1]) * JxW;\\n\\u00a0           }\\n\\u00a0         for (unsigned int v = 0; v < data.n_active_entries_per_cell_batch(cell);\\n\\u00a0              ++v)\\n\\u00a0           for (unsigned int d = 0; d < 3; ++d)\\n\\u00a0             errors_squared[d] += local_errors_squared[d][v];\\n\\u00a0       }\\n\\u00a0 \\n\\u00a0     Utilities::MPI::sum(errors_squared, MPI_COMM_WORLD, errors_squared);\\n\\u00a0 \\n\\u00a0     std::array<double, 3> errors;\\n\\u00a0     for (unsigned int d = 0; d < 3; ++d)\\n\\u00a0       errors[d] = std::sqrt(errors_squared[d]);\\n\\u00a0 \\n\\u00a0     return errors;\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim, int degree, int n_points_1d>\\n\\u00a0   double EulerOperator<dim, degree, n_points_1d>::compute_cell_transport_speed(\\n\\u00a0     const LinearAlgebra::distributed::Vector<Number> &solution) const\\n\\u00a0   {\\n\\u00a0     TimerOutput::Scope t(timer, \\\"compute transport speed\\\");\\n\\u00a0     Number             max_transport = 0;\\n\\u00a0     FEEvaluation<dim, degree, degree + 1, dim + 2, Number, VectorizedArrayType>\\n\\u00a0       phi(data, 0, 1);\\n\\u00a0 \\n\\u00a0     for (unsigned int cell = 0; cell < data.n_cell_batches(); ++cell)\\n\\u00a0       {\\n\\u00a0         phi.reinit(cell);\\n\\u00a0         phi.gather_evaluate(solution, EvaluationFlags::values);\\n\\u00a0         VectorizedArrayType local_max = 0.;\\n\\u00a0         for (const unsigned int q : phi.quadrature_point_indices())\\n\\u00a0           {\\n\\u00a0             const auto solution = phi.get_value(q);\\n\\u00a0             const auto velocity = euler_velocity<dim>(solution);\\n\\u00a0             const auto pressure = euler_pressure<dim>(solution);\\n\\u00a0 \\n\\u00a0             const auto          inverse_jacobian = phi.inverse_jacobian(q);\\n\\u00a0             const auto          convective_speed = inverse_jacobian * velocity;\\n\\u00a0             VectorizedArrayType convective_limit = 0.;\\n\\u00a0             for (unsigned int d = 0; d < dim; ++d)\\n\\u00a0               convective_limit =\\n\\u00a0                 std::max(convective_limit, std::abs(convective_speed[d]));\\n\\u00a0 \\n\\u00a0             const auto speed_of_sound =\\n\\u00a0               std::sqrt(gamma * pressure * (1. / solution[0]));\\n\\u00a0 \\n\\u00a0             Tensor<1, dim, VectorizedArrayType> eigenvector;\\n\\u00a0             for (unsigned int d = 0; d < dim; ++d)\\n\\u00a0               eigenvector[d] = 1.;\\n\\u00a0             for (unsigned int i = 0; i < 5; ++i)\\n\\u00a0               {\\n\\u00a0                 eigenvector = transpose(inverse_jacobian) *\\n\\u00a0                               (inverse_jacobian * eigenvector);\\n\\u00a0                 VectorizedArrayType eigenvector_norm = 0.;\\n\\u00a0                 for (unsigned int d = 0; d < dim; ++d)\\n\\u00a0                   eigenvector_norm =\\n\\u00a0                     std::max(eigenvector_norm, std::abs(eigenvector[d]));\\n\\u00a0                 eigenvector /= eigenvector_norm;\\n\\u00a0               }\\n\\u00a0             const auto jac_times_ev   = inverse_jacobian * eigenvector;\\n\\u00a0             const auto max_eigenvalue = std::sqrt(\\n\\u00a0               (jac_times_ev * jac_times_ev) / (eigenvector * eigenvector));\\n\\u00a0             local_max =\\n\\u00a0               std::max(local_max,\\n\\u00a0                        max_eigenvalue * speed_of_sound + convective_limit);\\n\\u00a0           }\\n\\u00a0 \\n\\u00a0         for (unsigned int v = 0; v < data.n_active_entries_per_cell_batch(cell);\\n\\u00a0              ++v)\\n\\u00a0           max_transport = std::max(max_transport, local_max[v]);\\n\\u00a0       }\\n\\u00a0 \\n\\u00a0     max_transport = Utilities::MPI::max(max_transport, MPI_COMM_WORLD);\\n\\u00a0 \\n\\u00a0     return max_transport;\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim>\\n\\u00a0   class EulerProblem\\n\\u00a0   {\\n\\u00a0   public:\\n\\u00a0     EulerProblem();\\n\\u00a0 \\n\\u00a0     void run();\\n\\u00a0 \\n\\u00a0   private:\\n\\u00a0     void make_grid_and_dofs();\\n\\u00a0 \\n\\u00a0     void output_results(const unsigned int result_number);\\n\\u00a0 \\n\\u00a0     LinearAlgebra::distributed::Vector<Number> solution;\\n\\u00a0 \\n\\u00a0     ConditionalOStream pcout;\\n\\u00a0 \\n\\u00a0 #ifdef DEAL_II_WITH_P4EST\\n\\u00a0     parallel::distributed::Triangulation<dim> triangulation;\\n\\u00a0 #else\\n\\u00a0     Triangulation<dim> triangulation;\\n\\u00a0 #endif\\n\\u00a0 \\n\\u00a0     const FESystem<dim> fe;\\n\\u00a0     MappingQ<dim>       mapping;\\n\\u00a0     DoFHandler<dim>     dof_handler;\\n\\u00a0 \\n\\u00a0     TimerOutput timer;\\n\\u00a0 \\n\\u00a0     EulerOperator<dim, fe_degree, n_q_points_1d> euler_operator;\\n\\u00a0 \\n\\u00a0     double time, time_step;\\n\\u00a0 \\n\\u00a0     class Postprocessor : public DataPostprocessor<dim>\\n\\u00a0     {\\n\\u00a0     public:\\n\\u00a0       Postprocessor();\\n\\u00a0 \\n\\u00a0       virtual void evaluate_vector_field(\\n\\u00a0         const DataPostprocessorInputs::Vector<dim> &inputs,\\n\\u00a0         std::vector<Vector<double>> &computed_quantities) const override;\\n\\u00a0 \\n\\u00a0       virtual std::vector<std::string> get_names() const override;\\n\\u00a0 \\n\\u00a0       virtual std::vector<\\n\\u00a0         DataComponentInterpretation::DataComponentInterpretation>\\n\\u00a0       get_data_component_interpretation() const override;\\n\\u00a0 \\n\\u00a0       virtual UpdateFlags get_needed_update_flags() const override;\\n\\u00a0 \\n\\u00a0     private:\\n\\u00a0       const bool do_schlieren_plot;\\n\\u00a0     };\\n\\u00a0   };\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim>\\n\\u00a0   EulerProblem<dim>::Postprocessor::Postprocessor()\\n\\u00a0     : do_schlieren_plot(dim == 2)\\n\\u00a0   {}\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim>\\n\\u00a0   void EulerProblem<dim>::Postprocessor::evaluate_vector_field(\\n\\u00a0     const DataPostprocessorInputs::Vector<dim> &inputs,\\n\\u00a0     std::vector<Vector<double>>                &computed_quantities) const\\n\\u00a0   {\\n\\u00a0     const unsigned int n_evaluation_points = inputs.solution_values.size();\\n\\u00a0 \\n\\u00a0     if (do_schlieren_plot == true)\\n\\u00a0       Assert(inputs.solution_gradients.size() == n_evaluation_points,\\n\\u00a0              ExcInternalError());\\n\\u00a0 \\n\\u00a0     Assert(computed_quantities.size() == n_evaluation_points,\\n\\u00a0            ExcInternalError());\\n\\u00a0     Assert(inputs.solution_values[0].size() == dim + 2, ExcInternalError());\\n\\u00a0     Assert(computed_quantities[0].size() ==\\n\\u00a0              dim + 2 + (do_schlieren_plot == true ? 1 : 0),\\n\\u00a0            ExcInternalError());\\n\\u00a0 \\n\\u00a0     for (unsigned int p = 0; p < n_evaluation_points; ++p)\\n\\u00a0       {\\n\\u00a0         Tensor<1, dim + 2> solution;\\n\\u00a0         for (unsigned int d = 0; d < dim + 2; ++d)\\n\\u00a0           solution[d] = inputs.solution_values[p](d);\\n\\u00a0 \\n\\u00a0         const double         density  = solution[0];\\n\\u00a0         const Tensor<1, dim> velocity = euler_velocity<dim>(solution);\\n\\u00a0         const double         pressure = euler_pressure<dim>(solution);\\n\\u00a0 \\n\\u00a0         for (unsigned int d = 0; d < dim; ++d)\\n\\u00a0           computed_quantities[p](d) = velocity[d];\\n\\u00a0         computed_quantities[p](dim)     = pressure;\\n\\u00a0         computed_quantities[p](dim + 1) = std::sqrt(gamma * pressure / density);\\n\\u00a0 \\n\\u00a0         if (do_schlieren_plot == true)\\n\\u00a0           computed_quantities[p](dim + 2) =\\n\\u00a0             inputs.solution_gradients[p][0] * inputs.solution_gradients[p][0];\\n\\u00a0       }\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim>\\n\\u00a0   std::vector<std::string> EulerProblem<dim>::Postprocessor::get_names() const\\n\\u00a0   {\\n\\u00a0     std::vector<std::string> names;\\n\\u00a0     for (unsigned int d = 0; d < dim; ++d)\\n\\u00a0       names.emplace_back(\\\"velocity\\\");\\n\\u00a0     names.emplace_back(\\\"pressure\\\");\\n\\u00a0     names.emplace_back(\\\"speed_of_sound\\\");\\n\\u00a0 \\n\\u00a0     if (do_schlieren_plot == true)\\n\\u00a0       names.emplace_back(\\\"schlieren_plot\\\");\\n\\u00a0 \\n\\u00a0     return names;\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim>\\n\\u00a0   std::vector<DataComponentInterpretation::DataComponentInterpretation>\\n\\u00a0   EulerProblem<dim>::Postprocessor::get_data_component_interpretation() const\\n\\u00a0   {\\n\\u00a0     std::vector<DataComponentInterpretation::DataComponentInterpretation>\\n\\u00a0       interpretation;\\n\\u00a0     for (unsigned int d = 0; d < dim; ++d)\\n\\u00a0       interpretation.push_back(\\n\\u00a0         DataComponentInterpretation::component_is_part_of_vector);\\n\\u00a0     interpretation.push_back(DataComponentInterpretation::component_is_scalar);\\n\\u00a0     interpretation.push_back(DataComponentInterpretation::component_is_scalar);\\n\\u00a0 \\n\\u00a0     if (do_schlieren_plot == true)\\n\\u00a0       interpretation.push_back(\\n\\u00a0         DataComponentInterpretation::component_is_scalar);\\n\\u00a0 \\n\\u00a0     return interpretation;\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim>\\n\\u00a0   UpdateFlags EulerProblem<dim>::Postprocessor::get_needed_update_flags() const\\n\\u00a0   {\\n\\u00a0     if (do_schlieren_plot == true)\\n\\u00a0       return update_values | update_gradients;\\n\\u00a0     else\\n\\u00a0       return update_values;\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim>\\n\\u00a0   EulerProblem<dim>::EulerProblem()\\n\\u00a0     : pcout(std::cout, Utilities::MPI::this_mpi_process(MPI_COMM_WORLD) == 0)\\n\\u00a0 #ifdef DEAL_II_WITH_P4EST\\n\\u00a0     , triangulation(MPI_COMM_WORLD)\\n\\u00a0 #endif\\n\\u00a0     , fe(FE_DGQ<dim>(fe_degree), dim + 2)\\n\\u00a0     , mapping(fe_degree)\\n\\u00a0     , dof_handler(triangulation)\\n\\u00a0     , timer(pcout, TimerOutput::never, TimerOutput::wall_times)\\n\\u00a0     , euler_operator(timer)\\n\\u00a0     , time(0)\\n\\u00a0     , time_step(0)\\n\\u00a0   {}\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim>\\n\\u00a0   void EulerProblem<dim>::make_grid_and_dofs()\\n\\u00a0   {\\n\\u00a0     switch (testcase)\\n\\u00a0       {\\n\\u00a0         case 0:\\n\\u00a0           {\\n\\u00a0             Point<dim> lower_left;\\n\\u00a0             for (unsigned int d = 1; d < dim; ++d)\\n\\u00a0               lower_left[d] = -5;\\n\\u00a0 \\n\\u00a0             Point<dim> upper_right;\\n\\u00a0             upper_right[0] = 10;\\n\\u00a0             for (unsigned int d = 1; d < dim; ++d)\\n\\u00a0               upper_right[d] = 5;\\n\\u00a0 \\n\\u00a0             GridGenerator::hyper_rectangle(triangulation,\\n\\u00a0                                            lower_left,\\n\\u00a0                                            upper_right);\\n\\u00a0             triangulation.refine_global(2);\\n\\u00a0 \\n\\u00a0             euler_operator.set_inflow_boundary(\\n\\u00a0               0, std::make_unique<ExactSolution<dim>>(0));\\n\\u00a0 \\n\\u00a0             break;\\n\\u00a0           }\\n\\u00a0 \\n\\u00a0         case 1:\\n\\u00a0           {\\n\\u00a0             GridGenerator::channel_with_cylinder(\\n\\u00a0               triangulation, 0.03, 1, 0, true);\\n\\u00a0 \\n\\u00a0             euler_operator.set_inflow_boundary(\\n\\u00a0               0, std::make_unique<ExactSolution<dim>>(0));\\n\\u00a0             euler_operator.set_subsonic_outflow_boundary(\\n\\u00a0               1, std::make_unique<ExactSolution<dim>>(0));\\n\\u00a0 \\n\\u00a0             euler_operator.set_wall_boundary(2);\\n\\u00a0             euler_operator.set_wall_boundary(3);\\n\\u00a0 \\n\\u00a0             if (dim == 3)\\n\\u00a0               euler_operator.set_body_force(\\n\\u00a0                 std::make_unique<Functions::ConstantFunction<dim>>(\\n\\u00a0                   std::vector<double>({0., 0., -0.2})));\\n\\u00a0 \\n\\u00a0             break;\\n\\u00a0           }\\n\\u00a0 \\n\\u00a0         default:\\n\\u00a0           DEAL_II_NOT_IMPLEMENTED();\\n\\u00a0       }\\n\\u00a0 \\n\\u00a0     triangulation.refine_global(n_global_refinements);\\n\\u00a0 \\n\\u00a0     dof_handler.distribute_dofs(fe);\\n\\u00a0 \\n\\u00a0     euler_operator.reinit(mapping, dof_handler);\\n\\u00a0     euler_operator.initialize_vector(solution);\\n\\u00a0 \\n\\u00a0     std::locale s = pcout.get_stream().getloc();\\n\\u00a0     pcout.get_stream().imbue(std::locale(\\\"\\\"));\\n\\u00a0     pcout << \\\"Number of degrees of freedom: \\\" << dof_handler.n_dofs()\\n\\u00a0           << \\\" ( = \\\" << (dim + 2) << \\\" [vars] x \\\"\\n\\u00a0           << triangulation.n_global_active_cells() << \\\" [cells] x \\\"\\n\\u00a0           << Utilities::pow(fe_degree + 1, dim) << \\\" [dofs/cell/var] )\\\"\\n\\u00a0           << std::endl;\\n\\u00a0     pcout.get_stream().imbue(s);\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim>\\n\\u00a0   void EulerProblem<dim>::output_results(const unsigned int result_number)\\n\\u00a0   {\\n\\u00a0     const std::array<double, 3> errors =\\n\\u00a0       euler_operator.compute_errors(ExactSolution<dim>(time), solution);\\n\\u00a0     const std::string quantity_name = testcase == 0 ? \\\"error\\\" : \\\"norm\\\";\\n\\u00a0 \\n\\u00a0     pcout << \\\"Time:\\\" << std::setw(8) << std::setprecision(3) << time\\n\\u00a0           << \\\", dt: \\\" << std::setw(8) << std::setprecision(2) << time_step\\n\\u00a0           << \\\", \\\" << quantity_name << \\\" rho: \\\" << std::setprecision(4)\\n\\u00a0           << std::setw(10) << errors[0] << \\\", rho * u: \\\" << std::setprecision(4)\\n\\u00a0           << std::setw(10) << errors[1] << \\\", energy:\\\" << std::setprecision(4)\\n\\u00a0           << std::setw(10) << errors[2] << std::endl;\\n\\u00a0 \\n\\u00a0     {\\n\\u00a0       TimerOutput::Scope t(timer, \\\"output\\\");\\n\\u00a0 \\n\\u00a0       Postprocessor postprocessor;\\n\\u00a0       DataOut<dim>  data_out;\\n\\u00a0 \\n\\u00a0       DataOutBase::VtkFlags flags;\\n\\u00a0       flags.write_higher_order_cells = true;\\n\\u00a0       data_out.set_flags(flags);\\n\\u00a0 \\n\\u00a0       data_out.attach_dof_handler(dof_handler);\\n\\u00a0       {\\n\\u00a0         std::vector<std::string> names;\\n\\u00a0         names.emplace_back(\\\"density\\\");\\n\\u00a0         for (unsigned int d = 0; d < dim; ++d)\\n\\u00a0           names.emplace_back(\\\"momentum\\\");\\n\\u00a0         names.emplace_back(\\\"energy\\\");\\n\\u00a0 \\n\\u00a0         std::vector<DataComponentInterpretation::DataComponentInterpretation>\\n\\u00a0           interpretation;\\n\\u00a0         interpretation.push_back(\\n\\u00a0           DataComponentInterpretation::component_is_scalar);\\n\\u00a0         for (unsigned int d = 0; d < dim; ++d)\\n\\u00a0           interpretation.push_back(\\n\\u00a0             DataComponentInterpretation::component_is_part_of_vector);\\n\\u00a0         interpretation.push_back(\\n\\u00a0           DataComponentInterpretation::component_is_scalar);\\n\\u00a0 \\n\\u00a0         data_out.add_data_vector(dof_handler, solution, names, interpretation);\\n\\u00a0       }\\n\\u00a0       data_out.add_data_vector(solution, postprocessor);\\n\\u00a0 \\n\\u00a0       LinearAlgebra::distributed::Vector<Number> reference;\\n\\u00a0       if (testcase == 0 && dim == 2)\\n\\u00a0         {\\n\\u00a0           reference.reinit(solution);\\n\\u00a0           euler_operator.project(ExactSolution<dim>(time), reference);\\n\\u00a0           reference.sadd(-1., 1, solution);\\n\\u00a0           std::vector<std::string> names;\\n\\u00a0           names.emplace_back(\\\"error_density\\\");\\n\\u00a0           for (unsigned int d = 0; d < dim; ++d)\\n\\u00a0             names.emplace_back(\\\"error_momentum\\\");\\n\\u00a0           names.emplace_back(\\\"error_energy\\\");\\n\\u00a0 \\n\\u00a0           std::vector<DataComponentInterpretation::DataComponentInterpretation>\\n\\u00a0             interpretation;\\n\\u00a0           interpretation.push_back(\\n\\u00a0             DataComponentInterpretation::component_is_scalar);\\n\\u00a0           for (unsigned int d = 0; d < dim; ++d)\\n\\u00a0             interpretation.push_back(\\n\\u00a0               DataComponentInterpretation::component_is_part_of_vector);\\n\\u00a0           interpretation.push_back(\\n\\u00a0             DataComponentInterpretation::component_is_scalar);\\n\\u00a0 \\n\\u00a0           data_out.add_data_vector(dof_handler,\\n\\u00a0                                    reference,\\n\\u00a0                                    names,\\n\\u00a0                                    interpretation);\\n\\u00a0         }\\n\\u00a0 \\n\\u00a0       Vector<double> mpi_owner(triangulation.n_active_cells());\\n\\u00a0       mpi_owner = Utilities::MPI::this_mpi_process(MPI_COMM_WORLD);\\n\\u00a0       data_out.add_data_vector(mpi_owner, \\\"owner\\\");\\n\\u00a0 \\n\\u00a0       data_out.build_patches(mapping,\\n\\u00a0                              fe.degree,\\n\\u00a0                              DataOut<dim>::curved_inner_cells);\\n\\u00a0 \\n\\u00a0       const std::string filename =\\n\\u00a0         \\\"solution_\\\" + Utilities::int_to_string(result_number, 3) + \\\".vtu\\\";\\n\\u00a0       data_out.write_vtu_in_parallel(filename, MPI_COMM_WORLD);\\n\\u00a0     }\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 \\n\\u00a0   template <int dim>\\n\\u00a0   void EulerProblem<dim>::run()\\n\\u00a0   {\\n\\u00a0     {\\n\\u00a0       const unsigned int n_vect_number = VectorizedArrayType::size();\\n\\u00a0       const unsigned int n_vect_bits   = 8 * sizeof(Number) * n_vect_number;\\n\\u00a0 \\n\\u00a0       pcout << \\\"Running with \\\"\\n\\u00a0             << Utilities::MPI::n_mpi_processes(MPI_COMM_WORLD)\\n\\u00a0             << \\\" MPI processes\\\" << std::endl;\\n\\u00a0       pcout << \\\"Vectorization over \\\" << n_vect_number << ' '\\n\\u00a0             << (std::is_same_v<Number, double> ? \\\"doubles\\\" : \\\"floats\\\") << \\\" = \\\"\\n\\u00a0             << n_vect_bits << \\\" bits (\\\"\\n\\u00a0             << Utilities::System::get_current_vectorization_level() << ')'\\n\\u00a0             << std::endl;\\n\\u00a0     }\\n\\u00a0 \\n\\u00a0     make_grid_and_dofs();\\n\\u00a0 \\n\\u00a0     const LowStorageRungeKuttaIntegrator integrator(lsrk_scheme);\\n\\u00a0 \\n\\u00a0     LinearAlgebra::distributed::Vector<Number> rk_register_1;\\n\\u00a0     LinearAlgebra::distributed::Vector<Number> rk_register_2;\\n\\u00a0     rk_register_1.reinit(solution);\\n\\u00a0     rk_register_2.reinit(solution);\\n\\u00a0 \\n\\u00a0     euler_operator.project(ExactSolution<dim>(time), solution);\\n\\u00a0 \\n\\u00a0 \\n\\u00a0     double min_vertex_distance = std::numeric_limits<double>::max();\\n\\u00a0     for (const auto &cell : triangulation.active_cell_iterators())\\n\\u00a0       if (cell->is_locally_owned())\\n\\u00a0         min_vertex_distance =\\n\\u00a0           std::min(min_vertex_distance, cell->minimum_vertex_distance());\\n\\u00a0     min_vertex_distance =\\n\\u00a0       Utilities::MPI::min(min_vertex_distance, MPI_COMM_WORLD);\\n\\u00a0 \\n\\u00a0     time_step = courant_number * integrator.n_stages() /\\n\\u00a0                 euler_operator.compute_cell_transport_speed(solution);\\n\\u00a0     pcout << \\\"Time step size: \\\" << time_step\\n\\u00a0           << \\\", minimal h: \\\" << min_vertex_distance\\n\\u00a0           << \\\", initial transport scaling: \\\"\\n\\u00a0           << 1. / euler_operator.compute_cell_transport_speed(solution)\\n\\u00a0           << std::endl\\n\\u00a0           << std::endl;\\n\\u00a0 \\n\\u00a0     output_results(0);\\n\\u00a0 \\n\\u00a0     unsigned int timestep_number = 0;\\n\\u00a0 \\n\\u00a0     while (time < final_time - 1e-12 && timestep_number < max_time_steps)\\n\\u00a0       {\\n\\u00a0         ++timestep_number;\\n\\u00a0         if (timestep_number % 5 == 0)\\n\\u00a0           time_step =\\n\\u00a0             courant_number * integrator.n_stages() /\\n\\u00a0             Utilities::truncate_to_n_digits(\\n\\u00a0               euler_operator.compute_cell_transport_speed(solution), 3);\\n\\u00a0 \\n\\u00a0         {\\n\\u00a0           TimerOutput::Scope t(timer, \\\"rk time stepping total\\\");\\n\\u00a0           integrator.perform_time_step(euler_operator,\\n\\u00a0                                        time,\\n\\u00a0                                        time_step,\\n\\u00a0                                        solution,\\n\\u00a0                                        rk_register_1,\\n\\u00a0                                        rk_register_2);\\n\\u00a0         }\\n\\u00a0 \\n\\u00a0         time += time_step;\\n\\u00a0 \\n\\u00a0         if (static_cast<int>(time / output_tick) !=\\n\\u00a0               static_cast<int>((time - time_step) / output_tick) ||\\n\\u00a0             time >= final_time - 1e-12)\\n\\u00a0           output_results(\\n\\u00a0             static_cast<unsigned int>(std::round(time / output_tick)));\\n\\u00a0       }\\n\\u00a0 \\n\\u00a0     timer.print_wall_time_statistics(MPI_COMM_WORLD);\\n\\u00a0     pcout << std::endl;\\n\\u00a0   }\\n\\u00a0 \\n\\u00a0 } // namespace Euler_DG\\n\\u00a0 \\n\\u00a0 \\n\\u00a0 int main(int argc, char **argv)\\n\\u00a0 {\\n\\u00a0   using namespace Euler_DG;\\n\\u00a0   using namespace dealii;\\n\\u00a0 \\n\\u00a0   Utilities::MPI::MPI_InitFinalize mpi_initialization(argc, argv, 1);\\n\\u00a0 \\n\\u00a0   try\\n\\u00a0     {\\n\\u00a0       EulerProblem<dimension> euler_problem;\\n\\u00a0       euler_problem.run();\\n\\u00a0     }\\n\\u00a0   catch (std::exception &exc)\\n\\u00a0     {\\n\\u00a0       std::cerr << std::endl\\n\\u00a0                 << std::endl\\n\\u00a0                 << \\\"----------------------------------------------------\\\"\\n\\u00a0                 << std::endl;\\n\\u00a0       std::cerr << \\\"Exception on processing: \\\" << std::endl\\n\\u00a0                 << exc.what() << std::endl\\n\\u00a0                 << \\\"Aborting!\\\" << std::endl\\n\\u00a0                 << \\\"----------------------------------------------------\\\"\\n\\u00a0                 << std::endl;\\n\\u00a0 \\n\\u00a0       return 1;\\n\\u00a0     }\\n\\u00a0   catch (...)\\n\\u00a0     {\\n\\u00a0       std::cerr << std::endl\\n\\u00a0                 << std::endl\\n\\u00a0                 << \\\"----------------------------------------------------\\\"\\n\\u00a0                 << std::endl;\\n\\u00a0       std::cerr << \\\"Unknown exception!\\\" << std::endl\\n\\u00a0                 << \\\"Aborting!\\\" << std::endl\\n\\u00a0                 << \\\"----------------------------------------------------\\\"\\n\\u00a0                 << std::endl;\\n\\u00a0       return 1;\\n\\u00a0     }\\n\\u00a0 \\n\\u00a0   return 0;\\n\\u00a0 }\\nConditionalOStreamDefinition conditional_ostream.h:80\\nDataOutDefinition data_out.h:147\\nDataPostprocessorDefinition data_postprocessor.h:583\\nFESystemDefinition fe_system.h:208\\nFE_DGQDefinition fe_dgq.h:112\\nLinearAlgebra::distributed::Vector::reinitvoid reinit(const size_type size, const bool omit_zeroing_entries=false)\\nMappingQDefinition mapping_q.h:110\\nMatrixFreeOperators::CellwiseInverseMassMatrixDefinition operators.h:622\\nTimerOutput::ScopeDefinition timer.h:557\\nTriangulationDefinition tria.h:1323\\nTriangulation::n_active_cellsunsigned int n_active_cells() const\\nTriangulation::refine_globalvoid refine_global(const unsigned int times=1)\\nUtilities::MPI::MPI_InitFinalizeDefinition mpi.h:1081\\nVectorDefinition vector.h:120\\nparallel::TriangulationBase::n_global_active_cellsvirtual types::global_cell_index n_global_active_cells() const overrideDefinition tria_base.cc:151\\nparallel::distributed::TriangulationDefinition tria.h:268\\ntransposeDerivativeForm< 1, spacedim, dim, Number > transpose(const DerivativeForm< 1, dim, spacedim, Number > &DF)Definition derivative_form.h:610\\nUpdateFlagsUpdateFlagsDefinition fe_update_flags.h:64\\nInitializeLibrary::MPI@ MPI\\nDataComponentInterpretation::DataComponentInterpretationDataComponentInterpretationDefinition data_component_interpretation.h:47\\nDataComponentInterpretation::component_is_scalar@ component_is_scalarDefinition data_component_interpretation.h:52\\nDataComponentInterpretation::component_is_part_of_vector@ component_is_part_of_vectorDefinition data_component_interpretation.h:58\\nGridGenerator::hyper_rectanglevoid hyper_rectangle(Triangulation< dim, spacedim > &tria, const Point< dim > &p1, const Point< dim > &p2, const bool colorize=false)\\nGridGenerator::channel_with_cylindervoid channel_with_cylinder(Triangulation< dim > &tria, const double shell_region_width=0.03, const unsigned int n_shells=2, const double skewness=2.0, const bool colorize=false)\\nUtilities::MPI::sumT sum(const T &t, const MPI_Comm mpi_communicator)\\nUtilities::MPI::n_mpi_processesunsigned int n_mpi_processes(const MPI_Comm mpi_communicator)Definition mpi.cc:92\\nUtilities::MPI::maxT max(const T &t, const MPI_Comm mpi_communicator)\\nUtilities::MPI::minT min(const T &t, const MPI_Comm mpi_communicator)\\nUtilities::System::get_current_vectorization_levelstd::string get_current_vectorization_level()Definition utilities.cc:938\\nUtilitiesDefinition communication_pattern_base.h:30\\nUtilities::truncate_to_n_digitsNumber truncate_to_n_digits(const Number number, const unsigned int n_digits)Definition utilities.cc:578\\nUtilities::int_to_stringstd::string int_to_string(const unsigned int value, const unsigned int digits=numbers::invalid_unsigned_int)Definition utilities.cc:470\\nUtilities::powconstexpr T pow(const T base, const int iexp)Definition utilities.h:966\\nVectorTools::EvaluationFlags::min@ minDefinition vector_tools_evaluate.h:61\\nWorkStream::internal::tbb_no_coloring::runvoid run(const Iterator &begin, const std_cxx20::type_identity_t< Iterator > &end, Worker worker, Copier copier, const ScratchData &sample_scratch_data, const CopyData &sample_copy_data, const unsigned int queue_length, const unsigned int chunk_size)Definition work_stream.h:471\\nstdSTL namespace.\\ntypes::boundary_idunsigned int boundary_idDefinition types.h:144\\ntriangulationconst ::parallel::distributed::Triangulation< dim, spacedim > * triangulationDefinition p4est_wrappers.cc:68\\nDataOutBase::VtkFlagsDefinition data_out_base.h:1127\\nDataOutBase::VtkFlags::write_higher_order_cellsbool write_higher_order_cellsDefinition data_out_base.h:1201\\nDataPostprocessorInputs::VectorDefinition data_postprocessor.h:400\\n Results\\nRunning the program with the default settings on a machine with 40 processes produces the following output:\\nRunning with 40 MPI processes\\nVectorization over 8 doubles = 512 bits (AVX512)\\nNumber of degrees of freedom: 27.648.000 ( = 5 [vars] x 25.600 [cells] x 216 [dofs/cell/var] )\\nTime step size: 0.000295952, minimal h: 0.0075, initial transport scaling: 0.00441179\\nTime:       0, dt:   0.0003, norm rho:  5.385e-16, rho * u:  1.916e-16, energy: 1.547e-15\\n+--------------------------------------+------------------+------------+------------------+\\n| Total wallclock time elapsed         |     17.52s    10 |     17.52s |     17.52s    11 |\\n|                                      |                  |                               |\\n| Section                  | no. calls |   min time  rank |   avg time |   max time  rank |\\n+--------------------------------------+------------------+------------+------------------+\\n| compute errors           |         1 |  0.009594s    16 |  0.009705s |  0.009819s     8 |\\n| compute transport speed  |        22 |    0.1366s     0 |    0.1367s |    0.1368s    18 |\\n| output                   |         1 |     1.233s     0 |     1.233s |     1.233s    32 |\\n| rk time stepping total   |       100 |     8.746s    35 |     8.746s |     8.746s     0 |\\n| rk_stage - integrals L_h |       500 |     8.742s    36 |     8.742s |     8.743s     2 |\\n+--------------------------------------+------------------+------------+------------------+\\nand the following visual output:\\n\\n\\n  \\n\\n  \\n\\nAs a reference, the results of step-67 using FCL are:\\nRunning with 40 MPI processes\\nVectorization over 8 doubles = 512 bits (AVX512)\\nNumber of degrees of freedom: 27.648.000 ( = 5 [vars] x 25.600 [cells] x 216 [dofs/cell/var] )\\nTime step size: 0.000295952, minimal h: 0.0075, initial transport scaling: 0.00441179\\nTime:       0, dt:   0.0003, norm rho:  5.385e-16, rho * u:  1.916e-16, energy: 1.547e-15\\n+-------------------------------------------+------------------+------------+------------------+\\n| Total wallclock time elapsed              |     13.33s     0 |     13.34s |     13.35s    34 |\\n|                                           |                  |                               |\\n| Section                       | no. calls |   min time  rank |   avg time |   max time  rank |\\n+-------------------------------------------+------------------+------------+------------------+\\n| compute errors                |         1 |  0.007977s    10 |  0.008053s |  0.008161s    30 |\\n| compute transport speed       |        22 |    0.1228s    34 |    0.2227s |    0.3845s     0 |\\n| output                        |         1 |     1.255s     3 |     1.257s |     1.259s    27 |\\n| rk time stepping total        |       100 |     11.15s     0 |     11.32s |     11.42s    34 |\\n| rk_stage - integrals L_h      |       500 |     8.719s    10 |     8.932s |     9.196s     0 |\\n| rk_stage - inv mass + vec upd |       500 |     1.944s     0 |     2.377s |      2.55s    10 |\\n+-------------------------------------------+------------------+------------+------------------+\\nBy the modifications shown in this tutorial, we were able to achieve a speedup of 27% for the Runge-Kutta stages.\\nPossibilities for extensions\\nThe algorithms are easily extendable to higher dimensions: a high-dimensional advection operator based on cell-centric loops is part of the hyper.deal library. An extension of cell-centric loops to locally-refined meshes is more involved.\\nExtension to the compressible Navier-Stokes equations\\nThe solver presented in this tutorial program can also be extended to the compressible Navier\\u2013Stokes equations by adding viscous terms, as also suggested in step-67. To keep as much of the performance obtained here despite the additional cost of elliptic terms, e.g. via an interior penalty method, that tutorial has proposed to switch the basis from FE_DGQ to FE_DGQHermite like in the step-59 tutorial program. The reasoning behind this switch is that in the case of FE_DGQ all values of neighboring cells (i.e., \\\\(k+1\\\\) layers) are needed, whilst in the case of FE_DGQHermite only 2 layers, making the latter significantly more suitable for higher degrees. The additional layers have to be, on the one hand, loaded from main memory during flux computation and, one the other hand, have to be communicated. Using the shared-memory capabilities introduced in this tutorial, the second point can be eliminated on a single compute node or its influence can be reduced in a hybrid context.\\nBlock Gauss-Seidel-like preconditioners\\nCell-centric loops could be used to create block Gauss-Seidel preconditioners that are multiplicative within one process and additive over processes. These type of preconditioners use during flux computation, in contrast to Jacobi-type preconditioners, already updated values from neighboring cells. The following pseudo-code visualizes how this could in principal be achieved:\\n// vector monitor if cells have been updated or not\\nVector<Number> visit_flags(data.n_cell_batches () + data.n_ghost_cell_batches ());\\n \\n// element centric loop with a modified kernel\\ndata.template loop_cell_centric<VectorType, VectorType>(\\n  [&](const auto &data, auto &dst, const auto &src, const auto cell_range) {\\n \\n for (unsigned int cell = cell_range.first; cell < cell_range.second; ++cell)\\n      {\\n // cell integral as usual (not shown)\\n \\n for (unsigned int face = 0; face < GeometryInfo<dim>::faces_per_cell; ++face)\\n          {\\n const auto boundary_id = data.get_faces_by_cells_boundary_id(cell, face)[0];\\n \\n if (boundary_id == numbers::internal_face_boundary_id)\\n              {\\n                phi_p.reinit(cell, face);\\n \\n const auto flags = phi_p.read_cell_data(visit_flags);\\n const auto all_neighbors_have_been_updated =\\n std::min(flags.begin(),\\n                           flags().begin() + data.n_active_entries_per_cell_batch(cell) == 1;\\n \\n if(all_neighbors_have_been_updated)\\n                  phi_p.gather_evaluate(dst, EvaluationFlags::values);\\n else\\n                  phi_p.gather_evaluate(src, EvaluationFlags::values);\\n \\n // continue as usual (not shown)\\n              }\\n else\\n              {\\n // boundary integral as usual (not shown)\\n              }\\n          }\\n \\n // continue as above and apply your favorite algorithm to invert\\n // the cell-local operator (not shown)\\n \\n // make cells as updated\\n        phi.set_cell_data(visit_flags, VectorizedArrayType(1.0));\\n      }\\n  },\\n  dst,\\n  src,\\n true,\\n MatrixFree<dim, Number, VectorizedArrayType>::DataAccessOnFaces::values);\\nFor this purpose, one can exploit the cell-data vector capabilities of MatrixFree and the range-based iteration capabilities of VectorizedArray.\\nPlease note that in the given example we process VectorizedArrayType::size() number of blocks, since each lane corresponds to one block. We consider blocks as updated if all blocks processed by a vector register have been updated. In the case of Cartesian meshes this is a reasonable approach, however, for general unstructured meshes this conservative approach might lead to a decrease in the efficiency of the preconditioner. A reduction of cells processed in parallel by explicitly reducing the number of lanes used by VectorizedArrayType might increase the quality of the preconditioner, but with the cost that each iteration might be more expensive. This dilemma leads us to a further \\\"possibility for extension\\\": vectorization within an element.\\n The plain program\\n/* ------------------------------------------------------------------------\\n *\\n * SPDX-License-Identifier: LGPL-2.1-or-later\\n * Copyright (C) 2021 - 2024 by the deal.II authors\\n *\\n * This file is part of the deal.II library.\\n *\\n * Part of the source code is dual licensed under Apache-2.0 WITH\\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\\n * governing the source code and code contributions can be found in\\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\\n *\\n * ------------------------------------------------------------------------\\n *\\n * Authors: Martin Kronbichler, Peter Munch, David Schneider, 2020\\n */\\n \\n \\n#include <deal.II/base/conditional_ostream.h>\\n#include <deal.II/base/function.h>\\n#include <deal.II/base/time_stepping.h>\\n#include <deal.II/base/timer.h>\\n#include <deal.II/base/utilities.h>\\n#include <deal.II/base/vectorization.h>\\n \\n#include <deal.II/distributed/tria.h>\\n \\n#include <deal.II/dofs/dof_handler.h>\\n \\n#include <deal.II/fe/fe_dgq.h>\\n#include <deal.II/fe/fe_system.h>\\n \\n#include <deal.II/grid/grid_generator.h>\\n#include <deal.II/grid/tria.h>\\n#include <deal.II/grid/tria_accessor.h>\\n#include <deal.II/grid/tria_iterator.h>\\n \\n#include <deal.II/lac/affine_constraints.h>\\n#include <deal.II/lac/la_parallel_vector.h>\\n \\n#include <deal.II/matrix_free/fe_evaluation.h>\\n#include <deal.II/matrix_free/matrix_free.h>\\n#include <deal.II/matrix_free/operators.h>\\n \\n#include <deal.II/numerics/data_out.h>\\n \\n#include <fstream>\\n#include <iomanip>\\n#include <iostream>\\n \\n#include <deal.II/matrix_free/tools.h>\\n \\n \\n \\nnamespace Euler_DG\\n{\\n using namespace dealii;\\n \\n constexpr unsigned int testcase             = 1;\\n constexpr unsigned int dimension            = 2;\\n constexpr unsigned int n_global_refinements = 2;\\n constexpr unsigned int fe_degree            = 5;\\n constexpr unsigned int n_q_points_1d        = fe_degree + 2;\\n \\n constexpr unsigned int group_size = numbers::invalid_unsigned_int;\\n \\n using Number = double;\\n \\n using VectorizedArrayType = VectorizedArray<Number>;\\n \\n constexpr double gamma       = 1.4;\\n constexpr double final_time  = testcase == 0 ? 10 : 2.0;\\n constexpr double output_tick = testcase == 0 ? 1 : 0.05;\\n \\n const double courant_number = 0.15 / std::pow(fe_degree, 1.5);\\n \\n constexpr unsigned int max_time_steps = numbers::invalid_unsigned_int;\\n \\n enum LowStorageRungeKuttaScheme\\n  {\\n    stage_3_order_3,\\n    stage_5_order_4,\\n    stage_7_order_4,\\n    stage_9_order_5,\\n  };\\n constexpr LowStorageRungeKuttaScheme lsrk_scheme = stage_5_order_4;\\n \\n \\n \\n class LowStorageRungeKuttaIntegrator\\n  {\\n public:\\n    LowStorageRungeKuttaIntegrator(const LowStorageRungeKuttaScheme scheme)\\n    {\\n TimeStepping::runge_kutta_method lsrk;\\n switch (scheme)\\n        {\\n case stage_3_order_3:\\n            lsrk = TimeStepping::LOW_STORAGE_RK_STAGE3_ORDER3;\\n break;\\n case stage_5_order_4:\\n            lsrk = TimeStepping::LOW_STORAGE_RK_STAGE5_ORDER4;\\n break;\\n case stage_7_order_4:\\n            lsrk = TimeStepping::LOW_STORAGE_RK_STAGE7_ORDER4;\\n break;\\n case stage_9_order_5:\\n            lsrk = TimeStepping::LOW_STORAGE_RK_STAGE9_ORDER5;\\n break;\\n \\n default:\\n AssertThrow(false, ExcNotImplemented());\\n        }\\n TimeStepping::LowStorageRungeKutta<\\n LinearAlgebra::distributed::Vector<Number>>\\n                          rk_integrator(lsrk);\\n      std::vector<double> ci; // not used\\n      rk_integrator.get_coefficients(ai, bi, ci);\\n    }\\n \\n unsigned int n_stages() const\\n {\\n return bi.size();\\n    }\\n \\n template <typename VectorType, typename Operator>\\n void perform_time_step(const Operator &pde_operator,\\n const double    current_time,\\n const double    time_step,\\n                           VectorType     &solution,\\n                           VectorType     &vec_ri,\\n                           VectorType     &vec_ki) const\\n {\\n AssertDimension(ai.size() + 1, bi.size());\\n \\n      vec_ki.swap(solution);\\n \\n double sum_previous_bi = 0;\\n for (unsigned int stage = 0; stage < bi.size(); ++stage)\\n        {\\n const double c_i = stage == 0 ? 0 : sum_previous_bi + ai[stage - 1];\\n \\n          pde_operator.perform_stage(stage,\\n                                     current_time + c_i * time_step,\\n                                     bi[stage] * time_step,\\n                                     (stage == bi.size() - 1 ?\\n                                        0 :\\n                                        ai[stage] * time_step),\\n                                     (stage % 2 == 0 ? vec_ki : vec_ri),\\n                                     (stage % 2 == 0 ? vec_ri : vec_ki),\\n                                     solution);\\n \\n if (stage > 0)\\n            sum_previous_bi += bi[stage - 1];\\n        }\\n    }\\n \\n private:\\n    std::vector<double> bi;\\n    std::vector<double> ai;\\n  };\\n \\n \\n enum EulerNumericalFlux\\n  {\\n    lax_friedrichs_modified,\\n    harten_lax_vanleer,\\n  };\\n constexpr EulerNumericalFlux numerical_flux_type = lax_friedrichs_modified;\\n \\n \\n \\n template <int dim>\\n class ExactSolution : public Function<dim>\\n  {\\n public:\\n    ExactSolution(const double time)\\n      : Function<dim>(dim + 2, time)\\n    {}\\n \\n virtual double value(const Point<dim>  &p,\\n const unsigned int component = 0) const override;\\n  };\\n \\n \\n \\n template <int dim>\\n double ExactSolution<dim>::value(const Point<dim>  &x,\\n const unsigned int component) const\\n {\\n const double t = this->get_time();\\n \\n switch (testcase)\\n      {\\n case 0:\\n          {\\n Assert(dim == 2, ExcNotImplemented());\\n const double beta = 5;\\n \\n Point<dim> x0;\\n            x0[0] = 5.;\\n const double radius_sqr =\\n              (x - x0).norm_square() - 2. * (x[0] - x0[0]) * t + t * t;\\n const double factor =\\n              beta / (numbers::PI * 2) * std::exp(1. - radius_sqr);\\n const double density_log = std::log2(\\n std::abs(1. - (gamma - 1.) / gamma * 0.25 * factor * factor));\\n const double density = std::exp2(density_log * (1. / (gamma - 1.)));\\n const double u       = 1. - factor * (x[1] - x0[1]);\\n const double v       = factor * (x[0] - t - x0[0]);\\n \\n if (component == 0)\\n return density;\\n else if (component == 1)\\n return density * u;\\n else if (component == 2)\\n return density * v;\\n else\\n              {\\n const double pressure =\\n                  std::exp2(density_log * (gamma / (gamma - 1.)));\\n return pressure / (gamma - 1.) +\\n                       0.5 * (density * u * u + density * v * v);\\n              }\\n          }\\n \\n case 1:\\n          {\\n if (component == 0)\\n return 1.;\\n else if (component == 1)\\n return 0.4;\\n else if (component == dim + 1)\\n return 3.097857142857143;\\n else\\n return 0.;\\n          }\\n \\n default:\\n DEAL_II_NOT_IMPLEMENTED();\\n return 0.;\\n      }\\n  }\\n \\n \\n \\n template <int dim, typename Number>\\n inline DEAL_II_ALWAYS_INLINE \\n Tensor<1, dim, Number>\\n    euler_velocity(const Tensor<1, dim + 2, Number> &conserved_variables)\\n  {\\n const Number inverse_density = Number(1.) / conserved_variables[0];\\n \\n Tensor<1, dim, Number> velocity;\\n for (unsigned int d = 0; d < dim; ++d)\\n      velocity[d] = conserved_variables[1 + d] * inverse_density;\\n \\n return velocity;\\n  }\\n \\n template <int dim, typename Number>\\n inline DEAL_II_ALWAYS_INLINE \\n    Number\\n    euler_pressure(const Tensor<1, dim + 2, Number> &conserved_variables)\\n  {\\n const Tensor<1, dim, Number> velocity =\\n      euler_velocity<dim>(conserved_variables);\\n \\n    Number rho_u_dot_u = conserved_variables[1] * velocity[0];\\n for (unsigned int d = 1; d < dim; ++d)\\n      rho_u_dot_u += conserved_variables[1 + d] * velocity[d];\\n \\n return (gamma - 1.) * (conserved_variables[dim + 1] - 0.5 * rho_u_dot_u);\\n  }\\n \\n template <int dim, typename Number>\\n inline DEAL_II_ALWAYS_INLINE \\n Tensor<1, dim + 2, Tensor<1, dim, Number>>\\n    euler_flux(const Tensor<1, dim + 2, Number> &conserved_variables)\\n  {\\n const Tensor<1, dim, Number> velocity =\\n      euler_velocity<dim>(conserved_variables);\\n const Number pressure = euler_pressure<dim>(conserved_variables);\\n \\n Tensor<1, dim + 2, Tensor<1, dim, Number>> flux;\\n for (unsigned int d = 0; d < dim; ++d)\\n      {\\n        flux[0][d] = conserved_variables[1 + d];\\n for (unsigned int e = 0; e < dim; ++e)\\n          flux[e + 1][d] = conserved_variables[e + 1] * velocity[d];\\n        flux[d + 1][d] += pressure;\\n        flux[dim + 1][d] =\\n          velocity[d] * (conserved_variables[dim + 1] + pressure);\\n      }\\n \\n return flux;\\n  }\\n \\n template <int n_components, int dim, typename Number>\\n inline DEAL_II_ALWAYS_INLINE \\n Tensor<1, n_components, Number>\\n operator*(const Tensor<1, n_components, Tensor<1, dim, Number>> &matrix,\\n const Tensor<1, dim, Number>                          &vector)\\n  {\\n Tensor<1, n_components, Number> result;\\n for (unsigned int d = 0; d < n_components; ++d)\\n      result[d] = matrix[d] * vector;\\n return result;\\n  }\\n \\n template <int dim, typename Number>\\n inline DEAL_II_ALWAYS_INLINE \\n Tensor<1, dim + 2, Number>\\n    euler_numerical_flux(const Tensor<1, dim + 2, Number> &u_m,\\n const Tensor<1, dim + 2, Number> &u_p,\\n const Tensor<1, dim, Number>     &normal)\\n  {\\n const auto velocity_m = euler_velocity<dim>(u_m);\\n const auto velocity_p = euler_velocity<dim>(u_p);\\n \\n const auto pressure_m = euler_pressure<dim>(u_m);\\n const auto pressure_p = euler_pressure<dim>(u_p);\\n \\n const auto flux_m = euler_flux<dim>(u_m);\\n const auto flux_p = euler_flux<dim>(u_p);\\n \\n switch (numerical_flux_type)\\n      {\\n case lax_friedrichs_modified:\\n          {\\n const auto lambda =\\n              0.5 * std::sqrt(std::max(velocity_p.norm_square() +\\n                                         gamma * pressure_p * (1. / u_p[0]),\\n                                       velocity_m.norm_square() +\\n                                         gamma * pressure_m * (1. / u_m[0])));\\n \\n return 0.5 * (flux_m * normal + flux_p * normal) +\\n                   0.5 * lambda * (u_m - u_p);\\n          }\\n \\n case harten_lax_vanleer:\\n          {\\n const auto avg_velocity_normal =\\n              0.5 * ((velocity_m + velocity_p) * normal);\\n const auto   avg_c = std::sqrt(std::abs(\\n              0.5 * gamma *\\n              (pressure_p * (1. / u_p[0]) + pressure_m * (1. / u_m[0]))));\\n const Number s_pos =\\n std::max(Number(), avg_velocity_normal + avg_c);\\n const Number s_neg =\\n std::min(Number(), avg_velocity_normal - avg_c);\\n const Number inverse_s = Number(1.) / (s_pos - s_neg);\\n \\n return inverse_s *\\n                   ((s_pos * (flux_m * normal) - s_neg * (flux_p * normal)) -\\n                    s_pos * s_neg * (u_m - u_p));\\n          }\\n \\n default:\\n          {\\n DEAL_II_NOT_IMPLEMENTED();\\n return {};\\n          }\\n      }\\n  }\\n \\n \\n \\n template <int dim, typename VectorizedArrayType>\\n  VectorizedArrayType\\n  evaluate_function(const Function<dim>                   &function,\\n const Point<dim, VectorizedArrayType> &p_vectorized,\\n const unsigned int                     component)\\n  {\\n    VectorizedArrayType result;\\n for (unsigned int v = 0; v < VectorizedArrayType::size(); ++v)\\n      {\\n Point<dim> p;\\n for (unsigned int d = 0; d < dim; ++d)\\n          p[d] = p_vectorized[d][v];\\n        result[v] = function.value(p, component);\\n      }\\n return result;\\n  }\\n \\n \\n template <int dim, typename VectorizedArrayType, int n_components = dim + 2>\\n Tensor<1, n_components, VectorizedArrayType>\\n  evaluate_function(const Function<dim>                   &function,\\n const Point<dim, VectorizedArrayType> &p_vectorized)\\n  {\\n AssertDimension(function.n_components, n_components);\\n Tensor<1, n_components, VectorizedArrayType> result;\\n for (unsigned int v = 0; v < VectorizedArrayType::size(); ++v)\\n      {\\n Point<dim> p;\\n for (unsigned int d = 0; d < dim; ++d)\\n          p[d] = p_vectorized[d][v];\\n for (unsigned int d = 0; d < n_components; ++d)\\n          result[d][v] = function.value(p, d);\\n      }\\n return result;\\n  }\\n \\n \\n \\n template <int dim, int degree, int n_points_1d>\\n class EulerOperator\\n  {\\n public:\\n static constexpr unsigned int n_quadrature_points_1d = n_points_1d;\\n \\n    EulerOperator(TimerOutput &timer_output);\\n \\n    ~EulerOperator();\\n \\n void reinit(const Mapping<dim>    &mapping,\\n const DoFHandler<dim> &dof_handler);\\n \\n void set_inflow_boundary(const types::boundary_id       boundary_id,\\n                             std::unique_ptr<Function<dim>> inflow_function);\\n \\n void set_subsonic_outflow_boundary(\\n const types::boundary_id       boundary_id,\\n      std::unique_ptr<Function<dim>> outflow_energy);\\n \\n void set_wall_boundary(const types::boundary_id boundary_id);\\n \\n void set_body_force(std::unique_ptr<Function<dim>> body_force);\\n \\n void\\n    perform_stage(const unsigned int                                stage,\\n const Number                                      cur_time,\\n const Number                                      bi,\\n const Number                                      ai,\\n const LinearAlgebra::distributed::Vector<Number> &current_ri,\\n LinearAlgebra::distributed::Vector<Number>       &vec_ki,\\n LinearAlgebra::distributed::Vector<Number> &solution) const;\\n \\n void project(const Function<dim>                        &function,\\n LinearAlgebra::distributed::Vector<Number> &solution) const;\\n \\n    std::array<double, 3> compute_errors(\\n const Function<dim>                              &function,\\n const LinearAlgebra::distributed::Vector<Number> &solution) const;\\n \\n double compute_cell_transport_speed(\\n const LinearAlgebra::distributed::Vector<Number> &solution) const;\\n \\n void\\n    initialize_vector(LinearAlgebra::distributed::Vector<Number> &vector) const;\\n \\n private:\\n MPI_Comm subcommunicator;\\n \\n MatrixFree<dim, Number, VectorizedArrayType> data;\\n \\n TimerOutput &timer;\\n \\n    std::map<types::boundary_id, std::unique_ptr<Function<dim>>>\\n      inflow_boundaries;\\n    std::map<types::boundary_id, std::unique_ptr<Function<dim>>>\\n                                   subsonic_outflow_boundaries;\\n    std::set<types::boundary_id>   wall_boundaries;\\n    std::unique_ptr<Function<dim>> body_force;\\n  };\\n \\n \\n \\n template <int dim, int degree, int n_points_1d>\\n  EulerOperator<dim, degree, n_points_1d>::EulerOperator(TimerOutput &timer)\\n    : timer(timer)\\n  {\\n#ifdef DEAL_II_WITH_MPI\\n if (group_size == 1)\\n      {\\n        this->subcommunicator = MPI_COMM_SELF;\\n      }\\n else if (group_size == numbers::invalid_unsigned_int)\\n      {\\n const auto rank = Utilities::MPI::this_mpi_process(MPI_COMM_WORLD);\\n \\n        MPI_Comm_split_type(MPI_COMM_WORLD,\\n                            MPI_COMM_TYPE_SHARED,\\n                            rank,\\n                            MPI_INFO_NULL,\\n                            &subcommunicator);\\n      }\\n else\\n      {\\n DEAL_II_NOT_IMPLEMENTED();\\n      }\\n#else\\n    (void)subcommunicator;\\n    (void)group_size;\\n    this->subcommunicator = MPI_COMM_SELF;\\n#endif\\n  }\\n \\n \\n template <int dim, int degree, int n_points_1d>\\n  EulerOperator<dim, degree, n_points_1d>::~EulerOperator()\\n  {\\n#ifdef DEAL_II_WITH_MPI\\n if (this->subcommunicator != MPI_COMM_SELF)\\n      MPI_Comm_free(&subcommunicator);\\n#endif\\n  }\\n \\n \\n template <int dim, int degree, int n_points_1d>\\n void EulerOperator<dim, degree, n_points_1d>::reinit(\\n const Mapping<dim>    &mapping,\\n const DoFHandler<dim> &dof_handler)\\n  {\\n const std::vector<const DoFHandler<dim> *> dof_handlers = {&dof_handler};\\n const AffineConstraints<double>            dummy;\\n const std::vector<const AffineConstraints<double> *> constraints = {&dummy};\\n const std::vector<Quadrature<1>> quadratures = {QGauss<1>(n_q_points_1d),\\n QGauss<1>(fe_degree + 1)};\\n \\n typename MatrixFree<dim, Number, VectorizedArrayType>::AdditionalData\\n      additional_data;\\n    additional_data.mapping_update_flags =\\n      (update_gradients | update_JxW_values | update_quadrature_points |\\n update_values);\\n    additional_data.mapping_update_flags_inner_faces =\\n      (update_JxW_values | update_quadrature_points | update_normal_vectors |\\n update_values);\\n    additional_data.mapping_update_flags_boundary_faces =\\n      (update_JxW_values | update_quadrature_points | update_normal_vectors |\\n update_values);\\n    additional_data.tasks_parallel_scheme =\\n MatrixFree<dim, Number, VectorizedArrayType>::AdditionalData::none;\\n \\n MatrixFreeTools::categorize_by_boundary_ids(dof_handler.get_triangulation(),\\n                                                additional_data);\\n \\n    additional_data.communicator_sm = subcommunicator;\\n \\n    data.reinit(\\n      mapping, dof_handlers, constraints, quadratures, additional_data);\\n  }\\n \\n \\n template <int dim, int degree, int n_points_1d>\\n void EulerOperator<dim, degree, n_points_1d>::perform_stage(\\n const unsigned int                                stage,\\n const Number                                      current_time,\\n const Number                                      bi,\\n const Number                                      ai,\\n const LinearAlgebra::distributed::Vector<Number> &current_ri,\\n LinearAlgebra::distributed::Vector<Number>       &vec_ki,\\n LinearAlgebra::distributed::Vector<Number>       &solution) const\\n {\\n for (auto &i : inflow_boundaries)\\n      i.second->set_time(current_time);\\n for (auto &i : subsonic_outflow_boundaries)\\n      i.second->set_time(current_time);\\n \\n    data.template loop_cell_centric<LinearAlgebra::distributed::Vector<Number>,\\n LinearAlgebra::distributed::Vector<Number>>(\\n      [&](const auto &data, auto &dst, const auto &src, const auto cell_range) {\\n using FECellIntegral = FEEvaluation<dim,\\n                                            degree,\\n                                            n_points_1d,\\n                                            dim + 2,\\n                                            Number,\\n                                            VectorizedArrayType>;\\n using FEFaceIntegral = FEFaceEvaluation<dim,\\n                                                degree,\\n                                                n_points_1d,\\n                                                dim + 2,\\n                                                Number,\\n                                                VectorizedArrayType>;\\n \\n        FECellIntegral phi(data);\\n        FECellIntegral phi_temp(data);\\n        FEFaceIntegral phi_m(data, true);\\n        FEFaceIntegral phi_p(data, false);\\n \\n Tensor<1, dim, VectorizedArrayType>     constant_body_force;\\n const Functions::ConstantFunction<dim> *constant_function =\\n dynamic_cast<Functions::ConstantFunction<dim> *>(body_force.get());\\n \\n if (constant_function)\\n          constant_body_force =\\n            evaluate_function<dim, VectorizedArrayType, dim>(\\n              *constant_function, Point<dim, VectorizedArrayType>());\\n \\n const internal::EvaluatorTensorProduct<\\n internal::EvaluatorVariant::evaluate_evenodd,\\n          dim,\\n          n_points_1d,\\n          n_points_1d,\\n          VectorizedArrayType,\\n          Number>\\n          eval({},\\n               data.get_shape_info().data[0].shape_gradients_collocation_eo,\\n               {});\\n \\n AlignedVector<VectorizedArrayType> buffer(phi.static_n_q_points *\\n                                                  phi.n_components);\\n \\n for (unsigned int cell = cell_range.first; cell < cell_range.second;\\n             ++cell)\\n          {\\n            phi.reinit(cell);\\n \\n if (ai != Number())\\n              phi_temp.reinit(cell);\\n \\n if (ai != Number() && stage == 0)\\n              {\\n                phi.read_dof_values(src);\\n \\n for (unsigned int i = 0;\\n                     i < phi.static_dofs_per_component * (dim + 2);\\n                     ++i)\\n                  phi_temp.begin_dof_values()[i] = phi.begin_dof_values()[i];\\n \\n                phi.evaluate(EvaluationFlags::values);\\n              }\\n else\\n              {\\n                phi.gather_evaluate(src, EvaluationFlags::values);\\n              }\\n \\n for (unsigned int i = 0; i < phi.static_n_q_points * (dim + 2); ++i)\\n              buffer[i] = phi.begin_values()[i];\\n \\n for (const unsigned int q : phi.quadrature_point_indices())\\n              {\\n const auto w_q = phi.get_value(q);\\n                phi.submit_gradient(euler_flux<dim>(w_q), q);\\n if (body_force.get() != nullptr)\\n                  {\\n const Tensor<1, dim, VectorizedArrayType> force =\\n                      constant_function ?\\n                        constant_body_force :\\n                        evaluate_function<dim, VectorizedArrayType, dim>(\\n                          *body_force, phi.quadrature_point(q));\\n \\n Tensor<1, dim + 2, VectorizedArrayType> forcing;\\n for (unsigned int d = 0; d < dim; ++d)\\n                      forcing[d + 1] = w_q[0] * force[d];\\n for (unsigned int d = 0; d < dim; ++d)\\n                      forcing[dim + 1] += force[d] * w_q[d + 1];\\n \\n                    phi.submit_value(forcing, q);\\n                  }\\n              }\\n \\n            {\\n auto *values_ptr   = phi.begin_values();\\n auto *gradient_ptr = phi.begin_gradients();\\n \\n for (unsigned int c = 0; c < dim + 2; ++c)\\n                {\\n if (dim >= 1 && body_force.get() == nullptr)\\n                    eval.template gradients<0, false, false, dim>(gradient_ptr,\\n                                                                  values_ptr);\\n else if (dim >= 1)\\n                    eval.template gradients<0, false, true, dim>(gradient_ptr,\\n                                                                 values_ptr);\\n if (dim >= 2)\\n                    eval.template gradients<1, false, true, dim>(gradient_ptr +\\n                                                                   1,\\n                                                                 values_ptr);\\n if (dim >= 3)\\n                    eval.template gradients<2, false, true, dim>(gradient_ptr +\\n                                                                   2,\\n                                                                 values_ptr);\\n \\n                  values_ptr += phi.static_n_q_points;\\n                  gradient_ptr += phi.static_n_q_points * dim;\\n                }\\n            }\\n \\n for (unsigned int face = 0;\\n                 face < GeometryInfo<dim>::faces_per_cell;\\n                 ++face)\\n              {\\n const auto boundary_ids =\\n                  data.get_faces_by_cells_boundary_id(cell, face);\\n \\n Assert(std::equal(boundary_ids.begin(),\\n                                  boundary_ids.begin() +\\n                                    data.n_active_entries_per_cell_batch(cell),\\n                                  boundary_ids.begin()),\\n                       ExcMessage(\\\"Boundary IDs of lanes differ.\\\"));\\n \\n const auto boundary_id = boundary_ids[0];\\n \\n                phi_m.reinit(cell, face);\\n \\n internal::FEFaceNormalEvaluationImpl<dim,\\n                                                     n_points_1d - 1,\\n                                                     VectorizedArrayType>::\\n                  template interpolate_quadrature<true, false>(\\n                    dim + 2,\\n EvaluationFlags::values,\\n                    data.get_shape_info(),\\n                    buffer.data(),\\n                    phi_m.begin_values(),\\n                    face);\\n \\n if (boundary_id == numbers::internal_face_boundary_id)\\n                  {\\n                    phi_p.reinit(cell, face);\\n                    phi_p.gather_evaluate(src, EvaluationFlags::values);\\n \\n for (const unsigned int q :\\n                         phi_m.quadrature_point_indices())\\n                      {\\n const auto numerical_flux =\\n                          euler_numerical_flux<dim>(phi_m.get_value(q),\\n                                                    phi_p.get_value(q),\\n                                                    phi_m.normal_vector(q));\\n                        phi_m.submit_value(-numerical_flux, q);\\n                      }\\n                  }\\n else\\n                  {\\n for (const unsigned int q :\\n                         phi_m.quadrature_point_indices())\\n                      {\\n const auto w_m    = phi_m.get_value(q);\\n const auto normal = phi_m.normal_vector(q);\\n \\n auto rho_u_dot_n = w_m[1] * normal[0];\\n for (unsigned int d = 1; d < dim; ++d)\\n                          rho_u_dot_n += w_m[1 + d] * normal[d];\\n \\n bool at_outflow = false;\\n \\n Tensor<1, dim + 2, VectorizedArrayType> w_p;\\n \\n if (wall_boundaries.find(boundary_id) !=\\n                            wall_boundaries.end())\\n                          {\\n                            w_p[0] = w_m[0];\\n for (unsigned int d = 0; d < dim; ++d)\\n                              w_p[d + 1] =\\n                                w_m[d + 1] - 2. * rho_u_dot_n * normal[d];\\n                            w_p[dim + 1] = w_m[dim + 1];\\n                          }\\n else if (inflow_boundaries.find(boundary_id) !=\\n                                 inflow_boundaries.end())\\n                          w_p = evaluate_function(\\n                            *inflow_boundaries.find(boundary_id)->second,\\n                            phi_m.quadrature_point(q));\\n else if (subsonic_outflow_boundaries.find(\\n                                   boundary_id) !=\\n                                 subsonic_outflow_boundaries.end())\\n                          {\\n                            w_p = w_m;\\n                            w_p[dim + 1] =\\n                              evaluate_function(*subsonic_outflow_boundaries\\n                                                   .find(boundary_id)\\n                                                   ->second,\\n                                                phi_m.quadrature_point(q),\\n                                                dim + 1);\\n                            at_outflow = true;\\n                          }\\n else\\n AssertThrow(false,\\n                                      ExcMessage(\\n \\\"Unknown boundary id, did \\\"\\n \\\"you set a boundary condition for \\\"\\n \\\"this part of the domain boundary?\\\"));\\n \\n auto flux = euler_numerical_flux<dim>(w_m, w_p, normal);\\n \\n if (at_outflow)\\n for (unsigned int v = 0;\\n                               v < VectorizedArrayType::size();\\n                               ++v)\\n                            {\\n if (rho_u_dot_n[v] < -1e-12)\\n for (unsigned int d = 0; d < dim; ++d)\\n                                  flux[d + 1][v] = 0.;\\n                            }\\n \\n                        phi_m.submit_value(-flux, q);\\n                      }\\n                  }\\n \\n internal::FEFaceNormalEvaluationImpl<dim,\\n                                                     n_points_1d - 1,\\n                                                     VectorizedArrayType>::\\n                  template interpolate_quadrature<false, true>(\\n                    dim + 2,\\n EvaluationFlags::values,\\n                    data.get_shape_info(),\\n                    phi_m.begin_values(),\\n                    phi.begin_values(),\\n                    face);\\n              }\\n \\n for (unsigned int q = 0; q < phi.static_n_q_points; ++q)\\n              {\\n const auto factor = VectorizedArrayType(1.0) / phi.JxW(q);\\n for (unsigned int c = 0; c < dim + 2; ++c)\\n                  phi.begin_values()[c * phi.static_n_q_points + q] =\\n                    phi.begin_values()[c * phi.static_n_q_points + q] * factor;\\n              }\\n \\n internal::FEEvaluationImplBasisChange<\\n internal::EvaluatorVariant::evaluate_evenodd,\\n internal::EvaluatorQuantity::hessian,\\n              dim,\\n              degree + 1,\\n              n_points_1d>::do_backward(dim + 2,\\n                                        data.get_shape_info()\\n                                          .data[0]\\n                                          .inverse_shape_values_eo,\\n false,\\n                                        phi.begin_values(),\\n                                        phi.begin_dof_values());\\n \\n if (ai == Number())\\n              {\\n for (unsigned int q = 0; q < phi.static_dofs_per_cell; ++q)\\n                  phi.begin_dof_values()[q] = bi * phi.begin_dof_values()[q];\\n                phi.distribute_local_to_global(solution);\\n              }\\n else\\n              {\\n if (stage != 0)\\n                  phi_temp.read_dof_values(solution);\\n \\n for (unsigned int q = 0; q < phi.static_dofs_per_cell; ++q)\\n                  {\\n const auto K_i = phi.begin_dof_values()[q];\\n \\n                    phi.begin_dof_values()[q] =\\n                      phi_temp.begin_dof_values()[q] + (ai * K_i);\\n \\n                    phi_temp.begin_dof_values()[q] += bi * K_i;\\n                  }\\n                phi.set_dof_values(dst);\\n                phi_temp.set_dof_values(solution);\\n              }\\n          }\\n      },\\n      vec_ki,\\n      current_ri,\\n true,\\n MatrixFree<dim, Number, VectorizedArrayType>::DataAccessOnFaces::values);\\n  }\\n \\n \\n \\n template <int dim, int degree, int n_points_1d>\\n void EulerOperator<dim, degree, n_points_1d>::initialize_vector(\\n LinearAlgebra::distributed::Vector<Number> &vector) const\\n {\\n    data.initialize_dof_vector(vector);\\n  }\\n \\n \\n \\n template <int dim, int degree, int n_points_1d>\\n void EulerOperator<dim, degree, n_points_1d>::set_inflow_boundary(\\n const types::boundary_id       boundary_id,\\n    std::unique_ptr<Function<dim>> inflow_function)\\n  {\\n AssertThrow(subsonic_outflow_boundaries.find(boundary_id) ==\\n                    subsonic_outflow_boundaries.end() &&\\n                  wall_boundaries.find(boundary_id) == wall_boundaries.end(),\\n                ExcMessage(\\\"You already set the boundary with id \\\" +\\n                           std::to_string(static_cast<int>(boundary_id)) +\\n \\\" to another type of boundary before now setting \\\" +\\n \\\"it as inflow\\\"));\\n AssertThrow(inflow_function->n_components == dim + 2,\\n                ExcMessage(\\\"Expected function with dim+2 components\\\"));\\n \\n    inflow_boundaries[boundary_id] = std::move(inflow_function);\\n  }\\n \\n \\n \\n template <int dim, int degree, int n_points_1d>\\n void EulerOperator<dim, degree, n_points_1d>::set_subsonic_outflow_boundary(\\n const types::boundary_id       boundary_id,\\n    std::unique_ptr<Function<dim>> outflow_function)\\n  {\\n AssertThrow(inflow_boundaries.find(boundary_id) ==\\n                    inflow_boundaries.end() &&\\n                  wall_boundaries.find(boundary_id) == wall_boundaries.end(),\\n                ExcMessage(\\\"You already set the boundary with id \\\" +\\n                           std::to_string(static_cast<int>(boundary_id)) +\\n \\\" to another type of boundary before now setting \\\" +\\n \\\"it as subsonic outflow\\\"));\\n AssertThrow(outflow_function->n_components == dim + 2,\\n                ExcMessage(\\\"Expected function with dim+2 components\\\"));\\n \\n    subsonic_outflow_boundaries[boundary_id] = std::move(outflow_function);\\n  }\\n \\n \\n \\n template <int dim, int degree, int n_points_1d>\\n void EulerOperator<dim, degree, n_points_1d>::set_wall_boundary(\\n const types::boundary_id boundary_id)\\n  {\\n AssertThrow(inflow_boundaries.find(boundary_id) ==\\n                    inflow_boundaries.end() &&\\n                  subsonic_outflow_boundaries.find(boundary_id) ==\\n                    subsonic_outflow_boundaries.end(),\\n                ExcMessage(\\\"You already set the boundary with id \\\" +\\n                           std::to_string(static_cast<int>(boundary_id)) +\\n \\\" to another type of boundary before now setting \\\" +\\n \\\"it as wall boundary\\\"));\\n \\n    wall_boundaries.insert(boundary_id);\\n  }\\n \\n \\n \\n template <int dim, int degree, int n_points_1d>\\n void EulerOperator<dim, degree, n_points_1d>::set_body_force(\\n    std::unique_ptr<Function<dim>> body_force)\\n  {\\n AssertDimension(body_force->n_components, dim);\\n \\n    this->body_force = std::move(body_force);\\n  }\\n \\n \\n \\n template <int dim, int degree, int n_points_1d>\\n void EulerOperator<dim, degree, n_points_1d>::project(\\n const Function<dim>                        &function,\\n LinearAlgebra::distributed::Vector<Number> &solution) const\\n {\\n FEEvaluation<dim, degree, degree + 1, dim + 2, Number, VectorizedArrayType>\\n      phi(data, 0, 1);\\n MatrixFreeOperators::CellwiseInverseMassMatrix<dim,\\n                                                   degree,\\n                                                   dim + 2,\\n                                                   Number,\\n                                                   VectorizedArrayType>\\n      inverse(phi);\\n    solution.zero_out_ghost_values();\\n for (unsigned int cell = 0; cell < data.n_cell_batches(); ++cell)\\n      {\\n        phi.reinit(cell);\\n for (const unsigned int q : phi.quadrature_point_indices())\\n          phi.submit_dof_value(evaluate_function(function,\\n                                                 phi.quadrature_point(q)),\\n                               q);\\n        inverse.transform_from_q_points_to_basis(dim + 2,\\n                                                 phi.begin_dof_values(),\\n                                                 phi.begin_dof_values());\\n        phi.set_dof_values(solution);\\n      }\\n  }\\n \\n \\n \\n template <int dim, int degree, int n_points_1d>\\n  std::array<double, 3> EulerOperator<dim, degree, n_points_1d>::compute_errors(\\n const Function<dim>                              &function,\\n const LinearAlgebra::distributed::Vector<Number> &solution) const\\n {\\n TimerOutput::Scope t(timer, \\\"compute errors\\\");\\n double             errors_squared[3] = {};\\n FEEvaluation<dim, degree, n_points_1d, dim + 2, Number, VectorizedArrayType>\\n      phi(data, 0, 0);\\n \\n for (unsigned int cell = 0; cell < data.n_cell_batches(); ++cell)\\n      {\\n        phi.reinit(cell);\\n        phi.gather_evaluate(solution, EvaluationFlags::values);\\n        VectorizedArrayType local_errors_squared[3] = {};\\n for (const unsigned int q : phi.quadrature_point_indices())\\n          {\\n const auto error =\\n              evaluate_function(function, phi.quadrature_point(q)) -\\n              phi.get_value(q);\\n const auto JxW = phi.JxW(q);\\n \\n            local_errors_squared[0] += error[0] * error[0] * JxW;\\n for (unsigned int d = 0; d < dim; ++d)\\n              local_errors_squared[1] += (error[d + 1] * error[d + 1]) * JxW;\\n            local_errors_squared[2] += (error[dim + 1] * error[dim + 1]) * JxW;\\n          }\\n for (unsigned int v = 0; v < data.n_active_entries_per_cell_batch(cell);\\n             ++v)\\n for (unsigned int d = 0; d < 3; ++d)\\n            errors_squared[d] += local_errors_squared[d][v];\\n      }\\n \\n Utilities::MPI::sum(errors_squared, MPI_COMM_WORLD, errors_squared);\\n \\n    std::array<double, 3> errors;\\n for (unsigned int d = 0; d < 3; ++d)\\n      errors[d] = std::sqrt(errors_squared[d]);\\n \\n return errors;\\n  }\\n \\n \\n \\n template <int dim, int degree, int n_points_1d>\\n double EulerOperator<dim, degree, n_points_1d>::compute_cell_transport_speed(\\n const LinearAlgebra::distributed::Vector<Number> &solution) const\\n {\\n TimerOutput::Scope t(timer, \\\"compute transport speed\\\");\\n    Number             max_transport = 0;\\n FEEvaluation<dim, degree, degree + 1, dim + 2, Number, VectorizedArrayType>\\n      phi(data, 0, 1);\\n \\n for (unsigned int cell = 0; cell < data.n_cell_batches(); ++cell)\\n      {\\n        phi.reinit(cell);\\n        phi.gather_evaluate(solution, EvaluationFlags::values);\\n        VectorizedArrayType local_max = 0.;\\n for (const unsigned int q : phi.quadrature_point_indices())\\n          {\\n const auto solution = phi.get_value(q);\\n const auto velocity = euler_velocity<dim>(solution);\\n const auto pressure = euler_pressure<dim>(solution);\\n \\n const auto          inverse_jacobian = phi.inverse_jacobian(q);\\n const auto          convective_speed = inverse_jacobian * velocity;\\n            VectorizedArrayType convective_limit = 0.;\\n for (unsigned int d = 0; d < dim; ++d)\\n              convective_limit =\\n std::max(convective_limit, std::abs(convective_speed[d]));\\n \\n const auto speed_of_sound =\\n std::sqrt(gamma * pressure * (1. / solution[0]));\\n \\n Tensor<1, dim, VectorizedArrayType> eigenvector;\\n for (unsigned int d = 0; d < dim; ++d)\\n              eigenvector[d] = 1.;\\n for (unsigned int i = 0; i < 5; ++i)\\n              {\\n                eigenvector = transpose(inverse_jacobian) *\\n                              (inverse_jacobian * eigenvector);\\n                VectorizedArrayType eigenvector_norm = 0.;\\n for (unsigned int d = 0; d < dim; ++d)\\n                  eigenvector_norm =\\n std::max(eigenvector_norm, std::abs(eigenvector[d]));\\n                eigenvector /= eigenvector_norm;\\n              }\\n const auto jac_times_ev   = inverse_jacobian * eigenvector;\\n const auto max_eigenvalue = std::sqrt(\\n              (jac_times_ev * jac_times_ev) / (eigenvector * eigenvector));\\n            local_max =\\n std::max(local_max,\\n                       max_eigenvalue * speed_of_sound + convective_limit);\\n          }\\n \\n for (unsigned int v = 0; v < data.n_active_entries_per_cell_batch(cell);\\n             ++v)\\n          max_transport = std::max(max_transport, local_max[v]);\\n      }\\n \\n    max_transport = Utilities::MPI::max(max_transport, MPI_COMM_WORLD);\\n \\n return max_transport;\\n  }\\n \\n \\n \\n template <int dim>\\n class EulerProblem\\n  {\\n public:\\n    EulerProblem();\\n \\n void run();\\n \\n private:\\n void make_grid_and_dofs();\\n \\n void output_results(const unsigned int result_number);\\n \\n LinearAlgebra::distributed::Vector<Number> solution;\\n \\n ConditionalOStream pcout;\\n \\n#ifdef DEAL_II_WITH_P4EST\\n parallel::distributed::Triangulation<dim> triangulation;\\n#else\\n Triangulation<dim> triangulation;\\n#endif\\n \\n const FESystem<dim> fe;\\n MappingQ<dim>       mapping;\\n DoFHandler<dim>     dof_handler;\\n \\n TimerOutput timer;\\n \\n    EulerOperator<dim, fe_degree, n_q_points_1d> euler_operator;\\n \\n double time, time_step;\\n \\n class Postprocessor : public DataPostprocessor<dim>\\n    {\\n public:\\n      Postprocessor();\\n \\n virtual void evaluate_vector_field(\\n const DataPostprocessorInputs::Vector<dim> &inputs,\\n        std::vector<Vector<double>> &computed_quantities) const override;\\n \\n virtual std::vector<std::string> get_names() const override;\\n \\n virtual std::vector<\\n DataComponentInterpretation::DataComponentInterpretation>\\n      get_data_component_interpretation() const override;\\n \\n virtual UpdateFlags get_needed_update_flags() const override;\\n \\n private:\\n const bool do_schlieren_plot;\\n    };\\n  };\\n \\n \\n \\n template <int dim>\\n  EulerProblem<dim>::Postprocessor::Postprocessor()\\n    : do_schlieren_plot(dim == 2)\\n  {}\\n \\n \\n \\n template <int dim>\\n void EulerProblem<dim>::Postprocessor::evaluate_vector_field(\\n const DataPostprocessorInputs::Vector<dim> &inputs,\\n    std::vector<Vector<double>>                &computed_quantities) const\\n {\\n const unsigned int n_evaluation_points = inputs.solution_values.size();\\n \\n if (do_schlieren_plot == true)\\n Assert(inputs.solution_gradients.size() == n_evaluation_points,\\n             ExcInternalError());\\n \\n Assert(computed_quantities.size() == n_evaluation_points,\\n           ExcInternalError());\\n Assert(inputs.solution_values[0].size() == dim + 2, ExcInternalError());\\n Assert(computed_quantities[0].size() ==\\n             dim + 2 + (do_schlieren_plot == true ? 1 : 0),\\n           ExcInternalError());\\n \\n for (unsigned int p = 0; p < n_evaluation_points; ++p)\\n      {\\n Tensor<1, dim + 2> solution;\\n for (unsigned int d = 0; d < dim + 2; ++d)\\n          solution[d] = inputs.solution_values[p](d);\\n \\n const double         density  = solution[0];\\n const Tensor<1, dim> velocity = euler_velocity<dim>(solution);\\n const double         pressure = euler_pressure<dim>(solution);\\n \\n for (unsigned int d = 0; d < dim; ++d)\\n          computed_quantities[p](d) = velocity[d];\\n        computed_quantities[p](dim)     = pressure;\\n        computed_quantities[p](dim + 1) = std::sqrt(gamma * pressure / density);\\n \\n if (do_schlieren_plot == true)\\n          computed_quantities[p](dim + 2) =\\n            inputs.solution_gradients[p][0] * inputs.solution_gradients[p][0];\\n      }\\n  }\\n \\n \\n \\n template <int dim>\\n  std::vector<std::string> EulerProblem<dim>::Postprocessor::get_names() const\\n {\\n    std::vector<std::string> names;\\n for (unsigned int d = 0; d < dim; ++d)\\n      names.emplace_back(\\\"velocity\\\");\\n    names.emplace_back(\\\"pressure\\\");\\n    names.emplace_back(\\\"speed_of_sound\\\");\\n \\n if (do_schlieren_plot == true)\\n      names.emplace_back(\\\"schlieren_plot\\\");\\n \\n return names;\\n  }\\n \\n \\n \\n template <int dim>\\n  std::vector<DataComponentInterpretation::DataComponentInterpretation>\\n  EulerProblem<dim>::Postprocessor::get_data_component_interpretation() const\\n {\\n    std::vector<DataComponentInterpretation::DataComponentInterpretation>\\n      interpretation;\\n for (unsigned int d = 0; d < dim; ++d)\\n      interpretation.push_back(\\n DataComponentInterpretation::component_is_part_of_vector);\\n    interpretation.push_back(DataComponentInterpretation::component_is_scalar);\\n    interpretation.push_back(DataComponentInterpretation::component_is_scalar);\\n \\n if (do_schlieren_plot == true)\\n      interpretation.push_back(\\n DataComponentInterpretation::component_is_scalar);\\n \\n return interpretation;\\n  }\\n \\n \\n \\n template <int dim>\\n UpdateFlags EulerProblem<dim>::Postprocessor::get_needed_update_flags() const\\n {\\n if (do_schlieren_plot == true)\\n return update_values | update_gradients;\\n else\\n return update_values;\\n  }\\n \\n \\n \\n template <int dim>\\n  EulerProblem<dim>::EulerProblem()\\n    : pcout(std::cout, Utilities::MPI::this_mpi_process(MPI_COMM_WORLD) == 0)\\n#ifdef DEAL_II_WITH_P4EST\\n    , triangulation(MPI_COMM_WORLD)\\n#endif\\n    , fe(FE_DGQ<dim>(fe_degree), dim + 2)\\n    , mapping(fe_degree)\\n    , dof_handler(triangulation)\\n    , timer(pcout, TimerOutput::never, TimerOutput::wall_times)\\n    , euler_operator(timer)\\n    , time(0)\\n    , time_step(0)\\n  {}\\n \\n \\n \\n template <int dim>\\n void EulerProblem<dim>::make_grid_and_dofs()\\n  {\\n switch (testcase)\\n      {\\n case 0:\\n          {\\n Point<dim> lower_left;\\n for (unsigned int d = 1; d < dim; ++d)\\n              lower_left[d] = -5;\\n \\n Point<dim> upper_right;\\n            upper_right[0] = 10;\\n for (unsigned int d = 1; d < dim; ++d)\\n              upper_right[d] = 5;\\n \\n GridGenerator::hyper_rectangle(triangulation,\\n                                           lower_left,\\n                                           upper_right);\\n triangulation.refine_global(2);\\n \\n            euler_operator.set_inflow_boundary(\\n              0, std::make_unique<ExactSolution<dim>>(0));\\n \\n break;\\n          }\\n \\n case 1:\\n          {\\n GridGenerator::channel_with_cylinder(\\n triangulation, 0.03, 1, 0, true);\\n \\n            euler_operator.set_inflow_boundary(\\n              0, std::make_unique<ExactSolution<dim>>(0));\\n            euler_operator.set_subsonic_outflow_boundary(\\n              1, std::make_unique<ExactSolution<dim>>(0));\\n \\n            euler_operator.set_wall_boundary(2);\\n            euler_operator.set_wall_boundary(3);\\n \\n if (dim == 3)\\n              euler_operator.set_body_force(\\n                std::make_unique<Functions::ConstantFunction<dim>>(\\n                  std::vector<double>({0., 0., -0.2})));\\n \\n break;\\n          }\\n \\n default:\\n DEAL_II_NOT_IMPLEMENTED();\\n      }\\n \\n triangulation.refine_global(n_global_refinements);\\n \\n    dof_handler.distribute_dofs(fe);\\n \\n    euler_operator.reinit(mapping, dof_handler);\\n    euler_operator.initialize_vector(solution);\\n \\n    std::locale s = pcout.get_stream().getloc();\\n    pcout.get_stream().imbue(std::locale(\\\"\\\"));\\n    pcout << \\\"Number of degrees of freedom: \\\" << dof_handler.n_dofs()\\n          << \\\" ( = \\\" << (dim + 2) << \\\" [vars] x \\\"\\n          << triangulation.n_global_active_cells() << \\\" [cells] x \\\"\\n          << Utilities::pow(fe_degree + 1, dim) << \\\" [dofs/cell/var] )\\\"\\n          << std::endl;\\n    pcout.get_stream().imbue(s);\\n  }\\n \\n \\n \\n template <int dim>\\n void EulerProblem<dim>::output_results(const unsigned int result_number)\\n  {\\n const std::array<double, 3> errors =\\n      euler_operator.compute_errors(ExactSolution<dim>(time), solution);\\n const std::string quantity_name = testcase == 0 ? \\\"error\\\" : \\\"norm\\\";\\n \\n    pcout << \\\"Time:\\\" << std::setw(8) << std::setprecision(3) << time\\n          << \\\", dt: \\\" << std::setw(8) << std::setprecision(2) << time_step\\n          << \\\", \\\" << quantity_name << \\\" rho: \\\" << std::setprecision(4)\\n          << std::setw(10) << errors[0] << \\\", rho * u: \\\" << std::setprecision(4)\\n          << std::setw(10) << errors[1] << \\\", energy:\\\" << std::setprecision(4)\\n          << std::setw(10) << errors[2] << std::endl;\\n \\n    {\\n TimerOutput::Scope t(timer, \\\"output\\\");\\n \\n      Postprocessor postprocessor;\\n DataOut<dim>  data_out;\\n \\n DataOutBase::VtkFlags flags;\\n      flags.write_higher_order_cells = true;\\n      data_out.set_flags(flags);\\n \\n      data_out.attach_dof_handler(dof_handler);\\n      {\\n        std::vector<std::string> names;\\n        names.emplace_back(\\\"density\\\");\\n for (unsigned int d = 0; d < dim; ++d)\\n          names.emplace_back(\\\"momentum\\\");\\n        names.emplace_back(\\\"energy\\\");\\n \\n        std::vector<DataComponentInterpretation::DataComponentInterpretation>\\n          interpretation;\\n        interpretation.push_back(\\n DataComponentInterpretation::component_is_scalar);\\n for (unsigned int d = 0; d < dim; ++d)\\n          interpretation.push_back(\\n DataComponentInterpretation::component_is_part_of_vector);\\n        interpretation.push_back(\\n DataComponentInterpretation::component_is_scalar);\\n \\n        data_out.add_data_vector(dof_handler, solution, names, interpretation);\\n      }\\n      data_out.add_data_vector(solution, postprocessor);\\n \\n LinearAlgebra::distributed::Vector<Number> reference;\\n if (testcase == 0 && dim == 2)\\n        {\\n          reference.reinit(solution);\\n          euler_operator.project(ExactSolution<dim>(time), reference);\\n          reference.sadd(-1., 1, solution);\\n          std::vector<std::string> names;\\n          names.emplace_back(\\\"error_density\\\");\\n for (unsigned int d = 0; d < dim; ++d)\\n            names.emplace_back(\\\"error_momentum\\\");\\n          names.emplace_back(\\\"error_energy\\\");\\n \\n          std::vector<DataComponentInterpretation::DataComponentInterpretation>\\n            interpretation;\\n          interpretation.push_back(\\n DataComponentInterpretation::component_is_scalar);\\n for (unsigned int d = 0; d < dim; ++d)\\n            interpretation.push_back(\\n DataComponentInterpretation::component_is_part_of_vector);\\n          interpretation.push_back(\\n DataComponentInterpretation::component_is_scalar);\\n \\n          data_out.add_data_vector(dof_handler,\\n                                   reference,\\n                                   names,\\n                                   interpretation);\\n        }\\n \\n Vector<double> mpi_owner(triangulation.n_active_cells());\\n      mpi_owner = Utilities::MPI::this_mpi_process(MPI_COMM_WORLD);\\n      data_out.add_data_vector(mpi_owner, \\\"owner\\\");\\n \\n      data_out.build_patches(mapping,\\n                             fe.degree,\\n DataOut<dim>::curved_inner_cells);\\n \\n const std::string filename =\\n \\\"solution_\\\" + Utilities::int_to_string(result_number, 3) + \\\".vtu\\\";\\n      data_out.write_vtu_in_parallel(filename, MPI_COMM_WORLD);\\n    }\\n  }\\n \\n \\n \\n template <int dim>\\n void EulerProblem<dim>::run()\\n  {\\n    {\\n const unsigned int n_vect_number = VectorizedArrayType::size();\\n const unsigned int n_vect_bits   = 8 * sizeof(Number) * n_vect_number;\\n \\n      pcout << \\\"Running with \\\"\\n            << Utilities::MPI::n_mpi_processes(MPI_COMM_WORLD)\\n            << \\\" MPI processes\\\" << std::endl;\\n      pcout << \\\"Vectorization over \\\" << n_vect_number << ' '\\n            << (std::is_same_v<Number, double> ? \\\"doubles\\\" : \\\"floats\\\") << \\\" = \\\"\\n            << n_vect_bits << \\\" bits (\\\"\\n            << Utilities::System::get_current_vectorization_level() << ')'\\n            << std::endl;\\n    }\\n \\n    make_grid_and_dofs();\\n \\n const LowStorageRungeKuttaIntegrator integrator(lsrk_scheme);\\n \\n LinearAlgebra::distributed::Vector<Number> rk_register_1;\\n LinearAlgebra::distributed::Vector<Number> rk_register_2;\\n    rk_register_1.reinit(solution);\\n    rk_register_2.reinit(solution);\\n \\n    euler_operator.project(ExactSolution<dim>(time), solution);\\n \\n \\n double min_vertex_distance = std::numeric_limits<double>::max();\\n for (const auto &cell : triangulation.active_cell_iterators())\\n      if (cell->is_locally_owned())\\n        min_vertex_distance =\\n std::min(min_vertex_distance, cell->minimum_vertex_distance());\\n    min_vertex_distance =\\n Utilities::MPI::min(min_vertex_distance, MPI_COMM_WORLD);\\n \\n    time_step = courant_number * integrator.n_stages() /\\n                euler_operator.compute_cell_transport_speed(solution);\\n    pcout << \\\"Time step size: \\\" << time_step\\n          << \\\", minimal h: \\\" << min_vertex_distance\\n          << \\\", initial transport scaling: \\\"\\n          << 1. / euler_operator.compute_cell_transport_speed(solution)\\n          << std::endl\\n          << std::endl;\\n \\n    output_results(0);\\n \\n unsigned int timestep_number = 0;\\n \\n while (time < final_time - 1e-12 && timestep_number < max_time_steps)\\n      {\\n        ++timestep_number;\\n if (timestep_number % 5 == 0)\\n          time_step =\\n            courant_number * integrator.n_stages() /\\n Utilities::truncate_to_n_digits(\\n              euler_operator.compute_cell_transport_speed(solution), 3);\\n \\n        {\\n TimerOutput::Scope t(timer, \\\"rk time stepping total\\\");\\n          integrator.perform_time_step(euler_operator,\\n                                       time,\\n                                       time_step,\\n                                       solution,\\n                                       rk_register_1,\\n                                       rk_register_2);\\n        }\\n \\n        time += time_step;\\n \\n if (static_cast<int>(time / output_tick) !=\\n static_cast<int>((time - time_step) / output_tick) ||\\n            time >= final_time - 1e-12)\\n          output_results(\\n static_cast<unsigned int>(std::round(time / output_tick)));\\n      }\\n \\n    timer.print_wall_time_statistics(MPI_COMM_WORLD);\\n    pcout << std::endl;\\n  }\\n \\n} // namespace Euler_DG\\n \\n \\nint main(int argc, char **argv)\\n{\\n using namespace Euler_DG;\\n using namespace dealii;\\n \\n Utilities::MPI::MPI_InitFinalize mpi_initialization(argc, argv, 1);\\n \\n try\\n    {\\n      EulerProblem<dimension> euler_problem;\\n      euler_problem.run();\\n    }\\n catch (std::exception &exc)\\n    {\\n      std::cerr << std::endl\\n                << std::endl\\n                << \\\"----------------------------------------------------\\\"\\n                << std::endl;\\n      std::cerr << \\\"Exception on processing: \\\" << std::endl\\n                << exc.what() << std::endl\\n                << \\\"Aborting!\\\" << std::endl\\n                << \\\"----------------------------------------------------\\\"\\n                << std::endl;\\n \\n return 1;\\n    }\\n catch (...)\\n    {\\n      std::cerr << std::endl\\n                << std::endl\\n                << \\\"----------------------------------------------------\\\"\\n                << std::endl;\\n      std::cerr << \\\"Unknown exception!\\\" << std::endl\\n                << \\\"Aborting!\\\" << std::endl\\n                << \\\"----------------------------------------------------\\\"\\n                << std::endl;\\n return 1;\\n    }\\n \\n return 0;\\n}\\naffine_constraints.h\\nDataOutInterface::write_vtu_in_parallelvoid write_vtu_in_parallel(const std::string &filename, const MPI_Comm comm) constDefinition data_out_base.cc:7715\\nDataOutInterface::set_flagsvoid set_flags(const FlagType &flags)Definition data_out_base.cc:8863\\nDataOut_DoFData::attach_dof_handlervoid attach_dof_handler(const DoFHandler< dim, spacedim > &)\\nDataOut_DoFData::add_data_vectorvoid add_data_vector(const VectorType &data, const std::vector< std::string > &names, const DataVectorType type=type_automatic, const std::vector< DataComponentInterpretation::DataComponentInterpretation > &data_component_interpretation={})Definition data_out_dof_data.h:1069\\nDataOut::build_patchesvirtual void build_patches(const unsigned int n_subdivisions=0)Definition data_out.cc:1062\\nDoFHandler::distribute_dofsvoid distribute_dofs(const FiniteElement< dim, spacedim > &fe)\\nDoFHandler::get_triangulationconst Triangulation< dim, spacedim > & get_triangulation() const\\nDoFHandler::n_dofstypes::global_dof_index n_dofs() const\\nLinearAlgebra::distributed::Vector::zero_out_ghost_valuesvoid zero_out_ghost_values() const\\nLinearAlgebra::distributed::Vector::saddvoid sadd(const Number s, const Number a, const Vector< Number, MemorySpace > &V)\\nTimerOutput::print_wall_time_statisticsvoid print_wall_time_statistics(const MPI_Comm mpi_comm, const double print_quantile=0.) constDefinition timer.cc:840\\nconditional_ostream.h\\ntria.h\\ndof_handler.h\\nfe_dgq.h\\nfe_evaluation.h\\nfe_system.h\\nfunction.h\\ntria.h\\ngrid_generator.h\\nutilities.h\\nla_parallel_vector.h\\nmatrix_free.h\\nVectorTools::projectvoid project(const Mapping< dim, spacedim > &mapping, const DoFHandler< dim, spacedim > &dof, const AffineConstraints< typename VectorType::value_type > &constraints, const Quadrature< dim > &quadrature, const Function< spacedim, typename VectorType::value_type > &function, VectorType &vec, const bool enforce_zero_boundary=false, const Quadrature< dim - 1 > &q_boundary=(dim > 1 ? QGauss< dim - 1 >(2) :Quadrature< dim - 1 >()), const bool project_to_boundary_first=false)\\ninternal::reinitvoid reinit(MatrixBlock< MatrixType > &v, const BlockSparsityPattern &p)Definition matrix_block.h:617\\ninternal::EvaluatorQuantity::value@ value\\ndata_out.h\\noperators.h\\nDataPostprocessorInputs::Vector::solution_valuesstd::vector<::Vector< double > > solution_valuesDefinition data_postprocessor.h:410\\nDataPostprocessorInputs::Vector::solution_gradientsstd::vector< std::vector< Tensor< 1, spacedim > > > solution_gradientsDefinition data_postprocessor.h:429\\nMatrixFree::AdditionalData::tasks_parallel_schemeTasksParallelScheme tasks_parallel_schemeDefinition matrix_free.h:347\\ntime_stepping.h\\ntimer.h\\ntools.h\\ntria_accessor.h\\ntria_iterator.h\\nvectorization.h\\n \\n\\n\\n\\n\\nGenerated by\\u00a0 1.11.0\\n\\n\\n\\n\\n\", \"type\": \"Document\"}}]"